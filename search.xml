<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[python并发编程之多线程]]></title>
    <url>%2F2019%2F03%2F02%2Fpython%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[threading模块介绍multiprocess模块的完全模仿了threading模块的接口，二者在使用层面，有很大的相似性，因而不再详细介绍 开启线程的两种方式Thread类直接创建12345678910from threading import Threadimport timedef sayhi(name): time.sleep(2) print('%s say hello' %name) if __name__ == '__main__': t=Thread(target=sayhi,args=('egon',)) t.start() print('主线程') Thread类继承式创建12345678910111213141516171819from threading import Threadimport time class MyThread(Thread): def __init__(self,num): Thread.__init__(self) self.num=num def run(self): print("running on number:%s" %self.num) time.sleep(3) t1=MyThread(56)t2=MyThread(78) t1.start()t2.start()print("ending") Thread类的实例方法join()：在子线程完成运行之前，这个子线程的父线程将一直被阻塞（join写在start之后） setDaemon(True)：将线程声明为守护线程，必须在start() 方法调用之前设置，如果不设置为守护线程程序会被无限挂起。 当我们在程序运行中，执行一个主线程，如果主线程又创建一个子线程，主线程和子线程 就分兵两路，分别运行，那么当主线程完成想退出时，会检验子线程是否完成。如果子线程未完成，则主线程会等待子线程完成后再退出。但是有时候我们需要的是只要主线程完成了，不管子线程是否完成，都要和主线程一起退出，这时就可以 用setDaemon方法啦 当主线程执行完，要等非守护线程完成，而此时守护线程并没有死，等待的过程中可以执行 1234567891011121314151617181920212223242526272829303132333435363738394041import threadingfrom time import ctime,sleepimport time def Music(name): print ("Begin listening to &#123;name&#125;. &#123;time&#125;".format(name=name,time=ctime())) sleep(3) print("end listening &#123;time&#125;".format(time=ctime())) def Blog(title): print ("Begin recording the &#123;title&#125;. &#123;time&#125;".format(title=title,time=ctime())) sleep(5) print('end recording &#123;time&#125;'.format(time=ctime())) threads = [] t1 = threading.Thread(target=Music,args=('FILL ME',))t2 = threading.Thread(target=Blog,args=('',)) threads.append(t1)threads.append(t2) if __name__ == '__main__': #t2.setDaemon(True) for t in threads: #t.setDaemon(True) #注意:一定在start之前设置 t.start() #t.join() #t1.join() #t2.join() # 考虑这三种join位置下的结果？ print ("all over %s" %ctime()) daemon 12A boolean value indicating whether this thread is a daemon thread (True) or not (False). This must be set before start() is called, otherwise RuntimeError is raised. Its initial value is inherited from the creating thread; the main thread is not a daemon thread and therefore all threads created in the main thread default to daemon = False.The entire Python program exits when no alive non-daemon threads are left. 当daemon被设置为True时，如果主线程退出，那么子线程也将跟着退出,(注意退出不是死，) 反之，子线程将继续运行，直到正常退出。 Thread实例对象的方法isAlive(): 返回线程是否活动的。getName(): 返回线程名。setName(): 设置线程名。 threading模块提供的一些方法：threading.currentThread(): 返回当前的线程变量。threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。 GIL12345定义：In CPython, the global interpreter lock, or GIL, is a mutex that prevents multiple native threads from executing Python bytecodes at once. This lock is necessary mainly because CPython’s memory management is not thread-safe. (However, since the GIL exists, other features have grown to depend on the guarantees that it enforces.) Python中的线程是操作系统的原生线程，Python虚拟机使用一个全局解释器锁（Global Interpreter Lock）来互斥线程对Python虚拟机的使用。为了支持多线程机制，一个基本的要求就是需要实现不同线程对共享资源访问的互斥，所以引入了GIL。GIL：在一个线程拥有了解释器的访问权之后，其他的所有线程都必须等待它释放解释器的访问权，即使这些线程的下一条指令并不会互相影响。在调用任何Python C API之前，要先获得GILGIL缺点：多处理器退化为单处理器；优点：避免大量的加锁解锁操作 GIL的早期设计Python支持多线程，而解决多线程之间数据完整性和状态同步的最简单方法自然就是加锁。 于是有了GIL这把超级大锁，而当越来越多的代码库开发者接受了这种设定后，他们开始大量依赖这种特性（即默认python内部对象是thread-safe的，无需在实现时考虑额外的内存锁和同步操作）。慢慢的这种实现方式被发现是蛋疼且低效的。但当大家试图去拆分和去除GIL的时候，发现大量库代码开发者已经重度依赖GIL而非常难以去除了。有多难？做个类比，像MySQL这样的“小项目”为了把Buffer Pool Mutex这把大锁拆分成各个小锁也花了从5.5到5.6再到5.7多个大版为期近5年的时间，并且仍在继续。MySQL这个背后有公司支持且有固定开发团队的产品走的如此艰难，那又更何况Python这样核心开发和代码贡献者高度社区化的团队呢？ GIL的影响无论你启多少个线程，你有多少个cpu, Python在执行一个进程的时候会淡定的在同一时刻只允许一个线程运行。所以，python是无法利用多核CPU实现多线程的。这样，python对于计算密集型的任务开多线程的效率甚至不如串行(没有大量切换)，但是，对于IO密集型的任务效率还是有显著提升的。 计算密集型： 123456789101112131415161718192021222324252627282930313233343536373839404142#coding:utf8from threading import Threadimport time def counter(): i = 0 for _ in range(50000000): i = i + 1 return True def main(): l=[] start_time = time.time() for i in range(2): t = Thread(target=counter) t.start() l.append(t) t.join() # for t in l: # t.join() end_time = time.time() print("Total time: &#123;&#125;".format(end_time - start_time)) if __name__ == '__main__': main() '''py2.7: 串行:25.4523348808s 并发:31.4084379673spy3.5: 串行:8.62115597724914s 并发:8.99609899520874s''' 解决方案用multiprocessing替代Thread multiprocessing库的出现很大程度上是为了弥补thread库因为GIL而低效的缺陷。它完整的复制了一套thread所提供的接口方便迁移。唯一的不同就是它使用了多进程而不是多线程。每个进程有自己的独立的GIL，因此也不会出现进程之间的GIL争抢。 12345678910111213141516171819202122232425262728293031323334353637383940#coding:utf8from multiprocessing import Processimport time def counter(): i = 0 for _ in range(40000000): i = i + 1 return True def main(): l=[] start_time = time.time() for _ in range(2): t=Process(target=counter) t.start() l.append(t) #t.join() for t in l: t.join() end_time = time.time() print("Total time: &#123;&#125;".format(end_time - start_time)) if __name__ == '__main__': main() '''py2.7: 串行:6.1565990448 s 并行:3.1639978885 spy3.5: 串行:6.556925058364868 s 并发:3.5378448963165283 s''' 当然multiprocessing也不是万能良药。它的引入会增加程序实现时线程间数据通讯和同步的困难。就拿计数器来举例子，如果我们要多个线程累加同一个变量，对于thread来说，申明一个global变量，用thread.Lock的context包裹住三行就搞定了。而multiprocessing由于进程之间无法看到对方的数据，只能通过在主线程申明一个Queue，put再get或者用share memory的方法。这个额外的实现成本使得本来就非常痛苦的多线程程序编码，变得更加痛苦了。 总结：因为GIL的存在，只有IO Bound场景下得多线程会得到较好的性能 - 如果对并行计算性能较高的程序可以考虑把核心部分也成C模块，或者索性用其他语言实现 - GIL在较长一段时间内将会继续存在，但是会不断对其进行改进。 所以对于GIL，既然不能反抗，那就学会去享受它吧！ 总结： GIL（全局解释器锁） 加在cpython解释器上： 计算密集型：一直在使用cpu IO：存在大量IO操作 对于算计密集型任务：python的多线程没有用 对于IO密集型任务：python的多线程有意义的 python使用多核：多个进程，弊端：开销大而且切换复杂 着重点:协程+多进程 方向：IO多路复用 终极思路：换c模块实现多线程 同步锁 (Lock)123456789101112131415161718192021222324import timeimport threading def addNum(): global num #在每个线程中都获取这个全局变量 #num-=1 temp=num time.sleep(0.1) num =temp-1 # 对此公共变量进行-1操作 num = 100 #设定一个共享变量 thread_list = [] for i in range(100): t = threading.Thread(target=addNum) t.start() thread_list.append(t) for t in thread_list: #等待所有线程执行完毕 t.join() print('Result: ', num) 锁通常被用来实现对共享资源的同步访问。为每一个共享资源创建一个Lock对象，当你需要访问该资源时，调用acquire方法来获取锁对象（如果其它线程已经获得了该锁，则当前线程需等待其被释放），待资源访问完后，再调用release方法释放锁： 12345678import threading R=threading.Lock()R.acquire()'''对公共数据的操作'''R.release() 扩展思考1、为什么有了GIL，还需要线程同步？ 多线程环境下必须存在资源的竞争,那么如何才能保证同一时刻只有一个线程对共享资源进行存取? 加锁, 对, 加锁可以保证存取操作的唯一性, 从而保证同一时刻只有一个线程对共享数据存取. 通常加锁也有2种不同的粒度的锁: ​ coarse-grained(粗粒度)： python解释器层面维护着一个全局的锁机制,用来保证线程安全。​ 内核级通过GIL实现的互斥保护了内核的共享资源。 ​ fine-grained(细粒度)： 那么程序员需要自行地加,解锁来保证线程安全，​ 用户级通过自行加锁保护的用户程序的共享资源。 2、GIL为什么限定在一个进程上？ 你写一个py程序，运行起来本身就是一个进程，这个进程是有解释器来翻译的，所以GIL限定在当前进程； 如果又创建了一个子进程，那么两个进程是完全独立的，这个字进程也是有python解释器来运行的，所以 这个子进程上也是受GIL影响的 死锁与递归锁所谓死锁： 是指两个或两个以上的进程或线程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import threadingimport time mutexA = threading.Lock()mutexB = threading.Lock() class MyThread(threading.Thread): def __init__(self): threading.Thread.__init__(self) def run(self): self.fun1() self.fun2() def fun1(self): mutexA.acquire() # 如果锁被占用,则阻塞在这里,等待锁的释放 print ("I am %s , get res: %s---%s" %(self.name, "ResA",time.time())) mutexB.acquire() print ("I am %s , get res: %s---%s" %(self.name, "ResB",time.time())) mutexB.release() mutexA.release() def fun2(self): mutexB.acquire() print ("I am %s , get res: %s---%s" %(self.name, "ResB",time.time())) time.sleep(0.2) mutexA.acquire() print ("I am %s , get res: %s---%s" %(self.name, "ResA",time.time())) mutexA.release() mutexB.release() if __name__ == "__main__": print("start---------------------------%s"%time.time()) for i in range(0, 10): my_thread = MyThread() my_thread.start() 在Python中为了支持在同一线程中多次请求同一资源，python提供了可重入锁RLock。这个RLock内部维护着一个Lock和一个counter变量，counter记录了acquire的次数，从而使得资源可以被多次require。直到一个线程所有的acquire都被release，其他的线程才能获得资源。上面的例子如果使用RLock代替Lock，则不会发生死锁： 1mutex=threading.RLock() Event对象线程的一个关键特性是每个线程都是独立运行且状态不可预测。如果程序中的其 他线程需要通过判断某个线程的状态来确定自己下一步的操作,这时线程同步问题就 会变得非常棘手。为了解决这些问题,我们需要使用threading库中的Event对象。 对象包含一个可由线程设置的信号标志,它允许线程等待某些事件的发生。在 初始情况下,Event对象中的信号标志被设置为假。如果有线程等待一个Event对象, 而这个Event对象的标志为假,那么这个线程将会被一直阻塞直至该标志为真。一个线程如果将一个Event对象的信号标志设置为真,它将唤醒所有等待这个Event对象的线程。如果一个线程等待一个已经被设置为真的Event对象,那么它将忽略这个事件, 继续执行 event.isSet()：返回event的状态值； event.wait()：如果 event.isSet()==False将阻塞线程； event.set()： 设置event的状态值为True，所有阻塞池的线程激活进入就绪状态， 等待操作系统调度； event.clear()：恢复event的状态值为False 可以考虑一种应用场景（仅仅作为说明），例如，我们有多个线程从Redis队列中读取数据来处理，这些线程都要尝试去连接Redis的服务，一般情况下，如果Redis连接不成功，在各个线程的代码中，都会去尝试重新连接。如果我们想要在启动时确保Redis服务正常，才让那些工作线程去连接Redis服务器，那么我们就可以采用threading.Event机制来协调各个工作线程的连接操作：主线程中会去尝试连接Redis服务，如果正常的话，触发事件，各工作线程会尝试连接Redis服务。 1234567891011121314151617181920212223242526import threadingimport timeimport logging logging.basicConfig(level=logging.DEBUG, format='(%(threadName)-10s) %(message)s',) def worker(event): logging.debug('Waiting for redis ready...') event.wait() logging.debug('redis ready, and connect to redis server and do some work [%s]', time.ctime()) time.sleep(1) def main(): readis_ready = threading.Event() t1 = threading.Thread(target=worker, args=(readis_ready,), name='t1') t1.start() t2 = threading.Thread(target=worker, args=(readis_ready,), name='t2') t2.start() logging.debug('first of all, check redis server, make sure it is OK, and then trigger the redis ready event') time.sleep(3) # simulate the check progress readis_ready.set() if __name__=="__main__": main() threading.Event的wait方法还接受一个超时参数，默认情况下如果事件一致没有发生，wait方法会一直阻塞下去，而加入这个超时参数之后，如果阻塞时间超过这个参数设定的值之后，wait方法会返回。对应于上面的应用场景，如果Redis服务器一致没有启动，我们希望子线程能够打印一些日志来不断地提醒我们当前没有一个可以连接的Redis服务，我们就可以通过设置这个超时参数来达成这样的目的： 123456def worker(event): while not event.is_set(): logging.debug('Waiting for redis ready...') event.wait(2) logging.debug('redis ready, and connect to redis server and do some work [%s]', time.ctime()) time.sleep(1) 这样，我们就可以在等待Redis服务启动的同时，看到工作线程里正在等待的情况。 Semaphore（信号量）Semaphore管理一个内置的计数器，每当调用acquire()时内置计数器-1；调用release() 时内置计数器+1；计数器不能小于0；当计数器为0时，acquire()将阻塞线程直到其他线程调用release()。 实例：(同时只有5个线程可以获得semaphore,即可以限制最大连接数为5)： 1234567891011121314import threadingimport time semaphore = threading.Semaphore(5) def func(): if semaphore.acquire(): print (threading.currentThread().getName() + ' get semaphore') time.sleep(2) semaphore.release() for i in range(20): t1 = threading.Thread(target=func) t1.start() 队列(queue)get与put方法创建一个“队列”对象 12import Queueq = Queue.Queue(maxsize = 10) Queue.Queue类即是一个队列的同步实现。队列长度可为无限或者有限。可通过Queue的构造函数的可选参数maxsize来设定队列长度。如果maxsize小于1就表示队列长度无限。 将一个值放入队列中 1q.put(10) 调用队列对象的put()方法在队尾插入一个项目。put()有两个参数，第一个item为必需的，为插入项目的值；第二个block为可选参数，默认为1。如果队列当前为空且block为1，put()方法就使调用线程暂停,直到空出一个数据单元。如果block为0，put方法将引发Full异常。 将一个值从队列中取出 1q.get() 调用队列对象的get()方法从队头删除并返回一个项目。可选参数为block，默认为True。如果队列为空且block为True，get()就使调用线程暂停，直至有项目可用。如果队列为空且block为False，队列将引发Empty异常。 join与task_done方法join() 阻塞进程，直到所有任务完成，需要配合另一个方法task_done 1234def join(self): with self.all_tasks_done: while self.unfinished_tasks: self.all_tasks_done.wait() task_done() 表示某个任务完成。每一条get语句后需要一条task_done 123456789101112import queueq = queue.Queue(5)q.put(10)q.put(20)print(q.get())q.task_done()print(q.get())q.task_done() q.join() print("ending!") 其他常用方法此包中的常用方法(q = Queue.Queue()): q.qsize() 返回队列的大小q.empty() 如果队列为空，返回True,反之Falseq.full() 如果队列满了，返回True,反之Falseq.full 与 maxsize 大小对应q.get([block[, timeout]]) 获取队列，timeout等待时间q.get_nowait() 相当q.get(False)非阻塞q.put(item) 写入队列，timeout等待时间q.put_nowait(item) 相当q.put(item, False)q.task_done() 在完成一项工作之后，q.task_done() 函数向任务已经完成的队列发送一个信号q.join() 实际上意味着等到队列为空，再执行别的操作 其他模式Python Queue模块有三种队列及构造函数: 1、Python Queue模块的FIFO队列先进先出。 class queue.Queue(maxsize)2、LIFO类似于堆，即先进后出。 class queue.LifoQueue(maxsize)3、还有一种是优先级队列级别越低越先出来。 class queue.PriorityQueue(maxsize) 1234567891011121314151617181920import queue #先进后出 q=queue.LifoQueue() q.put(34)q.put(56)q.put(12) #优先级q=queue.PriorityQueue()q.put([5,100])q.put([7,200])q.put([3,"hello"])q.put([4,&#123;"name":"alex"&#125;]) while 1: data=q.get() print(data) 生产者消费者模型在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发当中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。为了解决这个问题于是引入了生产者和消费者模式。 生产者消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。 这就像，在餐厅，厨师做好菜，不需要直接和客户交流，而是交给前台，而客户去饭菜也不需要不找厨师，直接去前台领取即可，这也是一个结耦的过程。 1234567891011121314151617181920212223242526272829303132333435363738import time,randomimport queue,threading q = queue.Queue() def Producer(name): count = 0 while count &lt;10: print("making........") time.sleep(random.randrange(3)) q.put(count) print('Producer %s has produced %s baozi..' %(name, count)) count +=1 #q.task_done() #q.join() print("ok......")def Consumer(name): count = 0 while count &lt;10: time.sleep(random.randrange(4)) if not q.empty(): data = q.get() #q.task_done() #q.join() print(data) print('\033[32;1mConsumer %s has eat %s baozi...\033[0m' %(name, data)) else: print("-----no baozi anymore----") count +=1 p1 = threading.Thread(target=Producer, args=('A',))c1 = threading.Thread(target=Consumer, args=('B',))# c2 = threading.Thread(target=Consumer, args=('C',))# c3 = threading.Thread(target=Consumer, args=('D',))p1.start()c1.start()# c2.start()# c3.start() multiprocessing模块1Multiprocessing is a package that supports spawning processes using an API similar to the threading module. The multiprocessing package offers both local and remote concurrency,effectively side-stepping the Global Interpreter Lock by using subprocesses instead of threads. Due to this, the multiprocessing module allows the programmer to fully leverage multiple processors on a given machine. It runs on both Unix and Windows. 由于GIL的存在，python中的多线程其实并不是真正的多线程，如果想要充分地使用多核CPU的资源，在python中大部分情况需要使用多进程。 multiprocessing包是Python中的多进程管理包。与threading.Thread类似，它可以利用multiprocessing.Process对象来创建一个进程。该进程可以运行在Python程序内部编写的函数。该Process对象与Thread对象的用法相同，也有start(), run(), join()的方法。此外multiprocessing包中也有Lock/Event/Semaphore/Condition类 (这些对象可以像多线程那样，通过参数传递给各个进程)，用以同步进程，其用法与threading包中的同名类一致。所以，multiprocessing的很大一部份与threading使用同一套API，只不过换到了多进程的情境。 python的进程调用123456789101112131415161718192021222324252627282930313233343536373839404142434445# Process类调用 from multiprocessing import Processimport timedef f(name): print('hello', name,time.ctime()) time.sleep(1) if __name__ == '__main__': p_list=[] for i in range(3): p = Process(target=f, args=('alvin:%s'%i,)) p_list.append(p) p.start() for i in p_list: p.join() print('end') # 继承Process类调用from multiprocessing import Processimport time class MyProcess(Process): def __init__(self): super(MyProcess, self).__init__() # self.name = name def run(self): print ('hello', self.name,time.ctime()) time.sleep(1) if __name__ == '__main__': p_list=[] for i in range(3): p = MyProcess() p.start() p_list.append(p) for p in p_list: p.join() print('end') process类构造方法： Process([group [, target [, name [, args [, kwargs]]]]]) group: 线程组，目前还没有实现，库引用中提示必须是None； target: 要执行的方法； name: 进程名； args/kwargs: 要传入方法的参数。 实例方法： is_alive()：返回进程是否在运行。 join([timeout])：阻塞当前上下文环境的进程程，直到调用此方法的进程终止或到达指定的timeout（可选参数）。 start()：进程准备就绪，等待CPU调度 run()：strat()调用run方法，如果实例进程时未制定传入target，这star执行t默认run()方法。 terminate()：不管任务是否完成，立即停止工作进程 属性： daemon：和线程的setDeamon功能一样 name：进程名字 pid：进程号 123456789101112131415161718192021222324252627282930from multiprocessing import Processimport osimport timedef info(name): print("name:",name) print('parent process:', os.getppid()) print('process id:', os.getpid()) print("------------------") time.sleep(1) def foo(name): info(name) if __name__ == '__main__': info('main process line') p1 = Process(target=info, args=('alvin',)) p2 = Process(target=foo, args=('egon',)) p1.start() p2.start() p1.join() p2.join() print("ending") 协程协程，又称微线程，纤程。英文名Coroutine。一句话说明什么是线程：协程是一种用户态的轻量级线程。 协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此： 协程能保留上一次调用时的状态（即所有局部状态的一个特定组合），每次过程重入时，就相当于进入上一次调用的状态，换种说法：进入上一次离开时所处逻辑流的位置。 yield与协程1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import time """传统的生产者-消费者模型是一个线程写消息，一个线程取消息，通过锁机制控制队列和等待，但一不小心就可能死锁。如果改用协程，生产者生产消息后，直接通过yield跳转到消费者开始执行，待消费者执行完毕后，切换回生产者继续生产，效率极高。"""# 注意到consumer函数是一个generator（生成器）:# 任何包含yield关键字的函数都会自动成为生成器(generator)对象 def consumer(): r = '' while True: # 3、consumer通过yield拿到消息，处理，又通过yield把结果传回； # yield指令具有return关键字的作用。然后函数的堆栈会自动冻结(freeze)在这一行。 # 当函数调用者的下一次利用next()或generator.send()或for-in来再次调用该函数时， # 就会从yield代码的下一行开始，继续执行，再返回下一次迭代结果。通过这种方式，迭代器可以实现无限序列和惰性求值。 n = yield r if not n: return print('[CONSUMER] ←← Consuming %s...' % n) time.sleep(1) r = '200 OK'def produce(c): # 1、首先调用c.next()启动生成器 next(c) n = 0 while n &lt; 5: n = n + 1 print('[PRODUCER] →→ Producing %s...' % n) # 2、然后，一旦生产了东西，通过c.send(n)切换到consumer执行； cr = c.send(n) # 4、produce拿到consumer处理的结果，继续生产下一条消息； print('[PRODUCER] Consumer return: %s' % cr) # 5、produce决定不生产了，通过c.close()关闭consumer，整个过程结束。 c.close()if __name__=='__main__': # 6、整个流程无锁，由一个线程执行，produce和consumer协作完成任务，所以称为“协程”，而非线程的抢占式多任务。 c = consumer() produce(c) '''result:[PRODUCER] →→ Producing 1...[CONSUMER] ←← Consuming 1...[PRODUCER] Consumer return: 200 OK[PRODUCER] →→ Producing 2...[CONSUMER] ←← Consuming 2...[PRODUCER] Consumer return: 200 OK[PRODUCER] →→ Producing 3...[CONSUMER] ←← Consuming 3...[PRODUCER] Consumer return: 200 OK[PRODUCER] →→ Producing 4...[CONSUMER] ←← Consuming 4...[PRODUCER] Consumer return: 200 OK[PRODUCER] →→ Producing 5...[CONSUMER] ←← Consuming 5...[PRODUCER] Consumer return: 200 OK''' greenletGreenlet是python的一个C扩展，来源于Stackless python，旨在提供可自行调度的‘微线程’， 即协程。generator实现的协程在yield value时只能将value返回给调用者(caller)。 而在greenlet中，target.switch（value）可以切换到指定的协程（target）， 然后yield value。greenlet用switch来表示协程的切换，从一个协程切换到另一个协程需要显式指定。 greenlet的安装很简单：pip install greenlet 即可，安装好了之后我们来看一个官方的例子 1234567891011121314from greenlet import greenletdef test1(): print 12 gr2.switch() print 34 def test2(): print 56 gr1.switch() print 78 gr1 = greenlet(test1)gr2 = greenlet(test2)gr1.switch() 输出为：12 56 34 当创建一个greenlet时，首先初始化一个空的栈， switch到这个栈的时候，会运行在greenlet构造时传入的函数（首先在test1中打印 12）， 如果在这个函数（test1）中switch到其他协程（到了test2 打印34），那么该协程会被挂起，等到切换回来（在test2中切换回来 打印34）。当这个协程对应函数执行完毕，那么这个协程就变成dead状态。 注意 上面没有打印test2的最后一行输出 78，因为在test2中切换到gr1之后挂起，但是没有地方再切换回来。这个可能造成泄漏，后面细说。 基于greenlet的框架gevent模块实现协程Python通过yield提供了对协程的基本支持，但是不完全。而第三方的gevent为Python提供了比较完善的协程支持。 gevent是第三方库，通过greenlet实现协程，其基本思想是： 当一个greenlet遇到IO操作时，比如访问网络，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO。 由于切换是在IO操作时自动完成，所以gevent需要修改Python自带的一些标准库，这一过程在启动时通过monkey patch完成： 123456789101112131415161718192021import geventimport time def foo(): print("running in foo") gevent.sleep(2) print("switch to foo again") def bar(): print("switch to bar") gevent.sleep(5) print("switch to bar again") start=time.time() gevent.joinall( [gevent.spawn(foo), gevent.spawn(bar)]) print(time.time()-start) 当然，实际代码里，我们不会用gevent.sleep()去切换协程，而是在执行到IO操作时，gevent自动切换，代码如下： 12345678910111213141516171819202122232425from gevent import monkeymonkey.patch_all()import geventfrom urllib import requestimport time def f(url): print('GET: %s' % url) resp = request.urlopen(url) data = resp.read() print('%d bytes received from %s.' % (len(data), url)) start=time.time() gevent.joinall([ gevent.spawn(f, 'https://itk.org/'), gevent.spawn(f, 'https://www.github.com/'), gevent.spawn(f, 'https://zhihu.com/'),]) # f('https://itk.org/')# f('https://www.github.com/')# f('https://zhihu.com/') print(time.time()-start) IO模型同步（synchronous） IO和异步（asynchronous） IO，阻塞（blocking） IO和非阻塞（non-blocking）IO分别是什么，到底有什么区别？这个问题其实不同的人给出的答案都可能不同，比如wiki，就认为asynchronous IO和non-blocking IO是一个东西。这其实是因为不同的人的知识背景不同，并且在讨论这个问题的时候上下文(context)也不相同。所以，为了更好的回答这个问题，先限定一下本文的上下文。本文讨论的背景是Linux环境下的network IO。 Stevens在文章中一共比较了五种IO Model： ​ blocking IO ​ nonblocking IO ​ IO multiplexing ​ signal driven IO ​ asynchronous IO 由于signal driven IO在实际中并不常用，所以我这只提及剩下的四种IO Model。再说一下IO发生时涉及的对象和步骤。对于一个network IO (这里我们以read举例)，它会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段： 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) 记住这两点很重要，因为这些IO Model的区别就是在两个阶段上各有不同的情况。 blocking IO （阻塞IO）在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样： 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。所以，blocking IO的特点就是在IO执行的两个阶段都被block了。 non-blocking IO（非阻塞IO）linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子： 从图中可以看出，当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。所以，用户进程其实是需要不断的主动询问kernel数据好了没有。 注意： ​ 在网络IO时候，非阻塞IO也会进行recvform系统调用，检查数据是否准备好，与阻塞IO不一样，”非阻塞将大的整片时间的阻塞分成N多的小的阻塞, 所以进程不断地有机会 ‘被’ CPU光顾”。即每次recvform系统调用之间，cpu的权限还在进程手中，这段时间是可以做其他事情的， ​ 也就是说非阻塞的recvform系统调用调用之后，进程并没有被阻塞，内核马上返回给进程，如果数据还没准备好，此时会返回一个error。进程在返回之后，可以干点别的事情，然后再发起recvform系统调用。重复上面的过程，循环往复的进行recvform系统调用。这个过程通常被称之为轮询。轮询检查内核数据，直到数据准备好，再拷贝数据到进程，进行数据处理。需要注意，拷贝数据整个过程，进程仍然是属于阻塞的状态。 12345678910111213141516171819202122232425262728293031import timeimport socketsk = socket.socket(socket.AF_INET,socket.SOCK_STREAM)sk.setsockoptsk.bind(('127.0.0.1',6667))sk.listen(5)sk.setblocking(False)while True: try: print ('waiting client connection .......') connection,address = sk.accept() # 进程主动轮询 print("+++",address) client_messge = connection.recv(1024) print(str(client_messge,'utf8')) connection.close() except Exception as e: print (e) time.sleep(4) #############################client import timeimport socketsk = socket.socket(socket.AF_INET,socket.SOCK_STREAM) while True: sk.connect(('127.0.0.1',6667)) print("hello") sk.sendall(bytes("hello","utf8")) time.sleep(2) break 优点：能够在等待任务完成的时间里干其他活了（包括提交其他任务，也就是 “后台” 可以有多个任务在同时执行）。 缺点：任务完成的响应延迟增大了，因为每过一段时间才去轮询一次read操作，而任务可能在两次轮询之间的任意时间完成。这会导致整体数据吞吐量的降低。 IO multiplexing（IO多路复用） IO multiplexing这个词可能有点陌生，但是如果我说select，epoll，大概就都能明白了。有些地方也称这种IO方式为event driven IO。我们都知道，select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。它的流程如图： 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。（多说一句。所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 结论: select的优势在于可以处理多个连接，不适用于单个连接 123456789101112131415161718192021222324252627282930import socketimport time import selectsock=socket.socket() sock.bind(("127.0.0.1",8800)) sock.listen(5) sock.setblocking(False)inputs=[sock,] print("sock",sock) while 1: r,w,e=select.select(inputs,[],[]) # 监听有变化的套接字 inputs=[sock,conn1,conn2,conn3..] print("r",r) for obj in r: # 第一次 [sock,] 第二次 #[conn1,] if obj==sock: print('change') conn,addr=obj.accept() inputs.append(conn) # inputs=[sock,conn] else: data=obj.recv(1024) print(data.decode("utf8")) send_data=input("&gt;&gt;&gt;") obj.send(send_data.encode("utf8")) Asynchronous I/O（异步IO）linux下的asynchronous IO其实用得很少。先看一下它的流程： 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 IO模型比较分析到目前为止，已经将四个IO Model都介绍完了。现在回过头来回答最初的那几个问题：blocking和non-blocking的区别在哪，synchronous IO和asynchronous IO的区别在哪。先回答最简单的这个：blocking vs non-blocking。前面的介绍中其实已经很明确的说明了这两者的区别。调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。 在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。Stevens给出的定义（其实是POSIX的定义）是这样子的： A synchronous I/O operation causes the requesting process to be blocked until that I/O operationcompletes; An asynchronous I/O operation does not cause the requesting process to be blocked; 两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。有人可能会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。 各个IO Model的比较如图所示： 经过上面的介绍，会发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。 IO模型 1 阻塞IO:全程阻塞2 非阻塞IO: 发送多次系统调用；优点：wait for data时无阻塞 缺点：1 系统调用太多 2 数据不是实时接受的 两个阶段：wait for data:非阻塞 copy data :阻塞 3 IO多路复用（监听多个连接） sock::sock &lt;socket.socket fd=224, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=(‘127.0.0.1’, 8800)&gt; 对于文件描述符（套接字对象）： 1 是一个非零整数，不会变 2 收发数据的时候，对于接收端而言，数据先到内核空间，然后copy到用户空间，同时，内核空间数据清除。 特点：1 全程（wait for data,copy）阻塞 2 能监听多个文件描述符 3 实现并发 4 异步IO 全程无阻塞 总结： 同步： 阻塞IO 非阻塞IO io多路复用异步： 异步IO selectors模块12345678910111213141516171819202122232425262728293031323334353637383940414243import selectors # 基于select模块实现的IO多路复用，建议大家使用 import socket sock=socket.socket()sock.bind(("127.0.0.1",8800)) sock.listen(5) sock.setblocking(False) sel=selectors.DefaultSelector() #根据具体平台选择最佳IO多路机制，比如在linux，选择epoll def read(conn,mask): try: data=conn.recv(1024) print(data.decode("UTF8")) data2=input("&gt;&gt;&gt;") conn.send(data2.encode("utf8")) except Exception: sel.unregister(conn) def accept(sock,mask): conn, addr = sock.accept() print("conn",conn) sel.register(conn,selectors.EVENT_READ,read) sel.register(sock,selectors.EVENT_READ,accept) # 注册事件 while 1: print("wating...") events=sel.select() # 监听 [(key1,mask1),(key2,mask2)] for key,mask in events: # print(key.fileobj) # conn # print(key.data) # read func=key.data obj=key.fileobj func(obj,mask) # 1 accept(sock,mask) # 2 read(conn,mask)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python之socket编程]]></title>
    <url>%2F2019%2F03%2F02%2Fpython%E4%B9%8Bsocket%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[客户端/服务器架构1.硬件C/S架构(打印机) 2.软件C/S架构 互联网中处处是C/S架构 如百度是服务端，你的浏览器是客户端（B/S架构也是C/S架构的一种） 腾讯作为服务端为你提供视频，你得下个腾讯视频客户端才能看它的视频） C/S架构与socket的关系： 我们学习socket就是为了完成C/S架构的开发 osi七层引子： 须知一个完整的计算机系统是由硬件、操作系统、应用软件三者组成,具备了这三个条件，一台计算机系统就可以自己跟自己玩了（打个单机游戏，玩个扫雷啥的） 如果你要跟别人一起玩，那你就需要上网了，什么是互联网？ 互联网的核心就是由一堆协议组成，协议就是标准，比如全世界人通信的标准是英语 如果把计算机比作人，互联网协议就是计算机界的英语。所有的计算机都学会了互联网协议，那所有的计算机都就可以按照统一的标准去收发信息从而完成通信了。 人们按照分工不同把互联网协议从逻辑上划分了层级： 互联网协议按照功能不同分为osi七层或tcp/ip五层或tcp/ip四层 每层运行常见物理设备 为何学习socket一定要先学习互联网协议： 1.首先：本节课程的目标就是教会你如何基于socket编程，来开发一款自己的C/S架构软件 2.其次：C/S架构的软件（软件属于应用层）是基于网络进行通信的 3.然后：网络的核心即一堆协议，协议即标准，你想开发一款基于网络通信的软件，就必须遵循这些标准。 4.最后：就让我们从这些标准开始研究，开启我们的socket编程之旅 socket层在上面中，我们没有看到Socket的影子，那么它到底在哪里呢？还是用图来说话，一目了然。 socket是什么Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议。 所以，我们无需深入理解tcp/udp协议，socket已经为我们封装好了，我们只需要遵循socket的规定去编程，写出的程序自然就是遵循tcp/udp标准的。 也有人将socket说成ip+port，ip是用来标识互联网中的一台主机的位置，而port是用来标识这台机器上的一个应用程序，ip地址是配置到网卡上的，而port是应用程序开启的，ip与port的绑定就标识了互联网中独一无二的一个应用程序 而程序的pid是同一台机器上不同进程或者线程的标识 套接字发展史及分类套接字起源于 20 世纪 70 年代加利福尼亚大学伯克利分校版本的 Unix,即人们所说的 BSD Unix。 因此,有时人们也把套接字称为“伯克利套接字”或“BSD 套接字”。一开始,套接字被设计用在同 一台主机上多个应用程序之间的通讯。这也被称进程间通讯,或 IPC。套接字有两种（或者称为有两个种族）,分别是基于文件型的和基于网络型的。 基于文件类型的套接字家族 套接字家族的名字：AF_UNIX unix一切皆文件，基于文件的套接字调用的就是底层的文件系统来取数据，两个套接字进程运行在同一机器，可以通过访问同一个文件系统间接完成通信 基于网络类型的套接字家族 套接字家族的名字：AF_INET (还有AF_INET6被用于ipv6，还有一些其他的地址家族，不过，他们要么是只用于某个平台，要么就是已经被废弃，或者是很少被使用，或者是根本没有实现，所有地址家族中，AF_INET是使用最广泛的一个，python支持很多种地址家族，但是由于我们只关心网络编程，所以大部分时候我么只使用AF_INET) 套接字工作流程一个生活中的场景。你要打电话给一个朋友，先拨号，朋友听到电话铃声后提起电话，这时你和你的朋友就建立起了连接，就可以讲话了。等交流结束，挂断电话结束此次交谈。 生活中的场景就解释了这工作原理。 先从服务器端说起。服务器端先初始化Socket，然后与端口绑定(bind)，对端口进行监听(listen)，调用accept阻塞，等待客户端连接。在这时如果有个客户端初始化一个Socket，然后连接服务器(connect)，如果连接成功，这时客户端与服务器端的连接就建立了。客户端发送数据请求，服务器端接收请求并处理请求，然后把回应数据发送给客户端，客户端读取数据，最后关闭连接，一次交互结束 socket()模块函数用法 123456789101112import socketsocket.socket(socket_family,socket_type,protocal=0)socket_family 可以是 AF_UNIX 或 AF_INET。socket_type 可以是 SOCK_STREAM 或 SOCK_DGRAM。protocol 一般不填,默认值为 0。 获取tcp/ip套接字tcpSock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) 获取udp/ip套接字udpSock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) 由于 socket 模块中有太多的属性。我们在这里破例使用了'from module import *'语句。使用 'from socket import *',我们就把 socket 模块里的所有属性都带到我们的命名空间里了,这样能 大幅减短我们的代码。例如tcpSock = socket(AF_INET, SOCK_STREAM) 1234567891011121314151617181920212223242526272829服务端套接字函数s.bind() 绑定(主机,端口号)到套接字s.listen() 开始TCP监听s.accept() 被动接受TCP客户的连接,(阻塞式)等待连接的到来 客户端套接字函数s.connect() 主动初始化TCP服务器连接s.connect_ex() connect()函数的扩展版本,出错时返回出错码,而不是抛出异常 公共用途的套接字函数s.recv() 接收TCP数据s.send() 发送TCP数据(send在待发送数据量大于己端缓存区剩余空间时,数据丢失,不会发完)s.sendall() 发送完整的TCP数据(本质就是循环调用send,sendall在待发送数据量大于己端缓存区剩余空间时,数据不丢失,循环调用send直到发完)s.recvfrom() 接收UDP数据s.sendto() 发送UDP数据s.getpeername() 连接到当前套接字的远端的地址s.getsockname() 当前套接字的地址s.getsockopt() 返回指定套接字的参数s.setsockopt() 设置指定套接字的参数s.close() 关闭套接字 面向锁的套接字方法s.setblocking() 设置套接字的阻塞与非阻塞模式s.settimeout() 设置阻塞套接字操作的超时时间s.gettimeout() 得到阻塞套接字操作的超时时间 面向文件的套接字的函数s.fileno() 套接字的文件描述符s.makefile() 创建一个与该套接字相关的文件 基于TCP的套接字tcp是基于链接的，必须先启动服务端，然后再启动客户端去链接服务端 tcp服务端 12345678910import socketss = socket() #创建服务器套接字ss.bind() #把地址绑定到套接字ss.listen() #监听链接inf_loop: #服务器无限循环 cs = ss.accept() #接受客户端链接 comm_loop: #通讯循环 cs.recv()/cs.send() #对话(接收与发送) cs.close() #关闭客户端套接字ss.close() #关闭服务器套接字(可选) tcp客户端 123456import socketcs = socket() # 创建客户套接字cs.connect() # 尝试连接服务器comm_loop: # 通讯循环cs.send()/cs.recv() # 对话(发送/接收)cs.close() 实例：模仿ssh写服务端与客户端 tcp服务端 123456789101112131415161718192021222324252627import socketimport subprocessphone = socket.socket(socket.AF_INET, socket.SOCK_STREAM)phone.bind(('192.168.1.5', 8017))phone.listen(5)print('start....')while True: conf,message = phone.accept() print(conf) print(message) while True: try: data = conf.recv(1024) if not data: break data_tr = data.decode('utf-8') print(data_tr) # stdin,stdout, stderr： 分别指示要执行的程序标准输入、标准输出、标准错误输出文件的句柄 re = subprocess.Popen(data_tr, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) r1 = re.stdout.read() #读出来的是字节格式 r2 = re.stderr.read() conf.send(r1) conf.send(r2) except Exception: break conf.close()phone.close() tcp客户端 123456789101112import socketphone = socket.socket(socket.AF_INET, socket.SOCK_STREAM)phone.connect(('192.168.1.5', 8017))while True: sd = input("输入:".strip()) if not sd: continue phone.send(sd.encode('utf-8')) message = phone.recv(1024) print("----------------------") print(message.decode('gbk'))phone.close() 基于UDP的套接字udp是无链接的，先启动哪一端都不会报错 udp服务端 12345ss = socket() #创建一个服务器的套接字ss.bind() #绑定服务器套接字inf_loop: #服务器无限循环 cs = ss.recvfrom()/ss.sendto() # 对话(接收与发送)ss.close() # 关闭服务器套接字 udp客户端 1234cs = socket() # 创建客户套接字comm_loop: # 通讯循环 cs.sendto()/cs.recvfrom() # 对话(发送/接收)cs.close() # 关闭客户套接字 udp套接字简单示例 udp服务端 123456789101112import socketip_port=('127.0.0.1',9000)BUFSIZE=1024udp_server_client=socket.socket(socket.AF_INET,socket.SOCK_DGRAM) udp_server_client.bind(ip_port) while True: msg,addr=udp_server_client.recvfrom(BUFSIZE) print(msg,addr) udp_server_client.sendto(msg.upper(),addr) udp客户端 12345678910111213import socketip_port=('127.0.0.1',9000)BUFSIZE=1024udp_server_client=socket.socket(socket.AF_INET,socket.SOCK_DGRAM) while True: msg=input('&gt;&gt;: ').strip() if not msg:continue udp_server_client.sendto(msg.encode('utf-8'),ip_port) back_msg,addr=udp_server_client.recvfrom(BUFSIZE) print(back_msg.decode('utf-8'),addr) 粘包现象根据我之前写的模仿ssh程序，如果输入的命令，得到的内容比较大时，recv(1024)则可能不够用 什么是粘包须知：只有TCP有粘包现象，UDP永远不会粘包，为何，且听我娓娓道来 首先需要掌握一个socket收发消息的原理 发送端可以是一K一K地发送数据，而接收端的应用程序可以两K两K地提走数据，当然也有可能一次提走3K或6K数据，或者一次只提走几个字节的数据，也就是说，应用程序所看到的数据是一个整体，或说是一个流（stream），一条消息有多少字节对应用程序是不可见的，因此TCP协议是面向流的协议，这也是容易出现粘包问题的原因。而UDP是面向消息的协议，每个UDP段都是一条消息，应用程序必须以消息为单位提取数据，不能一次提取任意字节的数据，这一点和TCP是很不同的。怎样定义消息呢？可以认为对方一次性write/send的数据为一个消息，需要明白的是当对方send一条信息的时候，无论底层怎样分段分片，TCP协议层会把构成整条消息的数据段排序完成后才呈现在内核缓冲区。 例如基于tcp的套接字客户端往服务端上传文件，发送时文件内容是按照一段一段的字节流发送的，在接收方看了，根本不知道该文件的字节流从何处开始，在何处结束 所谓粘包问题主要还是因为接收方不知道消息之间的界限，不知道一次性提取多少字节的数据所造成的。 此外，发送方引起的粘包是由TCP协议本身造成的，TCP为提高传输效率，发送方往往要收集到足够多的数据后才发送一个TCP段。若连续几次需要send的数据都很少，通常TCP会根据优化算法把这些数据合成一个TCP段后一次发送出去，这样接收方就收到了粘包数据。 1231. TCP（transport control protocol，传输控制协议）是面向连接的，面向流的，提供高可靠性服务。收发两端（客户端和服务器端）都要有一一成对的socket，因此，发送端为了将多个发往接收端的包，更有效的发到对方，使用了优化方法（Nagle算法），将多次间隔较小且数据量小的数据，合并成一个大的数据块，然后进行封包。这样，接收端，就难于分辨出来了，必须提供科学的拆包机制。 即面向流的通信是无消息保护边界的。2. UDP（user datagram protocol，用户数据报协议）是无连接的，面向消息的，提供高效率服务。不会使用块的合并优化算法，, 由于UDP支持的是一对多的模式，所以接收端的skbuff(套接字缓冲区）采用了链式结构来记录每一个到达的UDP包，在每个UDP包中就有了消息头（消息来源地址，端口等信息），这样，对于接收端来说，就容易进行区分处理了。 即面向消息的通信是有消息保护边界的。3. tcp是基于数据流的，于是收发的消息不能为空，这就需要在客户端和服务端都添加空消息的处理机制，防止程序卡住，而udp是基于数据报的，即便是你输入的是空内容（直接回车），那也不是空消息，udp协议会帮你封装上消息头，实验略 udp的recvfrom是阻塞的，一个recvfrom(x)必须对唯一一个sendinto(y),收完了x个字节的数据就算完成,若是y&gt;x数据就丢失，这意味着udp根本不会粘包，但是会丢数据，不可靠 tcp的协议数据不会丢，没有收完包，下次接收，会继续上次继续接收，己端总是在收到ack时才会清除缓冲区内容。数据是可靠的，但是会粘包。 两种情况下会发生粘包。 1.发送端需要等缓冲区满才发送出去，造成粘包（发送数据时间间隔很短，数据了很小，会合到一起，产生粘包） 服务端 123456789101112131415161718from socket import *ip_port=('127.0.0.1',8080) tcp_socket_server=socket(AF_INET,SOCK_STREAM)tcp_socket_server.bind(ip_port)tcp_socket_server.listen(5) conn,addr=tcp_socket_server.accept() data1=conn.recv(10)data2=conn.recv(10) print('-----&gt;',data1.decode('utf-8'))print('-----&gt;',data2.decode('utf-8')) conn.close() 客户端 12345678910import socketBUFSIZE=1024ip_port=('127.0.0.1',8080) s=socket.socket(socket.AF_INET,socket.SOCK_STREAM)res=s.connect_ex(ip_port) s.send('hello'.encode('utf-8'))s.send('feng'.encode('utf-8')) 2.接收方不及时接收缓冲区的包，造成多个包接收（客户端发送了一段数据，服务端只收了一小部分，服务端下次再收的时候还是从缓冲区拿上次遗留的数据，产生粘包） 服务端 123456789101112131415161718from socket import *ip_port=('127.0.0.1',8080) tcp_socket_server=socket(AF_INET,SOCK_STREAM)tcp_socket_server.bind(ip_port)tcp_socket_server.listen(5) conn,addr=tcp_socket_server.accept() data1=conn.recv(2) #一次没有收完整data2=conn.recv(10)#下次收的时候,会先取旧的数据,然后取新的 print('-----&gt;',data1.decode('utf-8'))print('-----&gt;',data2.decode('utf-8')) conn.close() 客户端 123456789import socketBUFSIZE=1024ip_port=('127.0.0.1',8080) s=socket.socket(socket.AF_INET,socket.SOCK_STREAM)res=s.connect_ex(ip_port) s.send('hello feng'.encode('utf-8')) 拆包的发生情况 当发送端缓冲区的长度大于网卡的MTU时，tcp会将这次发送的数据拆成几个数据包发送出去。 补充问题一：为何tcp是可靠传输，udp是不可靠传输 tcp在数据传输时，发送端先把数据发送到自己的缓存中，然后协议控制将缓存中的数据发往对端，对端返回一个ack=1，发送端则清理缓存中的数据，对端返回ack=0，则重新发送数据，所以tcp是可靠的 而udp发送数据，对端是不会返回确认信息的，因此不可靠 补充问题二：send(字节流)和recv(1024)及sendall recv里指定的1024意思是从缓存里一次拿出1024个字节的数据 send的字节流是先放入己端缓存，然后由协议控制将缓存内容发往对端，如果待发送的字节流大小大于缓存剩余空间，那么数据丢失，用sendall就会循环调用send，数据不会丢失 解决粘包的方法为字节流加上自定义固定长度报头，报头中包含字节流长度，然后一次send到对端，对端在接收时，先从缓存中取出定长的报头，然后再取真实数据 struct模块 该模块可以把一个类型，如数字，转成固定长度的bytes 1struct.pack('i',1111111111111) struct.error: ‘i’ format requires -2147483648 &lt;= number &lt;= 2147483647 #这个是范围 123456789101112131415161718192021222324252627import json,struct#假设通过客户端上传1T:1073741824000的文件a.txt #为避免粘包,必须自定制报头header=&#123;'file_size':1073741824000,'file_name':'/a/b/c/d/e/a.txt','md5':'8f6fbf8347faa4924a76856701edb0f3'&#125; #1T数据,文件路径和md5值 #为了该报头能传送,需要序列化并且转为byteshead_bytes=bytes(json.dumps(header),encoding='utf-8') #序列化并转成bytes,用于传输 #为了让客户端知道报头的长度,用struck将报头长度这个数字转成固定长度:4个字节head_len_bytes=struct.pack('i',len(head_bytes)) #这4个字节里只包含了一个数字,该数字是报头的长度 #客户端开始发送conn.send(head_len_bytes) #先发报头的长度,4个bytesconn.send(head_bytes) #再发报头的字节格式conn.sendall(文件内容) #然后发真实内容的字节格式 #服务端开始接收head_len_bytes=s.recv(4) #先收报头4个bytes,得到报头长度的字节格式x=struct.unpack('i',head_len_bytes)[0] #提取报头的长度 head_bytes=s.recv(x) #按照报头长度x,收取报头的bytes格式header=json.loads(json.dumps(header)) #提取报头 #最后根据报头的内容提取真实的数据,比如real_data_len=s.recv(header['file_size'])s.recv(real_data_len) 服务端（自定制报头） 123456789101112131415161718192021222324252627282930313233343536373839404142import socketimport subprocessimport structimport jsonphone = socket.socket(socket.AF_INET, socket.SOCK_STREAM)phone.bind(('192.168.1.1', 8019))phone.listen(5)print('start....')while True: conf,message = phone.accept() print(conf) print(message) while True: try: data = conf.recv(1024) if not data: break data_tr = data.decode('utf-8') print(data_tr) # stdin,stdout, stderr： 分别指示要执行的程序标准输入、标准输出、标准错误输出文件的句柄 re = subprocess.Popen(data_tr, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) r1 = re.stdout.read() r2 = re.stderr.read() # 真正内容的长度 r_size = len(r1) + len(r2) # head头字典的格式 head_dict = &#123;'data_size': r_size&#125; # 用json转换 head_json = json.dumps(head_dict) head_content = head_json.encode('utf-8') # 发送报头的长度 head_size = len(head_content) conf.send(struct.pack('i', head_size)) # 发送报头 conf.send(head_content) # 发送真正的内容 conf.send(r1) conf.send(r2) except Exception: break conf.close()phone.close() 客户端（自定制报头） 1234567891011121314151617181920212223import socketimport structimport jsonphone = socket.socket(socket.AF_INET, socket.SOCK_STREAM)phone.connect(('192.168.1.1', 8019))while True: sd = input("输入:".strip()) if not sd: continue phone.send(sd.encode('utf-8')) baotou = phone.recv(4) baotou_len = struct.unpack('i', baotou)[0] head_json = phone.recv(baotou_len).decode('utf-8') head_size = json.loads(head_json) data_size = head_size['data_size'] real_content = b'' real_size = 0 if real_size &lt; data_size: data = phone.recv(1024) real_size += len(data) real_content += data print(real_content.decode('gbk'))phone.close() FTP例子：服务端有上传文件到服务器的功能 客户端 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import jsonimport structimport osimport socket class MyClient: coding = 'utf-8' address_family = socket.AF_INET socket_type = socket.SOCK_STREAM def __init__(self, client_address, client_active=True): self.client_address = client_address self.sock = socket.socket(self.address_family, self.socket_type) if client_active: try: self.client_connect() except: self.client_close() raise def client_connect(self): self.sock.connect(self.client_address) def client_close(self): self.sock.close() def run(self): print('请输入命令以及要上传的文件的路径') while True: inp = input("&gt;&gt;: ").strip() if not inp: continue inp_split = inp.split() cmd = inp_split[0] if hasattr(self, cmd): fu = getattr(self, cmd) fu(inp_split) def put(self, args): cmd = args[0] filename = args[1] if not os.path.isfile(filename): print('file:%s is not exists' % filename) return else: filesize = os.path.getsize(filename) head_dic = &#123;'cmd': cmd, 'file_name': os.path.basename(filename), 'file_size': filesize&#125; head_json = json.dumps(head_dic) head_json_bytes = head_json.encode(self.coding) head_struct = struct.pack('i', len(head_json_bytes)) # 发送报头的长度 self.sock.send(head_struct) # 发送真正的报头 self.sock.send(head_json_bytes) # 发送内容 send_size = 0 with open(filename, 'rb') as f: for i in f: self.sock.send(i) send_size += len(i) print(send_size) else: print('upload successful') c = MyClient(('192.168.1.1', 8089))c.run() 服务端 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import jsonimport osimport structimport socket class MyFtp: coding = 'utf-8' address_family = socket.AF_INET socket_type = socket.SOCK_STREAM server_dir = 'D://test' request_size = 5 max_packet_size = 8000 def __init__(self, server_address, server_active=True): self.server_address = server_address self.sock = socket.socket(self.address_family, self.socket_type) if server_active: try: self.server_bind() self.server_listen() except: self.server_close() raise def server_bind(self): self.sock.bind(self.server_address) def server_listen(self): self.sock.listen(self.request_size) def server_close(self): self.sock.close() def get_requset(self): return self.sock.accept() def run(self): while True: self.con,self.client_address = self.get_requset() while True: try: head_struct = self.con.recv(4) if not head_struct: break head_size = struct.unpack('i', head_struct)[0] head_json = self.con.recv(head_size).decode(self.coding) head_content = json.loads(head_json) cmd = head_content['cmd'] if hasattr(self, cmd): fuc = getattr(self, cmd) fuc(head_content) except Exception: break def put(self, head_content): file_path = os.path.normpath(os.path.join(self.server_dir, head_content['file_name'])) file_size = head_content['file_size'] recv_size = 0 with open(file_path, 'wb') as f: while recv_size &lt; file_size: file_content = self.con.recv(self.max_packet_size) f.write(file_content) recv_size += len(file_content) print(recv_size) t = MyFtp(('192.168.1.1', 8089))t.run() socketserver实现并发基于tcp的套接字，关键就是两个循环，一个链接循环，一个通信循环 socketserver模块中分两大类：server类（解决链接问题）和request类（解决通信问题） server类： request类： 继承关系: 以下述代码为例，分析socketserver源码： 123456789101112import socketserver class MyServer(socketserver.BaseRequestHandler): def handle(self): data = self.request.recv(1024) self.request.send(data.upper()) if __name__ == '__main__': obj = socketserver.ThreadingTCPServer(('192.168.1.1', 8014), MyServer) # 循环链接 obj.serve_forever() 查找属性的顺序：ThreadingTCPServer-&gt;ThreadingMixIn-&gt;TCPServer-&gt;BaseServer 123451、实例化得到ftpserver，先找类ThreadingTCPServer的__init__,在TCPServer中找到，进而执行server_bind,server_active2、找ftpserver下的serve_forever,在BaseServer中找到，进而执行self._handle_request_noblock()，该方法同样是在BaseServer中3、执行self._handle_request_noblock()进而执行request, client_address = self.get_request()（就是TCPServer中的self.socket.accept()），然后执行self.process_request(request, client_address)4、在ThreadingMixIn中找到process_request，开启多线程应对并发，进而执行process_request_thread，执行self.finish_request(request, client_address)5、上述四部分完成了链接循环，本部分开始进入处理通讯部分，在BaseServer中找到finish_request,触发我们自己定义的类的实例化，去找__init__方法，而我们自己定义的类没有该方法，则去它的父类也就是BaseRequestHandler中找.... 源码分析总结： 基于tcp的socketserver我们自己定义的类中的 1.self.server即套接字对象 2.self.request即一个链接 3.self.client_address即客户端地址 基于udp的socketserver我们自己定义的类中的 self.request是一个元组（第一个元素是客户端发来的数据，第二部分是服务端的udp套接字对象），如(b’adsf’, &lt;socket.socket fd=200, family=AddressFamily.AF_INET, type=SocketKind.SOCK_DGRAM, proto=0, laddr=(‘127.0.0.1’, 8080)&gt;) 1.self.client_address即客户端地址 2.self.client_address即客户端地址 将之前的服务端改成并发的： 123456789101112131415161718192021222324252627282930313233343536373839404142import jsonimport osimport structimport socketserver class MyFtp(socketserver.BaseRequestHandler): coding = 'utf-8' server_dir = 'D://test' request_size = 5 max_packet_size = 8000 def handle(self): while True: try: head_struct = self.request.recv(4) if not head_struct: break head_size = struct.unpack('i', head_struct)[0] head_json = self.request.recv(head_size).decode(self.coding) head_content = json.loads(head_json) cmd = head_content['cmd'] if hasattr(self, cmd): fuc = getattr(self, cmd) fuc(head_content) except Exception: break def put(self, head_content): file_path = os.path.normpath(os.path.join(self.server_dir, head_content['file_name'])) file_size = head_content['file_size'] recv_size = 0 with open(file_path, 'wb') as f: while recv_size &lt; file_size: file_content = self.request.recv(self.max_packet_size) f.write(file_content) recv_size += len(file_content) print(recv_size) obj = socketserver.ThreadingTCPServer(('192.168.1.1', 8089), MyFtp)obj.serve_forever() UDP的并发 客户端： 12345678910import socket sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)sever_address = ('192.168.1.1', 8089)while True: inp = input("&gt;&gt;&gt;&gt;&gt;&gt;") sock.sendto(inp.encode('utf-8'), sever_address) data, server = sock.recvfrom(1024) print(data.decode('utf-8')) print(server) 服务端 1234567891011import socketserver class MyUdpServer(socketserver.BaseRequestHandler): def handle(self): print(self.request[0]) # 得到的是客户端发来的信息 print(self.request[1]) # 得到一个对象 self.request[1].sendto('草拟吗'.encode('utf-8'), self.client_address) if __name__ == '__main__': obj = socketserver.ThreadingUDPServer(('192.168.1.1', 8089), MyUdpServer) obj.serve_forever()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python软件目录结构规范]]></title>
    <url>%2F2019%2F03%2F01%2Fpython%E8%BD%AF%E4%BB%B6%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[软件目录结构规范软件开发规范 一、为什么要设计好目录结构? 1.可读性高: 不熟悉这个项目的代码的人，一眼就能看懂目录结构，知道程序启动脚本是哪个，测试目录在哪儿，配置文件在哪儿等等。从而非常快速的了解这个项目。 2.可维护性高: 定义好组织规则后，维护者就能很明确地知道，新增的哪个文件和代码应该放在什么目录之下。这个好处是，随着时间的推移，代码/配置的规模增加，项目结构不会混乱，仍然能够组织良好。 二、目录组织方式 关于如何组织一个较好的Python工程目录结构，已经有一些得到了共识的目录结构。 假设你的项目名为ATM 12345678910111213141516171819202122232425262728293031ATM/|-- bin/ 存放项目的一些可执行文件，当然你可以起名script/之类的也行，但bin/更直观。易懂| |-- __init__| |-- start.py 写启动程序||-- core/ 存放项目的所有源代码(核心代码）。(1) 源代码中的所有模块、包都应该放在此目录。不要置于顶层目录。 (2) 其子目录tests/存放单元测试代码； (3) 程序的入口最好命名为main.py。| |-- tests/ | | |-- __init__.py| | |-- test.main.py | || |-- __init__.py| |-- test_main.py| 存放核心逻辑 ||-- conf/ 配置文件| |-- __init__.py| |-- setting.py 写上相关配置||---db/ 数据库文件| |--db.json 写数据库文件| |-- docs/ 存放一些文档| |-- lib/ 库文件，放自定义模块和包| |-- __init__.py| |-- common.py 放常用的功能||-- log/ 日志文件| |-- access.log 写上日志||-- __init__.py|-- README 项目说明文件 运行程序时，在bin目录下执行start.py代码，不可以直接执行core下的模块。 README相关 使用过开源软件的朋友们都知道README可以给软件的使用带来很大的帮助，包括软件介绍、功能定位、安装启动使用方法、有建议或bug怎么联系作者等，其必要性和重要性不言而喻。 因此每一个项目都应该有README说明，好的README应该至少包括以下几方面的内容： 软件的简要介绍、功能定位、适用场景等软件的安装、环境依赖、启动方法、常见使用命令（使用说明）等代码的目录结构说明常见问题说明遇到建议或bug如何联系作者或项目组 如果再编写的更详细，可以考虑简述软件的基本原理。这方面最好的参考就是开源软件的README，如nginx，redis等。！]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>目录规范</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python包]]></title>
    <url>%2F2019%2F03%2F01%2Fpython%E5%8C%85%2F</url>
    <content type="text"><![CDATA[包介绍1、什么是包？ 官网解释Packages are a way of structuring Python’s module namespace by using “dotted module names”包是一种通过使用‘.模块名’来组织python模块名称空间的方式。 具体的：包就是一个包含有__init__.py文件的文件夹，所以其实我们创建包的目的就是为了用文件夹将文件/模块组织起来 需要强调的是： 在python3中，即使包下没有__init__.py文件，import 包仍然不会报错，而在python2中，包下一定要有该文件，否则import 包报错 创建包的目的不是为了运行，而是被导入使用，记住，包只是模块的一种形式而已，包的本质就是一种模块 2、为何要使用包 包的本质就是一个文件夹，那么文件夹唯一的功能就是将文件组织起来 随着功能越写越多，我们无法将所以功能都放到一个文件中，于是我们使用模块去组织功能，而随着模块越来越多，我们就需要用文件夹将模块文件组织起来，以此来提高程序的结构性和可维护性 3、注意事项 1.关于包相关的导入语句也分为import和from … import …两种，但是无论哪种，无论在什么位置，在导入时都必须遵循一个原则：凡是在导入时带点的，点的左边都必须是一个包，否则非法。可以带有一连串的点，如item.subitem.subsubitem,但都必须遵循这个原则。但对于导入后，在使用时就没有这种限制了，点的左边可以是包,模块，函数，类(它们都可以用点的方式调用自己的属性)。 2、import导入文件时，产生名称空间中的名字来源于文件，import 包，产生的名称空间的名字同样来源于文件，即包下的init.py，导入包本质就是在导入该文件 3、包A和包B下有同名模块也不会冲突，如A.a与B.a来自俩个命名空间 包的使用1、示范文件 1234567891011121314151617181920212223glance/ #Top-level package├── __init__.py #Initialize the glance package├── api #Subpackage for api│ ├── __init__.py│ ├── policy.py│ └── versions.py├── cmd #Subpackage for cmd│ ├── __init__.py│ └── manage.py└── db #Subpackage for db ├── __init__.py └── models.py 包所包含的文件内容 文件内容 #policy.py 12def get(): print('from policy.py') #versions.py 12def create_resource(conf): print('from version.py: ',conf) #manage.py 12def main(): print('from manage.py') #models.py 12def register_models(engine): print('from models.py:',engine) 执行文件与示范文件在同级目录下 2、包的使用之import 12import glance.db.modelsglance.db.models.register_models('mysql') 单独导入包名称时不会导入包中所有包含的所有子模块，如 12345678#在与glance同级的test.py中import glanceglance.cmd.manage.main() '''执行结果：AttributeError: module 'glance' has no attribute 'cmd'''' 解决方法： 12345#glance/__init__.pyfrom . import cmd#glance/cmd/__init__.pyfrom . import manage 执行： 123#在于glance同级的test.py中import glanceglance.cmd.manage.main() 3、包的使用之from … import … 需要注意的是from后import导入的模块，必须是明确的一个不能带点，否则会有语法错误，如：from a import b.c是错误语法 4、from glance.api import * 在讲模块时，我们已经讨论过了从一个模块内导入所有，此处我们研究从一个包导入所有。 此处是想从包api中导入所有，实际上该语句只会导入包api下__init__.py文件中定义的名字，我们可以在这个文件中定义__all___: 1234567#在__init__.py中定义x=10 def func(): print('from api.__init.py') __all__=['x','func','policy'] 此时我们在于glance同级的文件中执行from glance.api import *就导入__all__中的内容（versions仍然不能导入）。 5、绝对导入和相对导入 我们的最顶级包glance是写给别人用的，然后在glance包内部也会有彼此之间互相导入的需求，这时候就有绝对导入和相对导入两种方式： 绝对导入：以glance作为起始 相对导入：用.或者..的方式最为起始（只能在一个包中使用，不能用于不同目录内） 例如：我们在glance/api/version.py中想要导入glance/cmd/manage.py 在glance/api/version.py #绝对导入 12from glance.cmd import managemanage.main() #相对导入 12from ..cmd import managemanage.main() 测试结果：注意一定要在于glance同级的文件中测试 6、包以及包所包含的模块都是用来被导入的，而不是被直接执行的。而环境变量都是以执行文件为准的 比如我们想在glance/api/versions.py中导入glance/api/policy.py，有的同学一抽这俩模块是在同一个目录下，十分开心的就去做了，它直接这么做 12345678910111213from glance.api import versions '''执行结果:ImportError: No module named 'policy'''' '''分析:此时我们导入versions在versions.py中执行import policy需要找从sys.path也就是从当前目录找policy.py,这必然是找不到的''' 7、 绝对导入与相对导入总结 绝对导入与相对导入 绝对导入: 以执行文件的sys.path为起始点开始导入,称之为绝对导入 优点: 执行文件与被导入的模块中都可以使用 缺点: 所有导入都是以sys.path为起始点,导入麻烦 相对导入: 参照当前所在文件的文件夹为起始开始查找,称之为相对导入 符号: .代表当前所在文件的文件加,..代表上一级文件夹,…代表上一级的上一级文件夹 优点: 导入更加简单 缺点: 只能在导入包中的模块时才能使用注意: 1.相对导入只能用于包内部模块之间的相互导入,导入者与被导入者都必须存在于一个包内 2.attempted relative import beyond top-level package # 试图在顶级包之外使用相对导入是错误的,言外之意,必须在顶级包内使用相对导入,每增加一个.代表跳到上一级文件夹,而上一级不应该超出顶级包 如果要导入的文件不在同一个包中 例：在a1.py中导入test3 1234import os,sysre = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))) #找到当前文件的上上级目录sys.path.append(re) #添加到路径中import test3 例：如果在test1.py中 12import AA.kill() 这样肯定会报错，想要通过这样调用到A下面的AA下面的a1.py的kill方法，需要在A下面的__init__文件中加入 1from .AA.a1 import kill 这样在test1文件中就能直接使用A.kill() 对于包来说必须要遵守以下原则 特别要注意的是： 可以 用import导入内置或者第三方模块，但是要绝对避免使用import来导入自定义包的子模块，应该使用from… import… 的绝对或者相对导入，且包的相对导入只能用from的形式]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python模块]]></title>
    <url>%2F2019%2F03%2F01%2Fpython%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[模块介绍1、什么是模块？ 模块就是一组功能的集合体，我们的程序可以导入模块来复用模块里的功能。 123456常见的场景：一个模块就是一个包含了一组功能的python文件,比如spam.py，模块名为spam，可以通过import spam使用。在python中，模块的使用方式都是一样的，但其实细说的话，模块可以分为四个通用类别： 1 使用python编写的.py文件 2 已被编译为共享库或DLL的C或C++扩展 3 把一系列模块组织到一起的文件夹（注：文件夹下有一个__init__.py文件，该文件夹称之为包） 4 使用C编写并链接到python解释器的内置模块 2、为何要使用模块？ 1、从文件级别组织程序，更方便管理 随着程序的发展，功能越来越多，为了方便管理，我们通常将程序分成一个个的文件，这样做程序的结构更清晰，方便管理。这时我们不仅仅可以把这些文件当做脚本去执行，还可以把他们当做模块来导入到其他的模块中，实现了功能的重复利用 2、拿来主义，提升开发效率 同样的原理，我们也可以下载别人写好的模块然后导入到自己的项目中使用，这种拿来主义，可以极大地提升我们的开发效率 ps： 如果你退出python解释器然后重新进入，那么你之前定义的函数或者变量都将丢失，因此我们通常将程序写到文件中以便永久保存下来，需要时就通过python test.py方式去执行，此时test.py被称为脚本script。 3、以spam.py为例来介绍模块的使用：文件名spam.py,模块名spam 123456789101112131415#spam.pyprint('from the spam.py') money=1000 def read1(): print('spam模块：',money) def read2(): print('spam模块') read1() def change(): global money money=0 使用模块之import1、模块可以包含可执行的语句和函数的定义 这些语句的目的是初始化模块，它们只在模块名第一次遇到导入import语句时才执行（import语句是可以在程序中的任意位置使用的,且针对同一个模块很import多次,为了防止你重复导入，python的优化手段是：第一次导入后就将模块名加载到内存了，后续的import语句仅是对已经加载到内存中的模块对象增加了一次引用，不会重新执行模块内的语句），如下 12345#test.pyimport spam #只在第一次导入时才执行spam.py内代码,此处的显式效果是只打印一次'from the spam.py',当然其他的顶级代码也都被执行了,只不过没有显示效果.import spamimport spamimport spam 执行结果：from the spam.py 2、在第一次导入模块时会做三件事，重复导入会直接引用内存中已经加载好的结果 1.为源文件(spam模块)创建新的名称空间，在spam中定义的函数和方法若是使用到了global时访问的就是这个名称空间。 2.在新创建的命名空间中执行模块中包含的代码，见初始导入import spam 提示:导入模块时到底执行了什么？ In fact function definitions are also ‘statements’ that are ‘executed’; the execution of a module-level function definition enters the function name in the module’s global symbol table. 事实上函数定义也是“被执行”的语句，模块级别函数定义的执行将函数名放 入模块全局名称空间表，用globals()可以查看 3.创建名字spam来引用该命名空间 这个名字和变量名没什么区别，都是‘第一类的’，且使用spam.名字的方式 可以访问spam.py文件中定义的名字，spam.名字与test.py中的名字来自 两个完全不同的地方。 3、被导入模块有独立的名称空间 每个模块都是一个独立的名称空间，定义在这个模块中的函数，把这个模块的名称空间当做全局名称空间，这样我们在编写自己的模块时，就不用担心我们定义在自己模块中全局变量会在被导入时，与使用者的全局变量冲突 测试一:money与spam.money不冲突 12345678910#test.pyimport spam money=10print(spam.money) '''执行结果：from the spam.py1000''' 测试二：read1与spam.read1不冲突 1234567891011#test.pyimport spamdef read1(): print('========')spam.read1() '''执行结果:from the spam.pyspam模块：1000''' 测试三：执行spam.change()操作的全局变量money仍然是spam中的 1234567891011#test.pyimport spammoney=1spam.change()print(money) '''执行结果：from the spam.py1''' 4、为模块名起别名 为已经导入的模块起别名的方式对编写可扩展的代码很有用 12import spam as smprint(sm.money) 有两中sql模块mysql和oracle，根据用户的输入，选择不同的sql功能 123456789101112131415#mysql.pydef sqlparse(): print('from mysql sqlparse')#oracle.pydef sqlparse(): print('from oracle sqlparse') #test.pydb_type=input('&gt;&gt;: ')if db_type == 'mysql': import mysql as dbelif db_type == 'oracle': import oracle as db db.sqlparse() 假设有两个模块xmlreader.py和csvreader.py，它们都定义了函数read_data(filename):用来从文件中读取一些数据，但采用不同的输入格式。可以编写代码来选择性地挑选读取模块 12345if file_format == 'xml': import xmlreader as readerelif file_format == 'csv': import csvreader as readerdata=reader.read_date(filename) 5、在一行导入多个模块（不推荐） 1import sys,os,re 使用模块之from … import…1、from…import…的使用 1from spam import read1,read2 2、from…import 与import的对比 唯一的区别就是：使用from…import…则是将spam中的名字直接导入到当前的名称空间中，所以在当前名称空间中，直接使用名字就可以了、无需加前缀：spam. from...import...的方式有好处也有坏处 好处：使用起来方便了 坏处：容易与当前执行文件中的名字冲突 验证一：当前位置直接使用read1和read2就好了，执行时，仍然以spam.py文件全局名称空间 123456789101112131415161718192021222324#测试一：导入的函数read1，执行时仍然回到spam.py中寻找全局变量money#test.pyfrom spam import read1money=1000read1()'''执行结果:from the spam.pyspam-&gt;read1-&gt;money 1000''' #测试二:导入的函数read2，执行时需要调用read1(),仍然回到spam.py中找read1()#test.pyfrom spam import read2def read1(): print('==========')read2() '''执行结果:from the spam.pyspam-&gt;read2 calling readspam-&gt;read1-&gt;money 1000''' 验证二：如果当前有重名read1或者read2，那么会有覆盖效果 12345678910#test.pyfrom spam import read1def read1(): print('==========')read1()'''执行结果:from the spam.py==========''' 验证三：导入的方法在执行时，始终是以源文件为准的 12345678910from spam import money,read1money=100 #将当前位置的名字money绑定到了100print(money) #打印当前的名字read1() #读取spam.py中的名字money,仍然为1000 '''from the spam.py100spam-&gt;read1-&gt;money 1000''' 3、也支持as from spam import read1 as read 4、一行导入多个名字 from spam import read1,read2,money 5、from…import * from spam import * 把spam中所有的不是以下划线(_)开头的名字都导入到当前位置 大部分情况下我们的python程序不应该使用这种导入方式，因为*你不知道你导入什么名字，很有可能会覆盖掉你之前已经定义的名字。而且可读性极其的差，在交互式环境中导入时没有问题。 可以使用__all__来控制*（用来发布新版本），在spam.py中新增一行 __all__=[&#39;money&#39;,&#39;read1&#39;]#这样在另外一个文件中用from spam import *就这能导入列表中规定的两个名字 模块的重载 (了解)考虑到性能的原因，每个模块只被导入一次,放入字典sys.module中，如果你改变了模块的内容，你必须重启程序，python不支持重新加载或卸载之前导入的模块， 有的同学可能会想到直接从sys.module中删除一个模块不就可以卸载了吗，注意了，你删了sys.module中的模块对象仍然可能被其他程序的组件所引用，因而不会被清楚。 特别的对于我们引用了这个模块中的一个类，用这个类产生了很多对象，因而这些对象都有关于这个模块的引用。 编写好的一个python文件可以有两种用途： 一：脚本，一个文件就是整个程序，用来被执行 二：模块，文件中存放着一堆功能，用来被导入使用 python为我们内置了全局变量__name__， 当文件被当做脚本执行时：__name__ 等于__main__ 当文件被当做模块导入时：__name__等于模块名 作用：用来控制.py文件在不同的应用场景下执行不同的逻辑 if __name__ == &#39;__main__&#39;: 模块搜索路径模块的查找顺序是：内存中已经加载的模块-&gt;内置模块-&gt;sys.path路径中包含的模块 搜索路径：当一个命名为spam的模块被导入时 解释器首先会从内建模块中寻找该名字 找不到，则去sys.path中找该名字 sys.path从以下位置初始化 1 执行文件所在的当前目录 2 PTYHONPATH（包含一系列目录名，与shell变量PATH语法一样） 3 依赖安装时默认指定的 注意：在支持软连接的文件系统中，执行脚本所在的目录是在软连接之后被计算的，换句话说，包含软连接的目录不会被添加到模块的搜索路径中 在初始化后，我们也可以在python程序中修改sys.path,执行文件所在的路径默认是sys.path的第一个目录，在所有标准库路径的前面。这意味着，当前目录是优先于标准库目录的，需要强调的是：我们自定义的模块名不要跟python标准库的模块名重复，除非你是故意的。 编译python文件（了解）为了提高加载模块的速度，强调强调强调：提高的是加载速度而绝非运行速度。python解释器会在pycache目录中下缓存每个模块编译后的版本，格式为：module.version.pyc。通常会包含python的版本号。例如，在CPython3.3版本下，spam.py模块会被缓存成pycache/spam.cpython-33.pyc。这种命名规范保证了编译后的结果多版本共存。 Python检查源文件的修改时间与编译的版本进行对比，如果过期就需要重新编译。这是完全自动的过程。并且编译的模块是平台独立的，所以相同的库可以在不同的架构的系统之间共享，即pyc使一种跨平台的字节码，类似于JAVA火.NET,是由python虚拟机来执行的，但是pyc的内容跟python的版本相关，不同的版本编译后的pyc文件不同，2.5编译的pyc文件不能到3.5上执行，并且pyc文件是可以反编译的，因而它的出现仅仅是用来提升模块的加载速度的，不是用来加密的。 python解释器在以下两种情况下不检测缓存1 如果是在命令行中被直接导入模块，则按照这种方式，每次导入都会重新编译，并且不会存储编译后的结果（python3.3以前的版本应该是这样） 1python -m spam.py 2 如果源文件不存在，那么缓存的结果也不会被使用，如果想在没有源文件的情况下来使用编译后的结果，则编译后的结果必须在源目录下 123456sh-3.2# ls__pycache__ spam.pysh-3.2# rm -rf spam.py sh-3.2# mv __pycache__/spam.cpython-36.pyc ./spam.pycsh-3.2# python3 spam.pyc spam 提示：1.模块名区分大小写，foo.py与FOO.py代表的是两个模块2.你可以使用-O或者-OO转换python命令来减少编译模块的大小 -O转换会帮你去掉assert语句 -OO转换会帮你去掉assert语句和__doc__文档字符串 由于一些程序可能依赖于assert语句或文档字符串，你应该在在确认需要 的情况下使用这些选项。3.在速度上从.pyc文件中读指令来执行不会比从.py文件中读指令执行更快，只有在模块被加载时，.pyc文件才是更快的 4.只有使用import语句是才将文件自动编译为.pyc文件，在命令行或标准输入中指定运行脚本则不会生成这类文件，因而我们可以使用compieall模块为一个目录中的所有模块创建.pyc文件 模块可以作为一个脚本（使用python -m compileall）编译Python源python -m compileall /module_directory 递归着编译如果使用python -O -m compileall /module_directory -l则只一层 命令行里使用compile()函数时，自动使用python -O -m compileall 详见：https://docs.python.org/3/library/compileall.html#module-compileall]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python异常处理]]></title>
    <url>%2F2019%2F03%2F01%2Fpython%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[什么是异常异常就是程序运行时发生错误的信号（在程序出现错误时，则会产生一个异常，若程序没有处理它，则会抛出该异常，程序的运行也随之终止），在python中,错误触发的异常如下 而错误分成两种 1.语法错误（这种错误，根本过不了python解释器的语法检测，必须在程序执行前就改正） 2.逻辑错误 异常的种类 在python中不同的异常可以用不同的类型（python中统一了类与类型，类型即类）去标识，一个异常标识一种错误 常用异常AttributeError 试图访问一个对象没有的树形，比如foo.x，但是foo没有属性xIOError 输入/输出异常；基本上是无法打开文件ImportError 无法引入模块或包；基本上是路径问题或名称错误IndentationError 语法错误（的子类） ；代码没有正确对齐IndexError 下标索引超出序列边界，比如当x只有三个元素，却试图访问x[5]KeyError 试图访问字典里不存在的键KeyboardInterrupt Ctrl+C被按下NameError 使用一个还未被赋予对象的变量SyntaxError Python代码非法，代码不能编译(个人认为这是语法错误，写错了）TypeError 传入对象类型与要求的不符合UnboundLocalError 试图访问一个还未被设置的局部变量，基本上是由于另有一个同名的全局变量，导致你以为正在访问它 ValueError 传入一个调用者不期望的值，即使值的类型是正确的 更多异常ArithmeticErrorAssertionErrorAttributeErrorBaseExceptionBufferErrorBytesWarningDeprecationWarningEnvironmentErrorEOFErrorExceptionFloatingPointErrorFutureWarningGeneratorExitImportErrorImportWarningIndentationErrorIndexErrorIOErrorKeyboardInterruptKeyErrorLookupErrorMemoryErrorNameErrorNotImplementedErrorOSErrorOverflowErrorPendingDeprecationWarningReferenceErrorRuntimeErrorRuntimeWarningStandardErrorStopIterationSyntaxErrorSyntaxWarningSystemErrorSystemExitTabErrorTypeErrorUnboundLocalErrorUnicodeDecodeErrorUnicodeEncodeErrorUnicodeErrorUnicodeTranslateErrorUnicodeWarningUserWarningValueErrorWarningZeroDivisionError 异常处理为了保证程序的健壮性与容错性，即在遇到错误时程序不会崩溃，我们需要对异常进行处理， 如果错误发生的条件是可预知的，我们需要用if进行处理：在错误发生之前进行预防 12345678AGE=10while True: age=input('&gt;&gt;: ').strip() if age.isdigit(): #只有在age为字符串形式的整数时,下列代码才不会出错,该条件是可预知的 age=int(age) if age == AGE: print('you got it') break 如果错误发生的条件是不可预知的，则需要用到try…except：在错误发生之后进行处理 #基本语法为try: 被检测的代码块except 异常类型： try中一旦检测到异常，就执行这个位置的逻辑举例： 12345678910try: f=open('a.txt') g=(line.strip() for line in f) print(next(g)) print(next(g)) print(next(g)) print(next(g)) print(next(g))except StopIteration: f.close() 1 异常类只能用来处理指定的异常情况，如果非指定异常则无法处理 12345s1 = 'hello'try: int(s1)except IndexError as e: # 未捕获到异常，程序直接报错 print e 2 多分支 123456789s1 = 'hello'try: int(s1)except IndexError as e: print(e)except KeyError as e: print(e)except ValueError as e: print(e) 3 万能异常Exception 12345s1 = 'hello'try: int(s1)except Exception as e: print(e) 4 多分支异常与万能异常4.1 如果你想要的效果是，无论出现什么异常，我们统一丢弃，或者使用同一段代码逻辑去处理他们，那么骚年，大胆的去做吧，只有一个Exception就足够了。4.2 如果你想要的效果是，对于不同的异常我们需要定制不同的处理逻辑，那就需要用到多分支了。 5 也可以在多分支后来一个Exception 1234567891011s1 = 'hello'try: int(s1)except IndexError as e: print(e)except KeyError as e: print(e)except ValueError as e: print(e)except Exception as e: print(e) 6 异常的其他机构 123456789101112131415s1 = 'hello'try: int(s1)except IndexError as e: print(e)except KeyError as e: print(e)except ValueError as e: print(e)#except Exception as e:# print(e)else: print('try内代码块没有异常则执行我')finally: print('无论异常与否,都会执行该模块,通常是进行清理工作') 7 主动触发异常 1234try: raise TypeError('类型错误')except Exception as e: print(e) 8 自定义异常 12345678910class EgonException(BaseException): def __init__(self,msg): self.msg=msg def __str__(self): return self.msg try: raise EgonException('类型错误')except EgonException as e: print(e) 9 断言:assert 条件 12assert 1 == 1 assert 1 == 2 10 总结try..except 1：把错误处理和真正的工作分开来2：代码更易组织，更清晰，复杂的工作任务更容易实现；3：毫无疑问，更安全了，不至于由于一些小的疏忽而使程序意外崩溃了； 什么时候用异常处理有的同学会这么想，学完了异常处理后，好强大，我要为我的每一段程序都加上try…except，干毛线去思考它会不会有逻辑错误啊，这样就很好啊，多省脑细胞===》2B青年欢乐多 首先try…except是你附加给你的程序的一种异常处理的逻辑，与你的主要的工作是没有关系的，这种东西加的多了，会导致你的代码可读性变差 然后异常处理本就不是你2b逻辑的擦屁股纸，只有在错误发生的条件无法预知的情况下，才应该加上try…except]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>异常处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python常用模块]]></title>
    <url>%2F2019%2F03%2F01%2Fpython%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[time模块时间表示形式在Python中，通常有这三种方式来表示时间：时间戳、元组(struct_time)、格式化的时间字符串：(1)时间戳(timestamp) ：通常来说，时间戳表示的是从1970年1月1日00:00:00开始按秒计算的偏移量。我们运行“type(time.time())”，返回的是float类型。 (2)格式化的时间字符串(Format String)： ‘1988-03-16’ (3)元组(struct_time) ：struct_time元组共有9个元素共九个元素:(年，月，日，时，分，秒，一年中第几周，一年中第几天等） 12345678910111213141516# &lt;1&gt; 时间戳 &gt;&gt;&gt; import time&gt;&gt;&gt; time.time() #--------------返回当前时间的时间戳1493136727.099066 # &lt;2&gt; 时间字符串&gt;&gt;&gt; time.strftime("%Y-%m-%d %X")'2017-04-26 00:32:18' # &lt;3&gt; 时间元组 &gt;&gt;&gt; time.localtime()time.struct_time(tm_year=2017, tm_mon=4, tm_mday=26, tm_hour=0, tm_min=32, tm_sec=42, tm_wday=2, tm_yday=116, tm_isdst=0) 小结：时间戳是计算机能够识别的时间；时间字符串是人能够看懂的时间；元组则是用来操作时间的 几种时间形式的转换(1) #一 时间戳&lt;－－－－&gt;结构化时间： localtime/gmtime mktime 1234time.localtime(3600*24)time.gmtime(3600*24)time.mktime(time.localtime()) #字符串时间&lt;－－－－&gt;结构化时间： strftime／strptime 12ime.strftime("%Y-%m-%d %X", time.localtime())time.strptime("2017-03-16","%Y-%m-%d") (2) 1234&gt;&gt;&gt;time.asctime(time.localtime(312343423))'Sun Nov 25 10:03:43 1979'&gt;&gt;&gt;time.ctime(312343423)'Sun Nov 25 10:03:43 1979' random模块123456789101112131415161718import random print(random.random())#(0,1)----float 大于0且小于1之间的小数 print(random.randint(1,3)) #[1,3] 大于等于1且小于等于3之间的整数 print(random.randrange(1,3)) #[1,3) 大于等于1且小于3之间的整数 print(random.choice([1,'23',[4,5]]))#1或者23或者[4,5]，choice()中只能放列表格式 print(random.sample([1,'23',[4,5]],2))#列表元素任意2个组合 print(random.uniform(1,3))#大于1小于3的小数，如1.927109612082716 item=[1,3,5,7,9]random.shuffle(item) #打乱item的顺序,相当于"洗牌"print(item) 实例：5位随机验证码 12345678910111213 import random def test(): s = "" for i in range(5): r1 = random.randint(0, 9) r2 = chr(random.randint(65, 90)) #ASCII表对应A-Z r3 = chr(random.randint(97, 122)) #ASCII表对应a-z r4 = random.choice([str(r1), r2, r3]) #三选一 s += r4 return s print(test()) hash模块1.什么叫hash:hash是一种算法,3.x里代替了md5模块和sha模块，主要提供 SHA1, SHA224, SHA256, SHA384, SHA512 ，MD5 算法，该算法接受传入的内容，经过运算得到一串hash值 2.hash值的特点是：1 只要传入的内容一样，得到的hash值必然一样=====&gt;要用明文传输密码文件完整性校验2 不能由hash值返解成内容=======》把密码做成hash值，不应该在网络传输明文密码 3 只要使用的hash算法不变，无论校验的内容有多大，得到的hash值长度是固定的 hash算法就像一座工厂，工厂接收你送来的原材料（可以用m.update()为工厂运送原材料），经过加工返回的产品就是hash值 12345678910111213141516171819import hashlib m=hashlib.md5()# m=hashlib.sha256() m.update('hello'.encode('utf8'))print(m.hexdigest()) #5d41402abc4b2a76b9719d911017c592 m.update('alvin'.encode('utf8')) print(m.hexdigest()) #92a7e713c30abbb0319fa07da2a5c4af m2=hashlib.md5()m2.update('helloalvin'.encode('utf8'))print(m2.hexdigest()) #92a7e713c30abbb0319fa07da2a5c4af '''注意：把一段很长的数据update多次，与一次update这段长数据，得到的结果一样但是update多次为校验大文件提供了可能。''' 以上加密算法虽然依然非常厉害，但时候存在缺陷，即：通过撞库可以反解。所以，有必要对加密算法中添加自定义key再来做加密。 12345import hashlib hash = hashlib.sha256('898oaFs09f'.encode('utf8'))hash.update('alvin'.encode('utf8'))print (hash.hexdigest())#e79e68f070cdedcfe63eaf1a2e92c83b4cfb1b5c6bc452d214c1b7e77cdfd1c7 模拟撞库破解密码 123456789101112131415161718192021222324import hashlibpasswds=[ 'alex3714', 'alex1313', 'alex94139413', 'alex123456', '123456alex', 'a123lex', ]def make_passwd_dic(passwds): dic=&#123;&#125; for passwd in passwds: m=hashlib.md5() m.update(passwd.encode('utf-8')) dic[passwd]=m.hexdigest() return dic def break_code(cryptograph,passwd_dic): for k,v in passwd_dic.items(): if v == cryptograph: print('密码是===&gt;\033[46m%s\033[0m' %k) cryptograph='aee949757a2e698417463d47acac93df'break_code(cryptograph,make_passwd_dic(passwds)) os模块123456789101112131415161718192021222324252627282930os.getcwd() #获取当前工作目录，即当前python脚本工作的目录路径os.chdir("dirname") #改变当前脚本工作目录；相当于shell下cdos.curdir #返回当前目录: ('.')os.pardir #获取当前目录的父目录字符串名：('..')os.makedirs('dirname1/dirname2') #可生成多层递归目录os.removedirs('dirname1') #若目录为空，则删除，并递归到上一级目录，如若也为空，则删除，依此类推os.mkdir('dirname') #生成单级目录；相当于shell中mkdir dirnameos.rmdir('dirname') #删除单级空目录，若目录不为空则无法删除，报错；相当于shell中rmdir dirnameos.listdir('dirname') #列出指定目录下的所有文件和子目录，包括隐藏文件，并以列表方式打印os.remove() #删除一个文件os.rename("oldname","newname") #重命名文件/目录os.stat('path/filename') #获取文件/目录信息os.sep #输出操作系统特定的路径分隔符，win下为"\\",Linux下为"/"os.linesep #输出当前平台使用的行终止符，win下为"\t\n",Linux下为"\n"os.pathsep #输出用于分割文件路径的字符串 win下为;,Linux下为:os.name #输出字符串指示当前使用平台。win-&gt;'nt'; Linux-&gt;'posix'os.system("bash command") #运行shell命令，直接显示os.environ #获取系统环境变量os.path.abspath(path) #返回path规范化的绝对路径os.path.split(path) #将path分割成目录和文件名二元组返回os.path.dirname(path) #返回path的目录。其实就是os.path.split(path)的第一个元素os.path.basename(path) #返回path最后的文件名。如何path以／或\结尾，那么就会返回空值。即os.path.split(path)的第二个元素os.path.exists(path) #如果path存在，返回True；如果path不存在，返回Falseos.path.isabs(path) #如果path是绝对路径，返回Trueos.path.isfile(path) #如果path是一个存在的文件，返回True。否则返回Falseos.path.isdir(path) #如果path是一个存在的目录，则返回True。否则返回Falseos.path.join(path1[, path2[, ...]]) #将多个路径组合后返回，第一个绝对路径之前的参数将被忽略os.path.getatime(path) #返回path所指向的文件或者目录的最后存取时间os.path.getmtime(path) #返回path所指向的文件或者目录的最后修改时间os.path.getsize(path) #返回path的大小 sys模块1234567sys.argv 命令行参数List，第一个元素是程序本身路径sys.exit(n) 退出程序，正常退出时exit(0)sys.version 获取Python解释程序的版本信息sys.maxint 最大的Int值sys.path 返回模块的搜索路径，初始化时使用PYTHONPATH环境变量的值sys.platform 返回操作系统平台名称 logging模块1 函数式简单配置123456import logging logging.debug('debug message') logging.info('info message') logging.warning('warning message') logging.error('error message') logging.critical('critical message') 默认情况下Python的logging模块将日志打印到了标准输出中，且只显示了大于等于WARNING级别的日志，这说明默认的日志级别设置为WARNING（日志级别等级CRITICAL &gt; ERROR &gt; WARNING &gt; INFO &gt; DEBUG），默认的日志格式为日志级别：Logger名称：用户输出消息。 灵活配置日志级别，日志格式，输出位置: 123456789101112import logging logging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s', datefmt='%a, %d %b %Y %H:%M:%S', filename='/tmp/test.log', filemode='w') logging.debug('debug message') logging.info('info message') logging.warning('warning message') logging.error('error message') logging.critical('critical message') 配置参数： 12345678910111213141516171819202122232425logging.basicConfig()函数中可通过具体参数来更改logging模块默认行为，可用参数有： filename：用指定的文件名创建FiledHandler，这样日志会被存储在指定的文件中。filemode：文件打开方式，在指定了filename时使用这个参数，默认值为“a”还可指定为“w”。format：指定handler使用的日志显示格式。datefmt：指定日期时间格式。level：设置rootlogger（后边会讲解具体概念）的日志级别stream：用指定的stream创建StreamHandler。可以指定输出到sys.stderr,sys.stdout或者文件(f=open(‘test.log’,’w’))，默认为sys.stderr。若同时列出了filename和stream两个参数，则stream参数会被忽略。 format参数中可能用到的格式化串：%(name)s Logger的名字%(levelno)s 数字形式的日志级别%(levelname)s 文本形式的日志级别%(pathname)s 调用日志输出函数的模块的完整路径名，可能没有%(filename)s 调用日志输出函数的模块的文件名%(module)s 调用日志输出函数的模块名%(funcName)s 调用日志输出函数的函数名%(lineno)d 调用日志输出函数的语句所在的代码行%(created)f 当前时间，用UNIX标准的表示时间的浮 点数表示%(relativeCreated)d 输出日志信息时的，自Logger创建以 来的毫秒数%(asctime)s 字符串形式的当前时间。默认格式是 “2003-07-08 16:49:45,896”。逗号后面的是毫秒%(thread)d 线程ID。可能没有%(threadName)s 线程名。可能没有%(process)d 进程ID。可能没有%(message)s用户输出的消息 2 logger对象配置（推荐）123456789101112131415161718192021222324252627282930import logging def test(): # 1、创建一个logger log = logging.getLogger() log.setLevel(logging.DEBUG) # 2.创建一个handler，用于写入日志文件 file = logging.FileHandler("test.txt") file.setLevel(logging.DEBUG) # 再创建一个handler，用于输出到控制台 stream = logging.StreamHandler() stream.setLevel(logging.DEBUG) # 3.定义handler的输出格式（formatter） formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s") # 4.给handler添加formatter file.setFormatter(formatter) stream.setFormatter(formatter) # 5.给logger添加handler log.addHandler(file) # logger对象可以添加多个file和stream对象 log.addHandler(stream) return log l = test()l.debug("debug")l.info("info")l.warning("warning")l.error("error")l.critical("critical") ogging库提供了多个组件：Logger、Handler、Filter、Formatter。Logger对象提供应用程序可直接使用的接口，Handler发送日志到适当的目的地，Filter提供了过滤日志信息的方法，Formatter指定日志显示格式。另外，可以通过：logger.setLevel(logging.Debug)设置级别,当然，也可以通过 fh.setLevel(logging.Debug)单对文件流设置某个级别。 序列化模块什么是序列化？我们把对象(变量)从内存中变成可存储或传输的过程称之为序列化，在Python中叫pickling，在其他语言中也被称之为serialization，marshalling，flattening等等，都是一个意思。序列化之后，就可以把序列化后的内容写入磁盘，或者通过网络传输到别的机器上。反过来，把变量内容从序列化的对象重新读到内存里称之为反序列化，即unpickling。 json模块如果我们要在不同的编程语言之间传递对象，就必须把对象序列化为标准格式，比如XML，但更好的方法是序列化为JSON，因为JSON表示出来就是一个字符串，可以被所有语言读取，也可以方便地存储到磁盘或者通过网络传输。JSON不仅是标准格式，并且比XML更快，而且可以直接在Web页面中读取，非常方便。 JSON表示的对象就是标准的JavaScript语言的对象一个子集，JSON和Python内置的数据类型对应如下： python在文本中的使用： 123456789101112131415161718192021import json dic=&#123;'name':'alvin','age':23,'sex':'male'&#125;print(type(dic))#&lt;class 'dict'&gt; data=json.dumps(dic)print("type",type(data))#&lt;class 'str'&gt;print("data",data) f=open('序列化对象','w')f.write(data) #-------------------等价于json.dump(dic,f)f.close() #-----------------------------反序列化&lt;br&gt;import jsonf=open('序列化对象')new_data=json.loads(f.read())# 等价于data=json.load(f) print(type(new_data)) pickle模块 12345678910111213141516171819202122##----------------------------序列化import pickle dic=&#123;'name':'alvin','age':23,'sex':'male'&#125; print(type(dic))#&lt;class 'dict'&gt; j=pickle.dumps(dic)print(type(j))#&lt;class 'bytes'&gt; f=open('序列化对象_pickle','wb')#注意是w是写入str,wb是写入bytes,j是'bytes'f.write(j) #-------------------等价于pickle.dump(dic,f) f.close()#-------------------------反序列化import picklef=open('序列化对象_pickle','rb') data=pickle.loads(f.read())# 等价于data=pickle.load(f) print(data['age']) Pickle的问题和所有其他编程语言特有的序列化问题一样，就是它只能用于Python，并且可能不同版本的Python彼此都不兼容，因此，只能用Pickle保存那些不重要的数据，不能成功地反序列化也没关系 shelve模块shelve模块比pickle模块简单，只有一个open函数，返回类似字典的对象，可读可写;key必须为字符串，而值可以是python所支持的数据类型 123456789import shelve f=shelve.open(r'sheve.txt')# f['stu1_info']=&#123;'name':'egon','age':18,'hobby':['piao','smoking','drinking']&#125;# f['stu2_info']=&#123;'name':'gangdan','age':53&#125;# f['school_info']=&#123;'website':'http://www.pypy.org','city':'beijing'&#125; print(f['stu1_info']['hobby'])f.close() re模块一：什么是正则？ 正则就是用一些具有特殊含义的符号组合到一起（称为正则表达式）来描述字符或者字符串的方法。或者说：正则就是用来描述一类事物的规则。（在Python中）它内嵌在Python中，并通过 re 模块实现。正则表达式模式被编译成一系列的字节码，然后由用 C 编写的匹配引擎执行。 生活中处处都是正则： 比如我们描述：4条腿 你可能会想到的是四条腿的动物或者桌子，椅子等 继续描述：4条腿，活的 就只剩下四条腿的动物这一类了 二：常用匹配模式(元字符) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091# =================================匹配模式=================================#一对一的匹配# 'hello'.replace(old,new)# 'hello'.find('pattern') #正则匹配import re#\w与\Wprint(re.findall('\w','hello egon 123')) #['h', 'e', 'l', 'l', 'o', 'e', 'g', 'o', 'n', '1', '2', '3']print(re.findall('\W','hello egon 123')) #[' ', ' '] #\s与\Sprint(re.findall('\s','hello egon 123')) #[' ', ' ', ' ', ' ']print(re.findall('\S','hello egon 123')) #['h', 'e', 'l', 'l', 'o', 'e', 'g', 'o', 'n', '1', '2', '3'] #\n \t都是空,都可以被\s匹配print(re.findall('\s','hello \n egon \t 123')) #[' ', '\n', ' ', ' ', '\t', ' '] #\n与\tprint(re.findall(r'\n','hello egon \n123')) #['\n']print(re.findall(r'\t','hello egon\t123')) #['\n'] #\d与\Dprint(re.findall('\d','hello egon 123')) #['1', '2', '3']print(re.findall('\D','hello egon 123')) #['h', 'e', 'l', 'l', 'o', ' ', 'e', 'g', 'o', 'n', ' '] #\A与\Zprint(re.findall('\Ahe','hello egon 123')) #['he'],\A==&gt;^print(re.findall('123\Z','hello egon 123')) #['he'],\Z==&gt;$ #^与$print(re.findall('^h','hello egon 123')) #['h']print(re.findall('3$','hello egon 123')) #['3'] # 重复匹配：| . | * | ? | .* | .*? | + | &#123;n,m&#125; |#.print(re.findall('a.b','a1b')) #['a1b']print(re.findall('a.b','a1b a*b a b aaab')) #['a1b', 'a*b', 'a b', 'aab']print(re.findall('a.b','a\nb')) #[]print(re.findall('a.b','a\nb',re.S)) #['a\nb']print(re.findall('a.b','a\nb',re.DOTALL)) #['a\nb']同上一条意思一样 #*print(re.findall('ab*','bbbbbbb')) #[]print(re.findall('ab*','a')) #['a']print(re.findall('ab*','abbbb')) #['abbbb'] #?print(re.findall('ab?','a')) #['a']print(re.findall('ab?','abbb')) #['ab']#匹配所有包含小数在内的数字print(re.findall('\d+\.?\d*',"asdfasdf123as1.13dfa12adsf1asdf3")) #['123', '1.13', '12', '1', '3'] #.*默认为贪婪匹配print(re.findall('a.*b','a1b22222222b')) #['a1b22222222b'] #.*?为非贪婪匹配：推荐使用print(re.findall('a.*?b','a1b22222222b')) #['a1b'] #+print(re.findall('ab+','a')) #[]print(re.findall('ab+','abbb')) #['abbb'] #&#123;n,m&#125;print(re.findall('ab&#123;2&#125;','abbb')) #['abb']print(re.findall('ab&#123;2,4&#125;','abbb')) #['abb']print(re.findall('ab&#123;1,&#125;','abbb')) #'ab&#123;1,&#125;' ===&gt; 'ab+'print(re.findall('ab&#123;0,&#125;','abbb')) #'ab&#123;0,&#125;' ===&gt; 'ab*' #[]print(re.findall('a[1*-]b','a1b a*b a-b')) #[]内的都为普通字符了，且如果-没有被转意的话，应该放到[]的开头或结尾print(re.findall('a[^1*-]b','a1b a*b a-b a=b')) #[]内的^代表的意思是取反，所以结果为['a=b']print(re.findall('a[0-9]b','a1b a*b a-b a=b')) # 结果为['a1b']print(re.findall('a[a-z]b','a1b a*b a-b a=b aeb')) # 结果为['aeb']print(re.findall('a[a-zA-Z]b','a1b a*b a-b a=b aeb aEb')) # 结果为['aeb','aEb'] #\# print(re.findall('a\\c','a\c')) #对于正则来说a\\c确实可以匹配到a\c,但是在python解释器读取a\\c时，会发生转义，然后交给re去执行，所以抛出异常print(re.findall(r'a\\c','a\c')) #r代表告诉解释器使用rawstring，即原生字符串，把我们正则内的所有符号都当普通字符处理，不要转义print(re.findall('a\\\\c','a\c')) #同上面的意思一样，和上面的结果一样都是['a\\c'] #():分组print(re.findall('ab+','ababab123')) #['ab', 'ab', 'ab']print(re.findall('(ab)+123','ababab123')) #['ab']，匹配到末尾的ab123中的abprint(re.findall('(?:ab)+123','ababab123')) #findall的结果不是匹配的全部内容，而是组内的内容,?:可以让结果为匹配的全部内容print(re.findall('href="(.*?)"','&lt;a href="http://www.baidu.com"&gt;点击&lt;/a&gt;'))#['http://www.baidu.com']print(re.findall('href="(?:.*?)"','&lt;a href="http://www.baidu.com"&gt;点击&lt;/a&gt;'))#['href="http://www.baidu.com"']# 给分组加上名字，可以用名字来取组值s = re.search('(?P&lt;w&gt;\w+)\.(?P&lt;fuck&gt;\w+)\.(?P&lt;com&gt;\w+)', 'www.buleone.com')print(s.group('fuck'))#|print(re.findall('compan(?:y|ies)','Too many companies have gone bankrupt, and the next one is my company')) re模块提供的方法介绍 1234567891011121314151617181920212223242526import re#1print(re.findall('e','alex make love') ) #['e', 'e', 'e'],返回所有满足匹配条件的结果,放在列表里#2print(re.search('e','alex make love').group()) #e,只到找到第一个匹配然后返回一个包含匹配信息的对象,该对象可以通过调用group()方法得到匹配的字符串,如果字符串没有匹配，则返回None。 #3print(re.match('e','alex make love')) #None,同search,不过在字符串开始处进行匹配,完全可以用search+^代替match #4print(re.split('[ab]','abcd')) #['', '', 'cd']，先按'a'分割得到''和'bcd',再对''和'bcd'分别按'b'分割 #5print('===&gt;',re.sub('a','A','alex make love')) #===&gt; Alex mAke love，不指定n，默认替换所有print('===&gt;',re.sub('a','A','alex make love',1)) #===&gt; Alex make loveprint('===&gt;',re.sub('a','A','alex make love',2)) #===&gt; Alex mAke loveprint('===&gt;',re.sub('^(\w+)(.*?\s)(\w+)(.*?\s)(\w+)(.*?)$',r'\5\2\3\4\1','alex make love')) #===&gt; love make alex print('===&gt;',re.subn('a','A','alex make love')) #===&gt; ('Alex mAke love', 2),结果带有总共替换的个数 #6obj=re.compile('\d&#123;2&#125;') print(obj.search('abc123eeee').group()) #12print(obj.findall('abc123eeee')) #['12'],重用了obj]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>常用模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python面向对象高级]]></title>
    <url>%2F2019%2F02%2F27%2Fpython%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E9%AB%98%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[isinstance(obj,cls)和issubclass(sub,super)isinstance(obj,cls)检查是否obj是否是类 cls 的对象12345class Foo(object): pass obj = Foo() isinstance(obj, Foo) issubclass(sub, super)检查sub类是否是 super 类的派生类1234567class Foo(object): pass class Bar(Foo): pass issubclass(Bar, Foo) 反射1 什么是反射反射的概念是由Smith在1982年首次提出的，主要是指程序可以访问、检测和修改它本身状态或行为的一种能力（自省）。这一概念的提出很快引发了计算机科学领域关于应用反射性的研究。它首先被程序语言的设计领域所采用,并在Lisp和面向对象方面取得了成绩。 2 python面向对象中的反射通过字符串的形式操作对象相关的属性。python中的一切事物都是对象（都可以使用反射） 四个可以实现自省的函数 下列方法适用于类和对象（一切皆对象，类本身也是一个对象） hasattr(object,name) 判断object中有没有一个name字符串对应的方法或属性 getattr(object, name, default=None) 1234567class People: def walk(self): print("fuck u walk") p = People()x = getattr(p, 'walk')x() setattr(x, y, v) 1234567class People: def walk(self): print("fuck u walk") p = People()setattr(p, 'age', 18) #设置age的值为18，没有这个属性则会创建print(p.age) delattr(x, y) 1234567class People: age = 18 def walk(self): print("fuck u walk") p = People()delattr(p, 'age') 反射当前模块成员 123456789101112import sys def s1(): print 's1' def s2(): print 's2' this_module = sys.modules[__name__] hasattr(this_module, 's1')getattr(this_module, 's2') 3 为什么用反射之反射的好处好处一：实现可插拔机制 有俩程序员，一个lili，一个是egon，lili在写程序的时候需要用到egon所写的类，但是egon去跟女朋友度蜜月去了，还没有完成他写的类，lili想到了反射，使用了反射机制lili可以继续完成自己的代码，等egon度蜜月回来后再继续完成类的定义并且去实现lili想要的功能。 总之反射的好处就是，可以事先定义好接口，接口只有在被完成后才会真正执行，这实现了即插即用，这其实是一种‘后期绑定’，什么意思？即你可以事先把主要的逻辑写好（只定义接口），然后后期再去实现接口的功能 12345class FtpClient: 'ftp客户端,但是还么有实现具体的功能' def __init__(self,addr): print('正在连接服务器[%s]' %addr) self.addr=addr 不影响lili的代码编写 12345678#from module import FtpClientf1=FtpClient('192.168.1.1')if hasattr(f1,'get'): func_get=getattr(f1,'get') func_get()else: print('----&gt;不存在此方法') print('处理其他的逻辑') 好处二：动态导入模块（基于反射当前模块成员） __setattr__,__delattr__,__getattr__三者的用法演示 1234567891011121314151617181920212223242526272829303132class Foo: x=1 def __init__(self,y): self.y=y def __getattr__(self, item): print('----&gt; from getattr:你找的属性不存在') def __setattr__(self, key, value): print('----&gt; from setattr') # self.key=value #这就无限递归了,你好好想想 # self.__dict__[key]=value #应该使用它 def __delattr__(self, item): print('----&gt; from delattr') # del self.item #无限递归了 self.__dict__.pop(item) #__setattr__添加/修改属性会触发它的执行f1=Foo(10)print(f1.__dict__) # 因为你重写了__setattr__,凡是赋值操作都会触发它的运行,你啥都没写,就是根本没赋值,除非你直接操作属性字典,否则永远无法赋值f1.z=3print(f1.__dict__) #__delattr__删除属性的时候会触发f1.__dict__['a']=3#我们可以直接修改属性字典,来完成添加/修改属性的操作del f1.aprint(f1.__dict__) #__getattr__只有在使用点调用属性且属性不存在的时候才会触发f1.xxxxxx 二次加工标准类型(包装)包装：python为大家提供了标准数据类型，以及丰富的内置方法，其实在很多场景下我们都需要基于标准数据类型来定制我们自己的数据类型，新增/改写方法，这就用到了我们刚学的继承/派生知识（其他的标准类型均可以通过下面的方式进行二次加工） 1234567891011121314151617181920212223242526class List(list): #继承list所有的属性，也可以派生出自己新的，比如append和mid def append(self, p_object): ' 派生自己的append：加上类型检查' if not isinstance(p_object,int): raise TypeError('must be int') super().append(p_object) @property def mid(self): '新增自己的属性' index=len(self)//2 return self[index] l=List([1,2,3,4])print(l)l.append(5)print(l)# l.append('1111111') #报错，必须为int类型 print(l.mid) #其余的方法都继承list的l.insert(0,-123)print(l)l.clear()print(l) 练习（clear加权限限制） 123456789101112131415161718192021222324class List(list): def __init__(self,item,tag=False): super().__init__(item) self.tag=tag def append(self, p_object): if not isinstance(p_object,str): raise TypeError super().append(p_object) def clear(self): if not self.tag: raise PermissionError super().clear() l=List([1,2,3],False)print(l)print(l.tag) l.append('saf')print(l) # l.clear() #异常 l.tag=Truel.clear() 授权：授权是包装的一个特性, 包装一个类型通常是对已存在的类型的一些定制,这种做法可以新建,修改或删除原有产品的功能。其它的则保持原样。授权的过程,即是所有更新的功能都是由新类的某部分来处理,但已存在的功能就授权给对象的默认属性。 实现授权的关键点就是覆盖__getattr__方法 例：利用open()函数重新定制一个文件处理器，增加写内容添加时间的功能； 1234567891011121314151617181920import time class FileHandler: def __init__(self,filename,mode='r',encoding="utf-8"): self.file = open(filename,mode,encoding=encoding) #self.file获取到一个文件句柄 def write(self,line): t = time.strftime("%Y-%m-%d %X") self.file.write("%s %s"%(t,line)) def __getattr__(self, item): return getattr(self.file,item) #当对象调用FileHandler类不存在的方法时，会返回open()函数的item字符串对应的方法； f1 = FileHandler("a.txt","r+")f1.write("你好吗\n")f1.seek(0)print(f1.tell()) __setitem__,__getitem,__delitem__把对象操作属性模拟成字典的形式 1234567891011121314151617181920212223class Foo: def __init__(self,name): self.name=name def __getitem__(self, item): print(self.__dict__[item]) def __setitem__(self, key, value): self.__dict__[key]=value def __delitem__(self, key): print('del obj[key]时,我执行') self.__dict__.pop(key) def __delattr__(self, item): print('del obj.key时,我执行') self.__dict__.pop(item) f1=Foo('sb')f1['age']=18f1['age1']=19del f1.age1del f1['age']f1['name']='alex'print(f1.__dict__) __str__当使用print输出对象的时候，只要自己定义了__str__(self)方法，那么就会打印从在这个方法中return的数据 12345678910class People: def __init__(self, name): self.name = name def __str__(self): return 'your name is %s' % self.name p = People('sb')print(p) 结果为 1your name is sb __slots__1234567891.__slots__是什么:是一个类变量,变量值可以是列表,元祖,或者可迭代对象,也可以是一个字符串(意味着所有实例只有一个数据属性)2.引子:使用点来访问属性本质就是在访问类或者对象的__dict__属性字典(类的字典是共享的,而每个实例的是独立的)3.为何使用__slots__:字典会占用大量内存,如果你有一个属性很少的类,但是有很多实例,为了节省内存可以使用__slots__取代实例的__dict__当你定义__slots__后,__slots__就会为实例使用一种更加紧凑的内部表示。实例通过一个很小的固定大小的数组来构建,而不是为每个实例定义一个字典,这跟元组或列表很类似。在__slots__中列出的属性名在内部被映射到这个数组的指定小标上。使用__slots__一个不好的地方就是我们不能再给实例添加新的属性了,只能使用在__slots__中定义的那些属性名。4.注意事项:__slots__的很多特性都依赖于普通的基于字典的实现。另外,定义了__slots__后的类不再 支持一些普通类特性了,比如多继承。大多数情况下,你应该只在那些经常被使用到 的用作数据结构的类上定义__slots__比如在程序中需要创建某个类的几百万个实例对象 。关于__slots__的一个常见误区是它可以作为一个封装工具来防止用户给实例增加新的属性。尽管使用__slots__可以达到这样的目的,但是这个并不是它的初衷。 更多的是用来作为一个内存优化工具。 123456789101112131415class Foo: __slots__='x' f1=Foo()f1.x=1f1.y=2#报错print(f1.__slots__) #f1不再有__dict__ class Bar: __slots__=['x','y'] n=Bar()n.x,n.y=1,2n.z=3#报错 __next__和__iter__实现迭代器协议模仿range的功能 12345678910111213141516171819class My_range: def __init__(self, start, end): self.start = start self.end = end def __iter__(self): return self def __next__(self): if self.start == self.end: raise StopIteration n = self.start self.start += 1 return n s = My_range(1, 20)for i in s: print(i) __doc__123456789class Foo: '我是描述信息' pass class Bar(Foo): passprint(Bar.__doc__) #该属性无法继承给子类 该属性无法被继承 __module__和__class__123__module__ 表示当前操作的对象在那个模块__class__ 表示当前操作的对象的类是什么 __del__析构方法，当对象在内存中被释放时，自动触发执行。 注：如果产生的对象仅仅只是python程序级别的（用户级），那么无需定义del,如果产生的对象的同时还会向操作系统发起系统调用，即一个对象有用户级与内核级两种资源，比如（打开一个文件，创建一个数据库链接），则必须在清除对象的同时回收系统资源，这就用到了__del__ 123456789101112class Foo: def __del__(self): print('执行我啦') f1=Foo()del f1print('-------&gt;') #输出结果执行我啦-------&gt; 典型的应用场景： 创建数据库类，用该类实例化出数据库链接对象，对象本身是存放于用户空间内存中，而链接则是由操作系统管理的，存放于内核空间内存中 当程序结束时，python只会回收自己的内存空间，即用户态内存，而操作系统的资源则没有被回收，这就需要我们定制__del__，在对象被删除前向操作系统发起关闭数据库链接的系统调用，回收资源 __enter__和__exit__我们知道在操作文件对象的时候可以这么写 12with open('a.txt') as f: '代码块' 上述叫做上下文管理协议，即with语句，为了让一个对象兼容with语句，必须在这个对象的类中声明__enter__和__exit__方法 1234567891011121314class Open: def __init__(self,name): self.name=name def __enter__(self): print('出现with语句,对象的__enter__被触发,有返回值则赋值给as声明的变量') # return self def __exit__(self, exc_type, exc_val, exc_tb): print('with中代码块执行完毕时执行我啊') with Open('a.txt') as f: print('=====&gt;执行代码块') # print(f,f.name) __exit__()中的三个参数分别代表异常类型，异常值和追溯信息,with语句中代码块出现异常，则with后的代码都无法执行 12345678910111213141516171819class Open: def __init__(self,name): self.name=name def __enter__(self): print('出现with语句,对象的__enter__被触发,有返回值则赋值给as声明的变量') def __exit__(self, exc_type, exc_val, exc_tb): print('with中代码块执行完毕时执行我啊') print(exc_type) print(exc_val) print(exc_tb) with Open('a.txt') as f: print('=====&gt;执行代码块') raise AttributeError('***着火啦,救火啊***')print('0'*100) #-------------------------------&gt;不会执行 如果__exit()返回值为True,那么异常会被清空，就好像啥都没发生一样，with后的语句正常执行 实例： 1234567891011121314151617181920212223242526import time class Open: def __init__(self, file, m='r', en='utf-8'): self.file = file self.m = m self.en = en self.x = open(file, mode=m, encoding=en) def __enter__(self): return self def __exit__(self, exc_type, exc_val, exc_tb): self.x.close() def __getattr__(self, item): return getattr(self.x, item) def write(self, content): t = time.strftime("%Y-%m-%d-%X") self.x.write('%s %s' % (t, content)) with Open('b.txt') as f: print(f.read()) 用途或者说好处： 1.使用with语句的目的就是把代码块放入with中执行，with结束后，自动完成清理工作，无须手动干预 2.在需要管理一些资源比如文件，网络连接和锁的编程环境中，可以在exit中定制自动释放资源的机制，你无须再去关系这个问题，这将大有用处 __call__对象后面加括号，触发执行。 注：构造方法的执行是由创建对象触发的，即：对象 = 类名() ；而对于 call 方法的执行是由对象后加括号触发的，即：对象() 或者 类()() 123456789101112class Foo: def __init__(self): pass def __call__(self, *args, **kwargs): print('__call__') obj = Foo() # 执行 __init__obj() # 执行 __call__]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python面向对象之绑定方法与非绑定方法]]></title>
    <url>%2F2019%2F02%2F27%2Fpython%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%B9%8B%E7%BB%91%E5%AE%9A%E6%96%B9%E6%B3%95%E4%B8%8E%E9%9D%9E%E7%BB%91%E5%AE%9A%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[类中定义的函数分成两大类一：绑定方法绑定给谁，谁来调用就自动将它本身当作第一个参数传入 1.绑定到类的方法：用classmethod装饰器装饰的方法。 为类量身定制 类.boud_method(),自动将类当作第一个参数传入 (其实对象也可调用，但仍将类当作第一个参数传入) 2.绑定到对象的方法：没有被任何装饰器装饰的方法。 为对象量身定制 对象.boud_method(),自动将对象当作第一个参数传入 (属于类的函数，类可以调用，但是必须按照函数的规则来，没有自动传值那么一说) 二：非绑定方法用staticmethod装饰器装饰的方法 1.不与类或对象绑定，类和对象都可以调用，但是没有自动传值那么一说。就是一个普通工具而已 注意：与绑定到对象方法区分开，在类中直接定义的函数，没有被任何装饰器装饰的，都是绑定到对象的方法，可不是普通函数，对象调用该方法会自动传值，而staticmethod装饰的方法，不管谁来调用，都没有自动传值一说 绑定方法绑定给对象的方法首先我们明确一个知识点，凡是类中的方法或函数，默认情况下都是绑定给对象使用的。下面，我们通过实例，来慢慢解析绑定方法的应用。 123456789101112class People: def __init__(self,name,age): self.name = name self.age = age def talk(self): pass p = People('xiaohua',18)print(p.talk)输出结果：&lt;bound method People.talk of &lt;__main__.People object at 0x000000F802C69358&gt;&gt; 从上面的输出结果来看，talk()這个类中的方法，是绑定给对象使用的。下面，我在看看另外一种情况。 123456789101112class People: def __init__(self,name,age): self.name = name self.age = age def talk(): passp = People('xiaohua',18)print(p.talk)输出结果：&lt;bound method People.talk of &lt;__main__.People object at 0x000000FF68F39358&gt;&gt; 现在，我们将talk()函数的参数去掉，结果显示与上面是一样。这说明，不管是类中的方法，还是类中函数，默认情况下都是绑定给对象使用的。绑定给对象使用有一种好处，那就是不用手动将对象传入。对象是自动传到类中。如果你不信，我们来看看下面的例子： 1234567891011121314class People: def __init__(self,name,age): self.name = name self.age = age def talk(): passp = People('xiaohua',18)print(People.talk)print(p.talk)输出结果：&lt;function People.talk at 0x000000C54E3D0A60&gt; 类来调用仅仅是当作函数使用&lt;bound method People.talk of &lt;__main__.People object at 0x000000C54E249358&gt;&gt; 而对象来调用则为绑定方法 上面很好说明了，如果类来调用类中的方法，那么这个方法仅仅只是一个函数，那么既然是函数，就不会有自动传值这一功能。来看看下面代码： 1234567891011121314class People: def __init__(self,name,age): self.name = name self.age = age def talk(self): passp = People('xiaohua',18)People.talk() 1p.talk() 2#代码1处报错talk() missing 1 required positional argument: 'self'#代码2处正常 从上面输出结果来看，当类调用类中的方法时候，是不会进行自动传值的，也就是说，函数有几个参数，我们就得传递进去几个参数。如果想结果正常运行，那么在类名调用talk()的时候，将参数一一都传递进去。即： 1People.talk(312312) 這个参数可以是任意的，但是，必须传递进去。而，当对象调用类中方法时候，则不用传递，如上面的2正常执行。既然知道了区别，那么，我们来看看下面代码： 1234567891011121314class People: def __init__(self,name,age): self.name = name self.age = age def talk(): passp = People('xiaohua',18)People.talk() 1p.talk() 2# 1处正常执行# 2 处报错talk() takes 0 positional arguments but 1 was given 从输出结果来看，People来调用talk()方法时候，并不需要传递参数；而当对象来调用talk()的时候，由于对象调用自己的绑定方法，会自动将对象当作第一个参数传递进去，所以，当类中talk()方法没有带参数时，而你又给它传递了一个，显然是会报错的。 综上所述，我们可以得出以下结论： 1.凡是类中的方法和函数，都是绑定给对象使用的； 2.绑定方法都有自动传值的功能。传递进去的值，就是对象本身。 3.如果类想调用绑定方法，就必须遵循函数的参数规则，有几个参数，就必须传递几个参数。 绑定给类的方法（classmethod）classmehtod是给类用的，即绑定到类，类在使用时会将类本身当做参数传给类方法的第一个参数（即便是对象来调用也会将类当作第一个参数传入），python为我们内置了函数classmethod来把类中的函数定义成类方法 123456789101112131415import settingsclass MySQL: def __init__(self,host,port): self.host=host self.port=port @classmethod def from_conf(cls): print(cls) return cls(settings.HOST,settings.PORT) print(MySQL.from_conf) #&lt;bound method MySQL.from_conf of &lt;class '__main__.MySQL'&gt;&gt;conn=MySQL.from_conf() conn.from_conf() #对象也可以调用，但是默认传的第一个参数仍然是类 非绑定方法在类内部用staticmethod装饰的函数即非绑定方法，就是普通函数 statimethod不与类或对象绑定，谁都可以调用，没有自动传值效果 123456789101112131415161718import hashlibimport timeclass MySQL: def __init__(self,host,port): self.id=self.create_id() self.host=host self.port=port @staticmethod def create_id(): #就是一个普通工具 m=hashlib.md5(str(time.time()).encode('utf-8')) return m.hexdigest() print(MySQL.create_id) #&lt;function MySQL.create_id at 0x0000000001E6B9D8&gt; #查看结果为普通函数conn=MySQL('127.0.0.1',3306)print(conn.create_id) #&lt;function MySQL.create_id at 0x00000000026FB9D8&gt; #查看结果为普通函数 classmethod与staticmethod的区别12345678910111213141516171819202122232425import settingsclass MySQL: def __init__(self,host,port): self.host=host self.port=port @staticmethod def from_conf(): return MySQL(settings.HOST,settings.PORT) # @classmethod #哪个类来调用,就将哪个类当做第一个参数传入 # def from_conf(cls): # return cls(settings.HOST,settings.PORT) def __str__(self): return '就不告诉你' class Mariadb(MySQL): def __str__(self): return '&lt;%s:%s&gt;' %(self.host,self.port) m=Mariadb.from_conf()print(m) #我们的意图是想触发Mariadb.__str__,但是结果触发了MySQL.__str__的执行，打印就不告诉你：]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>绑定方法</tag>
        <tag>非绑定方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python封装与property]]></title>
    <url>%2F2019%2F02%2F27%2Fpython%E5%B0%81%E8%A3%85%E4%B8%8Eproperty%2F</url>
    <content type="text"><![CDATA[封装封装可以理解为一个多功能的自助饮料机器，且机器是不透明密封的，只在下方开了不同的龙头，当顾客需要不同的饮料时，只需要去打开不同的龙头开关即可得到自己想要的饮料，但顾客不知道机器内部是产生不同的饮料的。在python中，封装可以是类，可以是函数。封装是将数据或属性隐藏在内部，不让外部看到。 在python中用双下划线开头的方式将属性隐藏起来（设置成私有的） 1234567891011121314#其实这仅仅这是一种变形操作且仅仅只在类定义阶段发生变形#类中所有双下划线开头的名称如__x都会在类定义时自动变形成：_类名__x的形式： class A: __N=0 #类的数据属性就应该是共享的,但是语法上是可以把类的数据属性设置成私有的如__N,会变形为_A__N def __init__(self): self.__X=10 #变形为self._A__X def __foo(self): #变形为_A__foo print('from A') def bar(self): self.__foo() #只有在类内部才可以通过__foo的形式访问到. #A._A__N是可以访问到的，#这种，在外部是无法通过__x这个名字访问到 这种变形需要注意的问题是： 1.这种机制也并没有真正意义上限制我们从外部直接访问属性，知道了类名和属性名就可以拼出名字：_类名__属性，然后就可以访问了，如a._A__N，即这种操作并不是严格意义上的限制外部访问，仅仅只是一种语法意义上的变形，主要用来限制外部的直接访问。 2.变形的过程只在类的定义时发生一次,在定义后的赋值操作，不会变形 3.在继承中，父类如果不想让子类覆盖自己的方法，可以将方法定义为私有的 例： 123456789101112class A: def fa(self): print('from A') def test(self): self.fa() class B(A): def fa(self): print('from B') b=B()b.test() 输出：form B 12345678910111213#把fa定义成私有的，即__faclass A: def __fa(self): #在定义时就变形为_A__fa print('from A') def test(self): self.__fa() #只会与自己所在的类为准,即调用_A__fa class B(A): def __fa(self): print('from B') b=B()b.test() 输出：form A 封装的真谛在于明确地区分内外，封装的属性可以直接在内部使用，而不能被外部直接使用，然而定义属性的目的终归是要用，外部要想用类隐藏的属性，需要我们为其开辟接口，让外部能够间接地用到我们隐藏起来的属性，那这么做的意义何在？？？ 1：封装数据：将数据隐藏起来这不是目的。隐藏起来然后对外提供操作该数据的接口，然后我们可以在接口附加上对该数据操作的限制，以此完成对数据属性操作的严格控制。 2：封装方法：目的是隔离复杂度 3: 了解 python并不会真的阻止你访问私有的属性，模块也遵循这种约定，如果模块名以单下划线开头，那么from module import *时不能被导入,但是你from module import _private_module依然是可以导入的 特性(property)什么是特性propertyproperty是一种特殊的属性，访问它时会执行一段功能（函数）然后返回值 1234567891011class People: def __init__(self,name,weight,height): self.name=name self.weight=weight self.height=height @property def bmi(self): return self.weight / (self.height**2) p1=People('egon',75,1.85)print(p1.bmi) 为什么要用property将一个类的函数定义成特性以后，对象再去使用的时候p1.bmi,根本无法察觉自己的bmi是执行了一个函数然后计算出来的，这种特性的使用方式遵循了统一访问的原则 被property装饰的属性会 优先于对象的属性被使用 而被property装饰的属性，如sex，分成三种： 1.property 2.sex.setter 3.sex.deleter 1234567891011121314151617181920212223242526class People: def __init__(self, name, sex): self.name = name self.sex = sex @property def sex(self): return self.__sex @sex.setter def sex(self, sex1): if not isinstance(sex1, int): raise TypeError('必须是数字') self.__sex = sex1 @sex.deleter def sex(self): del self.__sex p = People('ezc', 20)print(p.sex)p.sex = 15print(p.sex)del p.sexprint(p.sex) 在创建对象时self.sex会先去找有没有property，如果有会先去调用其下面的，所以self.__sex = sex1，实际上真正的值存在了__sex中，可以通过p._dict_查看，查询时也是，会先去寻找被property装饰的属性，修改和删除也同理]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>封装</tag>
        <tag>property</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python类]]></title>
    <url>%2F2019%2F02%2F27%2Fpython%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[创建和使用12345678class Dog(): def __init__(self,name,age): self.name=name; self.age=age; def sit(self): print(self.name.title()+" is now sitting") def roll_over(self): print(self.name.title()+" rolled over!") 方法__init__()是一个特殊的方法，相当于构造方法，每当创建新实例时，Python都会自动运行它__init__中的形参self必不可少，还必须位于其他形参的前面。创建实例时不用给self传递值后面的两个方法由于不需要额外的信息，因此只有一个形参self，变量都有前缀self，以self为前缀的变量可供类中的所有方法使用。self.name=name获取存储在形参name中的值，并将其存储到变量name中，然后该变量被关联到当前创建的实例。 根据类创建实例my_dog=Dog(‘stupy’,3)这里使用上面的Dog类创建了一个名为‘stupy’、年龄为3的my_dog实例访问属性my_dog.name获取名字，my_dog.age获取年龄 调用方法my_dog.sit() my_dog.roll_over() 给属性指定默认值比如上例默认为公狗，则在init()函数中创建一个性别属性并设置初始值，self.sex=’gong’ 修改属性的值1.直接修改属性的值接上例，使用句点表示法来直接访问并设置小狗的属性name。my_dog.name=’clever’ 2.通过方法修改属性的值相当于java中的set方法例： 123def update_name(self,newname): self.name=newnamemy_dog.update_name('wuwu') 这样就无需直接访问属性，而可以将值传递给一个方法，由它在内部进行更新 继承如下例： 1234567891011121314151617181920212223class Car(): def __init__(self, make, model, year): self.make = make self.model = model self.year = year self.odometer_reading = 0 def get_descriptive_name(self): long_name = str(self.year) + ' ' + self.make + ' ' + self.model return long_name.title() def read_odometer(self): print("This car has " + str(self.odometer_reading) + " miles on it.") def update_odometer(self, mileage): if mileage &gt;= self.odometer_reading: self.odometer_reading = mileage else: print("You can't roll back an odometer!") def increment_odometer(self, miles): self.odometer_reading += miles class ElectricCar(Car): def __init__(self, make, model, year): super().__init__(make, model, year) my_tesla = ElectricCar('tesla', 'model s', 2016) print(my_tesla.get_descriptive_name()) 定义子类时，在括号里指定父类的名称。super()帮助Python将父类和子类关联起来，调用父类的方法__init__()，让ElectricCar实例包含父类的所有属性。上面ElectricCar实例的行为与Car实例一样，现在定义电动汽车特有的属性和方法在__init__函数內定义一个电动汽车特有的属性，self.battery_size=70编写一个打印电瓶描述的方法 123def describe_battery(self): print("This car has a " + str(self.battery_size) + "-kWh battery.") 1.继承顺序在Java和C#中子类只能继承一个父类，而Python中子类可以同时继承多个父类，如A(B,C,D) 如果继承关系为非菱形结构，则会按照先找B这一条分支，然后再找C这一条分支，最后找D这一条分支的顺序直到找到我们想要的属性 如果继承关系为菱形结构，那么属性的查找方式有两种，分别是：深度优先和广度优先 1234567891011121314151617181920212223242526272829303132class A(object): def test(self): print('from A') class B(A): def test(self): print('from B') class C(A): def test(self): print('from C') class D(B): def test(self): print('from D') class E(C): def test(self): print('from E') class F(D,E): # def test(self): # print('from F') passf1=F()f1.test()print(F.__mro__) #只有新式才有这个属性可以查看线性列表，经典类没有这个属性 #新式类继承顺序:F-&gt;D-&gt;B-&gt;E-&gt;C-&gt;A#经典类继承顺序:F-&gt;D-&gt;B-&gt;A-&gt;E-&gt;C#python3中统一都是新式类#pyhon2中才分新式类与经典类 2 继承原理(python如何实现的继承)python到底是如何实现继承的，对于你定义的每一个类，python会计算出一个方法解析顺序(MRO)列表，这个MRO列表就是一个简单的所有基类的线性顺序列表，例如 12&gt;&gt;&gt; F.mro() #等同于F.__mro__[&lt;class '__main__.F'&gt;, &lt;class '__main__.D'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.E'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, &lt;class 'object'&gt;] 为了实现继承,python会在MRO列表上从左到右开始查找基类,直到找到第一个匹配这个属性的类为止。而这个MRO列表的构造是通过一个C3线性化算法来实现的。我们不去深究这个算法的数学原理,它实际上就是合并所有父类的MRO列表并遵循如下三条准则:1.子类会先于父类被检查2.多个父类会根据它们在列表中的顺序被检查 3.如果对下一个类存在两个合法的选择,选择第一个父类 3.子类中调用父类的方法方法一：指名道姓，即父类名.父类方法() 12345678910111213141516171819202122class Vehicle: #定义交通工具类 Country='China' def __init__(self,name,speed,load,power): self.name=name self.speed=speed self.load=load self.power=power def run(self): print('开动啦...') class Subway(Vehicle): #地铁 def __init__(self,name,speed,load,power,line): Vehicle.__init__(self,name,speed,load,power) self.line=line def run(self): print('地铁%s号线欢迎您' %self.line) Vehicle.run(self) line13=Subway('中国地铁','180m/s','1000人/箱','电',13)line13.run() 方法二：super()，推荐用这种方法 1234567891011121314151617181920212223242526class Vehicle: #定义交通工具类 Country='China' def __init__(self,name,speed,load,power): self.name=name self.speed=speed self.load=load self.power=power def run(self): print('开动啦...') class Subway(Vehicle): #地铁 def __init__(self,name,speed,load,power,line): #super(Subway,self) 就相当于实例本身 在python3中super()等同于super(Subway,self) super().__init__(name,speed,load,power) self.line=line def run(self): print('地铁%s号线欢迎您' %self.line) super(Subway,self).run() class Mobike(Vehicle):#摩拜单车 pass line13=Subway('中国地铁','180m/s','1000人/箱','电',13)line13.run() 派生在子类中重新定义父类的方法，运行时将忽略父类中的方法，转而运行子类中重新定义的方法。 在子类中，新建的重名的函数属性，在编辑函数内功能的时候，有可能需要重用父类中重名的那个函数功能，应该是用调用普通函数的方式，即：类名.func()，此时就与调用普通函数无异了，因此即便是self参数也要为其传值 多态与多态性多态多态指的是一类事物有多种形态 动物有多种形态：人，狗，猪 多态性多态性是指在不考虑实例类型的情况下使用实例 12在面向对象方法中一般是这样表述多态性：向不同的对象发送同一条消息（！！！obj.func():是调用了obj的方法func，又称为向obj发送了一条消息func），不同的对象在接收时会产生不同的行为（即方法）。也就是说，每个对象可以用自己的方式去响应共同的消息。所谓消息，就是调用函数，不同的行为就是指不同的实现，即执行不同的函数。比如：老师.下课铃响了（），学生.下课铃响了()，老师执行的是下班操作，学生执行的是放学操作，虽然二者消息一样，但是执行的效果不同 多态性分为静态多态性和动态多态性 静态多态性：如任何类型都可以用运算符+进行运算 动态多态性：如下 12345678910111213peo=People()dog=Dog()pig=Pig() #peo、dog、pig都是动物,只要是动物肯定有talk方法#于是我们可以不用考虑它们三者的具体是什么类型,而直接使用peo.talk()dog.talk()pig.talk() #更进一步,我们可以定义一个统一的接口来使用def func(obj): #obj这个参数没有类型限制，可以传入不同类型的值 obj.talk() #调用的逻辑都一样，执行的结果不一样 为什么要用多态性（多态性的好处）： 1.增加了程序的灵活性 以不变应万变，不论对象千变万化，使用者都是同一种形式去调用，如func(animal) 2.增加了程序额可扩展性 通过继承animal类创建了一个新的类，使用者无需更改自己的代码，还是用func(animal)去调用 123456789class Cat(Animal): #属于动物的另外一种形态：猫 def talk(self): print('say miao') def func(animal): #对于使用者来说，自己的代码根本无需改动 animal.talk() cat1=Cat() #实例出一只猫func(cat1) #甚至连调用方式也无需改变，就能调用猫的talk功能 接口接口提取了一群类共同的函数，可以把接口当做一个函数的集合。 然后让子类去实现接口中的函数。 这么做的意义在于归一化，什么叫归一化，就是只要是基于同一个接口实现的类，那么所有的这些类产生的对象在使用时，从用法上来说都一样。 归一化的好处在于： 归一化让使用者无需关心对象的类是什么，只需要的知道这些对象都具备某些功能就可以了，这极大地降低了使用者的使用难度。 归一化使得高层的外部使用者可以不加区分的处理所有接口兼容的对象集合 在python中根本就没有一个叫做interface的关键字，如果非要去模仿接口的概念 可以借助第三方模块： http://pypi.python.org/pypi/zope.interface twisted的twisted\internet\interface.py里使用zope.interface 文档https://zopeinterface.readthedocs.io/en/latest/ 设计模式：https://github.com/faif/python-patterns 也可以使用继承： 继承的两种用途 一：继承基类的方法，并且做出自己的改变或者扩展（代码重用）：实践中，继承的这种用途意义并不很大，甚至常常是有害的。因为它使得子类与基类出现强耦合。 二：声明某个子类兼容于某基类，定义一个接口类（模仿java的Interface），接口类中定义了一些接口名（就是函数名）且并未实现接口的功能，子类继承接口类，并且实现接口中的功能 抽象类1 什么是抽象类与java一样，python也有抽象类的概念但是同样需要借助模块实现，抽象类本质也是类，只是加了装饰器的类，它的特殊之处在于只能被继承，不能被实例化， 2 为什么要有抽象类如果说类是从一堆对象中抽取相同的内容而来的，那么抽象类就是从一堆类中抽取相同的内容而来的，内容包括数据属性和函数属性。 比如我们有香蕉的类，有苹果的类，有桃子的类，从这些类抽取相同的内容就是水果这个抽象的类，你吃水果时，要么是吃一个具体的香蕉，要么是吃一个具体的桃子。。。。。。你永远无法吃到一个叫做水果的东西。 从设计角度去看，如果类是从现实对象抽象而来的，那么抽象类就是基于类抽象而来的。 从实现角度来看，抽象类与普通类的不同之处在于：抽象类中只能有抽象方法（没有实现功能），该类不能被实例化，只能被继承，且子类必须实现抽象方法。这一点与接口有点类似，但其实是不同的，即将揭晓答案 3 在python中实现抽象类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import abc #利用abc模块实现抽象类 class All_file(metaclass=abc.ABCMeta): all_type='file' @abc.abstractmethod #定义抽象方法，无需实现功能 def read(self): '子类必须定义读功能' pass @abc.abstractmethod #定义抽象方法，无需实现功能 def write(self): '子类必须定义写功能' pass # class Txt(All_file):# pass## t1=Txt() #报错,子类没有定义抽象方法 class Txt(All_file): #子类继承抽象类，但是必须定义read和write方法 def read(self): print('文本数据的读取方法') def write(self): print('文本数据的读取方法') class Sata(All_file): #子类继承抽象类，但是必须定义read和write方法 def read(self): print('硬盘数据的读取方法') def write(self): print('硬盘数据的读取方法') class Process(All_file): #子类继承抽象类，但是必须定义read和write方法 def read(self): print('进程数据的读取方法') def write(self): print('进程数据的读取方法') wenbenwenjian=Txt() yingpanwenjian=Sata() jinchengwenjian=Process() #这样大家都是被归一化了,也就是一切皆文件的思想wenbenwenjian.read()yingpanwenjian.write()jinchengwenjian.read() print(wenbenwenjian.all_type)print(yingpanwenjian.all_type)print(jinchengwenjian.all_type)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python的递归与二分法]]></title>
    <url>%2F2019%2F02%2F27%2Fpython%E7%9A%84%E9%80%92%E5%BD%92%E4%B8%8E%E4%BA%8C%E5%88%86%E6%B3%95%2F</url>
    <content type="text"><![CDATA[递归递归:在调用一个函数的过程中，直接或间接地调用了函数本身这个就叫递归 1.必须有个明确的结束条件 2.每次进入更深一层递归时，问题规模相比上次递归应有所减少 3.递归效率不高，递归层次过多会导致栈溢出（在计算机中，函数调用是通过栈(stack)这种数据结构实现的，每当进入一个函数调用，栈就会加一层栈帧，每当函数返回，就栈就会减少一层栈帧。由于栈的大小不是无限的，递归调用的次数过多，则会导致栈溢出） 实例： 123456789101112131415def age(n): if n == 1: return 18 else: return age(n-1)+2 print(age(5))# age(5)=age(4)+2 第一次进入# age(4)=age(3)+2 第二次进入# age(3)=age(2)+2 第三次进入# age(2)=age(1)+2 第四次进入# age(1)=18 第五次进入，最后判断终止条件# age(n)=age(n-1)+2 #n&gt;1 递归终止条件# age(1)=18 #n=1 等于终止条件 二分法每次拿中间的值与想要的值比较 例： 1234567891011121314151617181920212223name = &#123;12, 32, 23, 45, 123, 4654, 1231, 1, 2, 212, 56, 9, 34, 99, 30&#125;name_sor = sorted(name) #把列表内容按升序排列 def second_find(x, li): mid_index = int(len(li) / 2) if len(li) &gt; 1: if x &gt; li[mid_index]: l1 = li[mid_index:] second_find(x,l1) elif x &lt;li[mid_index]: l2 = li[:mid_index] second_find(x,l2) else: print('恭喜你找到了') elif len(li) == 1: if li[0] == x: print("恭喜你找到了") else: print("gun!") second_find(32, name_sor)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>递归</tag>
        <tag>二分法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python内置函数]]></title>
    <url>%2F2019%2F02%2F26%2Fpython%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[内置函数以下是Python3版本所有的内置函数： abs()绝对值 all()传进一个可迭代对象，如果对象为空，比如[],’ ‘等，则返回Ture，如果不为空，则需要全部对象为Ture，才返回Ture 1print(all([None,0,' ',1])) 输出结果：False any()传进一个可迭代对象,如果对象为空，比如[],’ ‘等，则返回False,如果不为空，只要可迭代对象next出来的值任何一个为Ture，就返回Ture 1print(any([None,0,' ',1])) 输出结果：True sum()传进一个可迭代对象，进行求和计算 bin()返回一个整数 int 或者长整数 long int 的二进制表示 bool()以下情况都为False： [] 空列表 {} 空字典，空集合 () 空元祖 ‘ ‘ 空字符串 0 bytes()将一个字符串转换成字节形式 1print(bytes('helloworld', encoding='utf-8')) callable()判断函数是否可被调用 chr()用一个范围在 range（256）内的（就是0～255）整数作参数，返回一个对应ascii字符 dir()查看下面的方法 例： print(dir(sum)) 查看sum下面的方法 divmod()传进去两个数，得到整除加余数，多用于分页 enumerate()可迭代,并加上序列例： 12for i in emumerate(['a','b','c']) print(i) 输出结果： 123(0,'a')(1,'b')(2,'c') eval()函数可将字符串转换为代码执行，并返回一个或多个值 hash()一种算法，如果字符串改变，hash值也会改变，且不能逆推 hex()十进制转十六进制 otc()十进制转八进制 id()返回对象的内存地址,判断身份 pow()方法返回 xy（x的y次方） 的值 reverse()函数用于反向列表中元素 lambda()匿名函数:是指一类无需定义标识符（函数名）的函数或子程序。lambda 函数可以接收任意多个参数 (包括可选参数) 并且返回单个表达式的值 例1:定义一个lambda表达式，求三个数的和 12345678f = lambda x,y,z:x + y + zprint f(1,2,3)print f(4,5,6)输出：615 例2:用lambda表达式求n的阶乘 1234n = 5print reduce(lambda x,y:x*y,range(1,n+1))输出：120 round()方法返回浮点数x的四舍五入值,但实际为四舍六入五留双 round(10.5) 离偶数10近，所以结果为10 round(11.5) 离偶数12近，所以结果为12 max()求最大值 例：求字典中values的最大值，但返回的key 12money =&#123;'wzc': 5000, 'lsy': 500, 'hsy': 7000&#125;print(max(money, key=lambda s: money[s])) min()求最小值 zip()函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。 如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同 1234a = [1,2,3]b = [4,5,6]c = [4,5,6,7,8]zipped = zip(a,b) 打包为元组的列表 [(1, 4), (2, 5), (3, 6)] 1zipped = zip(a,c) 元素个数与最短的列表一致 [(1, 4), (2, 5), (3, 6)] sorted()排序，返回值是列表，默认升序 123sor = [2, 4, 6, 1, 34, 3]print(sorted(sor)) # 升序print(sorted(sor, reverse=True)) # 降序 实例：把人员按工资的高低排列 12money =&#123;'wzc': 5000, 'lsy': 500, 'hsy': 7000&#125;print(sorted(money, key=lambda x: money[x])) map()会根据提供的函数对指定序列做映射。它接收一个函数 f 和一个 list，并通过把函数 f 依次作用在 list 的每个元素上，得到一个map迭代器 并返回 实例1： 将列表中的值平方： 123x = [1, 4, 3, 2, 9, 6]l = map(lambda x1: x1**2, x)print(list(l)) 注意:Pyhton2返回列表，Python3 返回迭代器对象,我看网上很多人的博客写的都是Python2的返回结果 实例2：拼接 123x = [1, 4, 3, 2, 9, 6]l = map(lambda x1: str(x1) + 'apple', x)print(list(l)) reduce()函数会对参数序列中元素进行累积 在 Python3 中，reduce() 函数已经被从全局名字空间里移除了，它现在被放置在 fucntools 模块里，如果想要使用它，则需要通过引入 functools 模块来调用 reduce() 函数： 12from functools import reducereduce(lambda x, y: x+y, [1,2,3,4,5]) filter()函数用于过滤序列，过滤掉不符合条件的元素，返回由符合条件元素组成的新列表。 该接收两个参数，第一个为函数，第二个为序列，序列的每个元素作为参数传递给函数进行判，然后返回 True 或 False，最后将返回 True 的元素放到新列表中。 注意: Pyhton2返回列表，Python3 返回迭代器对象 实例1： 123fe = [34, 23, 12, 56, 34, 34, 324]le = filter(lambda x: x &gt; 20, fe)print(list(le) 实例2： 123money =&#123;'wzc': 5000, 'lsy': 500, 'hsy': 7000&#125;li = filter(lambda x1: money[x1] &gt; 1000, money)print(list(li))]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>内置函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[冒泡排序]]></title>
    <url>%2F2019%2F02%2F26%2F%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[冒泡排序的思想: 每次比较两个相邻的元素, 如果他们的顺序错误就把他们交换位置比如有五个数: 12, 35, 99, 18, 76, 从大到小排序, 对相邻的两位进行比较 第一趟: 第一次比较: 35, 12, 99, 18, 76 第二次比较: 35, 99, 12, 18, 76 第三次比较: 35, 99, 18, 12, 76 第四次比较: 35, 99, 18, 76, 12 经过第一趟比较后, 五个数中最小的数已经在最后面了, 接下来只比较前四个数, 依次类推 第二趟99, 35, 76, 18, 12 第三趟99, 76, 35, 18, 12 第四趟99, 76, 35, 18, 12比较完成 冒泡排序原理: 每一趟只能将一个数归位, 如果有n个数进行排序,只需将n-1个数归位, 也就是说要进行n-1趟操作(已经归位的数不用再比较)1234567891011def my_sort(num): l = len(num) for i in range(l-1): for j in range(l-1-i): if num[j] &lt; num[j+1]: num[j], num[j+1] = num[j+1], num[j]nums = [2,45,67,8,0,56]my_sort(nums)print(nums)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>冒泡排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python生成器表达式]]></title>
    <url>%2F2019%2F02%2F26%2Fpython%E7%94%9F%E6%88%90%E5%99%A8%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[生成器表达式相比列表表达式，将[]换成了()，返回对象不是一个列表，而是一个生成器，相比列表更加省内存 实例1： 列表表达式写法： 12l = ['apple%s' % i for i in range(10000)]print(l) 生成器表达式写法： 123g = ('apple%s' % i for i in range(10000))for i in g: print(i) 实例2: 一般写法： 12345678910res = []with open('test1.txt') as f: for line in f: l = line.split(',') d = &#123;&#125; d['name'] = l[0] d['price'] = l[1] d['count'] = l[2] res.append(d) print(d) 生成器表达式写法： 12345with open('test1.txt') as f: res = (line.split(',') for line in f) dic_g = (&#123;'name': i[0], 'price': i[1], 'count': i[2]&#125; for i in res) apple_dic = next(dic_g) #只有调用next才会往外拿一个,大大节省内存 print(apple_dic)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>生成器表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python列表生成式]]></title>
    <url>%2F2019%2F02%2F26%2Fpython%E5%88%97%E8%A1%A8%E7%94%9F%E6%88%90%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[列表生成式会将所有的结果全部计算出来，把结果存放到内存中，如果列表中数据比较多，就会占用过多的内存空间，可能会导致MemoryError内存错误或者导致程序在运行时出现卡顿的情况 实例1： 在数字0-99中，取大于50的数，分为拼接在apple字符串后面，并存到一个列表中 一般的写法： 12345messi = []for i in range(100): if i &gt; 50: messi.append("apple%s" % i)print(messi) 列表生成式的写法： 123l = ["apple%s" % i for i in range(100) if i &gt; 50] # 'apple%s' %i 这句话在列表中，所以不用append命令写入列表中print(l) 实例2： 将一个列表中的每一个元素与一个字符串的每一个字符拼接，并保存到一个列表中 一般的写法： 123456789x1 = [1, 2, 3, 4]s = 'month'x2 = []for num in x1: for s1 in s: if num &gt; 2: t = (num, s1) x2.append(t)print(x2) 列表生成式的写法: 1234x1 = [1, 2, 3, 4]s = "month"le = [(num, s1) for num in x1 if num &gt; 2 for s1 in s]print(le)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>列表生成式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python协程函数]]></title>
    <url>%2F2019%2F02%2F26%2Fpython%E5%8D%8F%E7%A8%8B%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[协程函数从语法上来看，协程和生成器类似，都是定义体中包含yield关键字的函数。yield在协程中的用法： 在协程中yield通常出现在表达式的右边，例如：datum = yield,可以产出值，也可以不产出–如果yield关键字后面没有表达式，那么生成器产出None. 协程可能从调用方接受数据，调用方是通过send(datum)的方式把数据提供给协程使用，而不是next(…)函数，通常调用方会把值推送给协程。 协程可以把控制器让给中心调度程序，从而激活其他的协程 所以总体上在协程中把yield看做是控制流程的方式 实例： 123456789101112131415def menu(x): print("welcome %s to shaxian restaurant" % x) men_list = [] while True: print(men_list) food = yield men_list print("%s start to eat %s" % (x, food)) men_list.append(food) g = menu('张三')next(g)g.send('包子') # 将'包子'传给yield ，然后赋值给了food，然后从上次暂停的位置接着执行代码，直到又到下一个yieldg.send('饺子')g.send('牛肉面') g.send与next(g)的区别是： 1.如果函数内yield是表达式形式，那么必须先next(g) 2.二者的共同之处都是可以让函数在上一次暂停的位置继续运行，不一样的地方在于send在触发下一次代码的执行时，会顺便给yield传一个值 如果不想写next的初始化，而直接调用send，可以选择加个装饰器 12345678910111213141516171819202122232425def happy(fuc): def f1(*args, **kwargs): res = fuc(*args, **kwargs) next(res) #让函数调用时自动初始化next return res return f1 @happydef menu(x): print("welcome %s to shaxian restaurant" % x) men_list = [] while True: print(men_list) food = yield men_list print("%s start to eat %s" % (x, food)) men_list.append(food) g = menu('张三') g.send('包子') # 将'包子'传给yield ，然后赋值给了food，然后从上次暂停的位置接着执行代码，直到又到下一个yieldg.send('饺子')g.send('牛肉面')]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>协程函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python生成器]]></title>
    <url>%2F2019%2F02%2F26%2Fpython%E7%94%9F%E6%88%90%E5%99%A8%2F</url>
    <content type="text"><![CDATA[生成器生成器就是一个函数，这个函数内包含yield这个关键字 生成器与return的区别： return只能返回一次函数就结束，而生成器可以返回多次值 生成器函数包含一个或者多个yield 当调用生成器函数时，函数将返回一个对象，但是不会立刻向下执行，yield会保存一个状态，下一次运行会在这个位置接着往下运行，直到碰到下一个yield 像__iter__()和__next__()方法等是自动实现的，所以我们可以通过next()方法对对象进行迭代 一旦函数被yield，函数会暂停，控制权返回调用者 1234567891011def pr(x): print("start games") while x &gt; 0: yield x x -= 1 print("game over") game = pr(5) #此时game就是一个迭代器for i in game: print(i) 输出结果为： 1234567start games54321game over]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>生成器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python迭代器]]></title>
    <url>%2F2019%2F02%2F26%2Fpython%E8%BF%AD%E4%BB%A3%E5%99%A8%2F</url>
    <content type="text"><![CDATA[迭代器迭代器是一个可以记住遍历的位置的对象。 迭代器有两个基本的方法：iter() 和 next()。 使用对象内置的__iter__()方法生成迭代器 1it = name.__iter__() 使用内置工厂函数生成迭代器 1it = iter(name) 迭代器通过其内建的 iter.next() 方法，或通过 Python 内建的 next() 来迭代下一个元素，直到最后触发 StopIteration异常后表示迭代结束。 实例： 1234567name = &#123;'张三': 24, '李四': 25, '王五': 20&#125;it = iter(name)while True: try: print(next(it)) except StopIteration: break 输出为三个key的值 而for循环，本质就是调用了迭代器 for x in name 把name变成了一个迭代器，然后调用next方法，而且不用写 except StopIteration 作用优点1.提供一种不依赖索引的取值方式，这样就可以遍历那些没有索引的可迭代对象(字典，集合，文件) 2.迭代器与列表比较，迭代性是惰性计算，更省内存 缺点1.永远无法获取迭代器的长度，使用不如列表索引灵活，比如要获取第三个，则必须要一个个next 2.一次性，只能往后取，无法倒着取]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>迭代器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python装饰器]]></title>
    <url>%2F2019%2F02%2F26%2Fpython%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[python装饰器就是用于在不改变原函数代码的情况下拓展新功能的一种函数，这个函数的特殊之处在于它的返回值也是一个函数，使用python装饰器的好处就是在不用更改原函数的代码前提下给函数增加新的功能。 装饰器分为有参和无参两种 无参123456789101112131415161718192021import timedef happy(func): def f1(*args, **kwargs): start_time = time.time() func(*args, **kwargs) end_time = time.time() print('run time is %s' % (end_time-start_time)) return f1 @happy #auto=happy(auto)def auto(name, password): print(name, password) @happydef shadow(): time.sleep(3) print("hello_world") shadow()auto('wzc', '123456') auto函数为原函数，我们需要对其进行功能扩展 因为原函数可能有形参或者没有，因此我们将函数定义为 def f1(*args, **kwargs)，这样不管是有参还是无参，都可以接收，不会报错 这里的happy函数就是最原始的装饰器，把auto当做了一个参数传了进去 auto=happy(auto) 然后返回值也是一个函数，返回一个f1，相当于auto=f1 其中作为参数的这个函数auto就在返回函数f1的内部执行。在函数auto前面加上@happy，auto函数就相当于被注入了计时功能，现在只要调用auto，它就已经变身为“新的功能更多”的函数了。 有参有参装饰器与无参装饰器的区别就是在外面多加一个嵌套函数，实现闭包功能 12345678910111213141516171819import time def mom(x='blee'): def happy(func): def f1(*args, **kwargs): print(x) start_time = time.time() func(*args, **kwargs) end_time = time.time() print('run time is %s' % (end_time-start_time)) return f1 return happy @mom('red')def auto(name, password): print(name, password) auto('wzc', '123456') 在原函数前面写@装饰器名，并加入参数 @mom(‘red’) 这时候我们先看mom(‘red’)，传回一个函数happy，等同于 @happy 接下来就和上面一样，这样就实现了有参装饰器]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python函数]]></title>
    <url>%2F2019%2F02%2F26%2Fpython%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[内置函数比如print,len,max等，后面有详细介绍的文章 自定义函数函数定义1234def 函数名():'写注释，描述信息'函数体return 返回值可以是任意类型，不写return，则默认返回None 无参函数通常情况不需要return值 12def fly():函数体 有参函数123def fly(a,b):函数体return a+b 调用函数有参 money=fly(1,2) #定义一个变量来接收return的值 无参 fly() #无参函数不写return，则默认返回None 函数的参数介绍从形参的角度分析位置参数：必须传值的参数 123def fly(x,y): print(x) print(y) 默认参数 123def fly(x,y=1): print(x) print(y) fly(1) #output : 1 1 fly(1,4) #output : 1 4 默认参数要注意的问题：默认参数必须放到位置参数的后面,def fly(x=1,y)则会报错 特殊的两种参数 * args 接收所有除了正常传参的位置传参，保存为元祖 **kwagrs 接收所有除了正常传参的关键字传参，保存为字典 例1： 1234567def fly(x, y=1, *args, **kwargs): print(x) print(y) print(args) print(kwargs) fly(1,y=78,a=1,b=2) 输出结果： 1234178()&#123;'a': 1, 'b': 2&#125; 例2： 1234567def fly(x, y=1, *args, **kwargs): print(x) print(y) print(args) print(kwargs) fly(1,20,300,78,w=1,l=2) 输出结果： 1234120(300, 78)&#123;'w': 1, 'l': 2&#125; 从实参的角度分析：第一种按位置传参 1fly(1,4) 第二种按关键字传参 12fly(x=1,y=2)fly(y=1,x=2) 第三种混着用 1fly(1,y=2) 如果写成fly(1,x=1)则会报错，因为参数只能赋值一次 如果写成fly(x=1,2)则会报错，因为按位置传值必须在按关键字传值前面 以上两条是混合实参的原则，不能违反 特殊的实参写法 1fly(*(12,16,14,15,18),**&#123;"ni":"fuck","sad":"many"&#125;) 上面的写法相当于： fly(12,16,14,15,18,ni=fuck,sad=many) 名称空间名称空间分为： 内部名称空间 全局名称空间 内置名称空间 搜索顺讯为：内置 全局 内部 闭包：内部函数包含对外部作用域而不是对全局作用域的名字的引用 下面是一个闭包例子： 123456789def f3(): x = 1 def f4(): print(x) return f4 x = 1000f4 = f3()f4() 输出结果：1 不管在哪调用内置函数，变量一定是由内向外搜索]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python文件操作]]></title>
    <url>%2F2019%2F02%2F26%2Fpython%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[流程1.打开文件 open() 2.操作文件 read write 3.关闭文件 close() 在window系统上 默认的编码是gbk 用open()打开时，window系统会使用默认的gbk编码，所以如果打开的文件是别的编码保存，则需要手动指定编码，例如打开utf-8保存的文件时 1f = open("test",encoding="utf-8") 而在linux系统上 默认的编码是utf-8 操作方法读整个文件的内容 1f.read() 读文件前5个字符的内容 1f.read(5) 如果再来一次 f.read(5),则读接下来的5个字符，read的内容取决于光标的位置 读一行 1f.readline() 一行一行打印，并移除空白 12for i in f: print(i.strip()) 写入模式1f = open("d://test1.txt", mode="w", encoding="utf-8") 当文件不存在时，会自动创建 这个模式只能写，不能读 覆盖的写 1f.write(hello\nworld) 多行一起写 1f.write(['11111\n','222222\n']) 追加模式跟w模式一样也是只能写，但是是追加的写 1f=open("d://test1.txt",mode="a",encoding="utf-8") 光标移动seek()的三种模式： （1）f.seek(p,0) 移动当文件第p个字节处，绝对位置 （2）f.seek(p,1) 移动到相对于当前位置之后的p个字节 （3）f.seek(p,2) 移动到相对文章尾之后的p个字节 seek是按字节移动 可读可写模式1.可读内容，写则是追加的写 1f=open("d://test1.txt",mode="r+",encoding="utf-8") 2.写的时候会把原来的内容覆盖,想读取内容，需要seek调整光标位置 1f=open("d://test1.txt",mode="w+",encoding="utf-8") 3.初始光标在最后，要读，则需要将光标调到初始位置，seek(0)，要写不管光标位置在哪，都是追加的写入 1f=open("d://test1.txt",mode="a+",encoding="utf-8") 新的方法可以避免忘记写close() 1with open("d://test1.txt", encoding="utf-8") as f 导入sys模块 123import syssys.stdout.write(s)sys.stdout.flush()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python文件操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础二]]></title>
    <url>%2F2019%2F02%2F25%2Fpython%E5%9F%BA%E7%A1%80%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[运算符算数运算 运算符 描述 实例 + 加 - 两个对象相加 a+b输出结果 30 - 减 - 得到负数 或是一个数减去另一个数 a-b输出结果 -10 * 乘 - 两个数相乘或是返回一个被重复若干次的字符串 a*b输出结果 200 / 除 - x除以y b/a 输出结果 2 % 取模 - 返回除法的余数 b%a输出结果 0 ** 幂 - 返回x的y次幂 a**b为10的20次方，输出结果10000000000000000000 // 取整除 - 返回商的整数部分 9//2输出结果4, 9.0//2.0输出结果4.0 比较运算 运算符 描述 实例 == 等于 - 比较对象是否相等 (a==b)返回False != 不等于 - 比较两个对象是否不相等 (a!=b)返回True &lt;&gt; 不等于 - 比较两个对象是否不相等 (a&lt;&gt;b)返回True。这个运算符类似!= &gt; 大于 - 返回x是否大于y (a&gt;b)返回False &lt; 小于 - 返回x是否小于y。所有比较运算符返回1表示真，返回0表示假。这分别与特殊变量True和False等价，注意这些变量名的大写 (a&lt;b)返回True &gt;= 大于等于 - 返回x是否大于y (a&gt;=b)返回False &lt;= 小 于等于 - 返回x是否小于y (a&lt;=b)返回True 赋值运算 运算符 描述 实例 = 简单的赋值运算符 c=a+b将a+b的运算结果赋值为c += 加法赋值运算符 c+=a等效于c=c+a -= 减法赋值运算符 c-=a等效于c=c-a *= 乘法赋值运算符 等效于c=c*a /= 除法赋值运算符 c/=a等效于c=c/a %= 取模赋值运算符 c%=a等效于c=c%a **= 幂赋值运算符 等效于c=c**a //= 取整除赋值运算符 c//=a等效于c=c//1 逻辑运算 运算符 描述 实例 and 布尔”与” - 如果x为False，x and y返回False，否则它返回y的计算值 (a and b)返回True or 布尔”或” - 如果x是True，它返回True，否则它返回y的计算值 (a or b)返回True not 布尔”非” - 如果x为True，返回False。如果x为False，它返回True not(a and b)返回False 如果and 和 or 同时存在，则or将整体分成两部分看 成员运算 运算符 描述 实例 in 如果在指定的序列中找到值返回True，否则返回False x在y序列中，如果x在y序列中返回True not in 如果在指定的序列中没有找到值返回True，否则返回False x不在y序列中，如果x不在y序列中返回True 三元运算1result =值1 if 条件 else 值2 如果条件为真：result =值1 如果条件为假 ：sesult =值2 123a = 3b = 7c = a if a&lt;b else b 如果a小于b则把a的值赋给c，相反则把b的值赋给c 身份运算 运算符 描述 实例 is is是判断两个标识是不是引用自一个对象 x is y，如果id(x)等于id(y)，is返回结果1 not is is not是判断两个标识是不是引用自不同对象 x is not y，如果id(x)不等于id(y)，is返回结果1 位运算 运算符 描述 实例 &amp; 按位与运算符 (a&amp;b)输出结果12，二进制解释：0000 1100 丨 按位或运算符 (a丨b)输出结果61，二进制解释：0011 1101 ^ 按位异或运算符 (a^b)输出结果49，二进制解释：0011 0001 ~ 按位取反运算符 (~a)输出结果-61，二进制解释：1100 0011，在一个有符号二进制数的补码形式 &lt;&lt; 左移动运算符 a&lt;&lt;2输出结果240，二进制解释：1111 0000 &gt;&gt; 右移动运算符 a&gt;&gt;2输出结果15，二进制解释：0000 1111 运算符优先级 运算符 描述 ** 指数(最高优先级) ~ + - 按位翻转，一元加号和减号(最后两个方法名为+@和-@) * / % // 乘，除，取模和取整除 + - 加法减法 &gt;&gt; &lt;&lt; 右移，左移运算 &amp; 位’AND’ ^ 丨 位运算符 &lt;= &lt;&gt; &gt;= 比较运算符 &lt;&gt; == != 等于运算符 = %= /= //= -= += *= **= 赋值运算符 is is not 身份运算符 in not in 成员运算符 not or and 逻辑运算符 bytes类型Python3中内置类型bytes和str用法及byte和string之间各种编码转换Python 3最重要的新特性大概要算是对文本和二进制数据作了更为清晰的区分。文本总是Unicode，由str类型表示，二进制数据则由bytes类型表示。Python 3不会以任意隐式的方式混用str和bytes，正是这使得两者的区分特别清晰。你不能拼接字符串和字节包，也无法在字节包里搜索字符串（反之亦然），也不能将字符串传入参数为字节包的函数（反之亦然）. 1234msg = "我爱北京天安门"print(msg)print(msg.encode(encoding="utf-8"))print(msg.encode(encoding="utf-8").decode(encoding="utf-8")) 执行结果： 123我爱北京天安门b'\xe6\x88\x91\xe7\x88\xb1\xe5\x8c\x97\xe4\xba\xac\xe5\xa4\xa9\xe5\xae\x89\xe9\x97\xa8'我爱北京天安门 格式化%s 字符串 例： 123456789101112131415161718192021string="hello"#%s打印时结果是helloprint "string=%s" % string # output: string=hello#%2s意思是字符串长度为2，当原字符串的长度超过2时，按原长度打印，所以%2s的打印结果还是helloprint "string=%2s" % string # output: string=hello#%7s意思是字符串长度为7，当原字符串的长度小于7时，在原字符串左侧补空格，#所以%7s的打印结果是 helloprint "string=%7s" % string # output: string= hello#%-7s意思是字符串长度为7，当原字符串的长度小于7时，在原字符串右侧补空格，#所以%-7s的打印结果是 helloprint "string=%-7s!" % string # output: string=hello !#%.2s意思是截取字符串的前2个字符，所以%.2s的打印结果是heprint "string=%.2s" % string # output: string=he#%.7s意思是截取字符串的前7个字符，当原字符串长度小于7时，即是字符串本身，#所以%.7s的打印结果是helloprint "string=%.7s" % string # output: string=hello#%a.bs这种格式是上面两种格式的综合，首先根据小数点后面的数b截取字符串，#当截取的字符串长度小于a时，还需要在其左侧补空格print "string=%7.2s" % string # output: string= heprint "string=%2.7s" % string # output: string=helloprint "string=%10.7s" % string # output: string= hello %d 整数 %f 浮点数 编码 在python3中不需要申明编码 从英文意思上看，encode和decode分别指编码和解码。在python中，Unicode类型是作为编码的基础类型，即： 12decode encodestr ---------&gt; str(Unicode) ---------&gt; str 12345678910111213141516171819&gt;&gt;&gt; u = '中文' # 指定字符串类型对象u &gt;&gt;&gt; str1 = u.encode('gb2312') # 以gb2312编码对u进行编码，获得bytes类型对象&gt;&gt;&gt; print(str1)b'\xd6\xd0\xce\xc4' &gt;&gt;&gt; str2 = u.encode('gbk') # 以gbk编码对u进行编码，获得bytes类型对象&gt;&gt;&gt; print(str2)b'\xd6\xd0\xce\xc4'&gt;&gt;&gt; str3 = u.encode('utf-8') # 以utf-8编码对u进行编码，获得bytes类型对象&gt;&gt;&gt; print(str3)b'\xe4\xb8\xad\xe6\x96\x87' &gt;&gt;&gt; u1 = str1.decode('gb2312') # 以gb2312编码对字符串str进行解码，获得字符串类型对象&gt;&gt;&gt; print('u1')'中文' &gt;&gt;&gt; u2 = str1.decode('utf-8') # 报错，因为str1是gb2312编码的UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd6 in position 0: invalid continuation byte 其他break 跳出本层循环 continue 跳出本次循环 1234567for i in range(10): print(i) if i ==5: breakelse: print("done")print("done2") 只有正常结束for循环才会执行else的命令，所以done不会被输出 判断是否为数字 isdigit() 取嵌套列表的值 name = [12,23,34,[34,55]] 取55的值 ：name[3][1]]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>运算符</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础一]]></title>
    <url>%2F2019%2F02%2F25%2Fpython%E5%9F%BA%E7%A1%80%E4%B8%80%2F</url>
    <content type="text"><![CDATA[数据类型数字整型 int 长整型 long 浮点型 float 复数 complex 字符str它只是人类可读的一种抽象表示形式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263name="helloworld" name.capitalize() #将字符串变成首字母大写，其他全部小写 name.casefold() #将字符串变成全部变小写 nam.lower() #将字符串变成全部变小写 name.upper() #将字符串变成全部变大写 name.swapcase() #大小写互换 name.center(50,'-') #将字符串长度变成50，且字符串居中,不够的由-填充，如果50后面不写，则默认空格填充 name.ljust(50,'-') #同上，字符串左对齐 name.rjust(50,'-') #同上，字符串右对齐 name.count('e') #查找整个字符串有几个e name.count('e',2,4) #从字符串的第3到4中找有几个e ,含头不含尾 name.startwith() #以..什么开头 name.endwith() #以..什么结尾 name.expandtabs(10) #定义\t的长度 name.find('h') #查找h的位置 name.index('h') #返回h的索引值 name.find('h',2,6) #在3到6之间找第一个h的位置，返回的是整个字符串的位置，找不到-1 name.format() #format的用法是： name=“hello&#123;0&#125;,fuck&#123;1&#125;” name.format('world',144) # output: helloworld,fuck144 “-”.join(["fuck","u","every","day"]) # output:fuck-u-every-day 将列表的内容用指定的字符串串起来，变成一个字符串 name.lstrip() #从左边开始删指定的字符串 name.rstrip() #从右边开始删指定的字符串 name.replace('he','she') #把he替换成she name.replace('he','she',1) #把he替换成she,只替换一次 name.strip() #移除空白 len(name) #判断 name.index("f") #以0开始，索引 name[0:8] #从第1个切到第8个 取头不取尾(切得最后一个不取) name[-6:] #从倒数第5个切到最后一个，因为-1在尾部，取不到，直接不写 name[2::2] #从第3个开始，隔2个取一个 布尔型boolbool，从Python2.3开始Python中添加了布尔类型。布尔类型有两种True和False。对于没有nozero方法的对象默认是True。 bool运算： 以下情况都为False [] 空列表 {} 空字典 空集合 () 空元祖 ‘’ 空字符串 0 数字0 list 列表list [] name=[“萨德”,”委屈”,”多行”,”太容易”,”电风扇”] name[0] 取第一个的值 name.index(“多行”) 查询多行的位置 得到结果 2 name.count(“太容易”) 查询太容易在列表中数量 name.append(“付出”) 追加 name.insert(4,”陈涛”) 把陈涛插到4的位置 name.pop(4) 删除第四个 ()内不写则默认删除最后一个 name.remove(“陈涛”) 删除成涛 del name[0] 删除第一个 name[name.index(“陈涛”)]=”水” 修改陈涛为水 dict 字典字典(dictionary)是除列表之外python中最灵活的内置数据结构类型。列表是有序的对象结合，字典是无序的对象集合。两者之间的区别在于：字典当中的元素是通过键来存取的，而不是通过偏移存取。 字典由键和对应的值组成。字典也被称作关联数组或哈希表。基本语法如下： 1dict = &#123;'Alice': '2341', 'Beth': '9102', 'Cecil': '3258'&#125;; 也可如此创建字典： 12dict1 = &#123; 'abc': 456 &#125;;dict2 = &#123; 'abc': 123, 98.6: 37 &#125;; 可以字典中加字典，嵌套 key必须是唯一的 实例：name = {1 : [’fuck‘], 2 : [‘fuck’], 3: {’name‘:’d‘}, 34 : [‘wzc’,’hsy’] } 增name[34].append(“love”) 在key为34中添加值love name[”nice“]=”whatever“ 在name中新插入key为nice,value为whatever的键/值对 删name.pop(34) 删除key为34的键/值对 del name[34] 删除key为34的键/值对 改name[34][0]=’’love’’ 将key为34内的第一个值改为love name[24]=name.pop(34) 将key名为34的改成24，值不变 查name.get(34) 查找key为34的值，没有则返回None name[34] 查找key为34的值，没有则报错 113 in name 判断字典中是否有key为113的键/值对 name.keys() 查找字典中所有的key name.values() 查找字典中所有的值 循环for i in name: print( i ,name[i] ) 更新name.update(name1) 将name1的键值对合并到name中，如果两者之间有相同名字的key，则取name1中的值 set 集合集合与字典的区别是没有key值 特点：天然去重，无序 12345678910111213141516171819202122232425262728linux = &#123;"alex", "jack", "rain", "lizhi", "sb", "lizhi"&#125;python = &#123;"sb", "alex", "mack", "rachel"&#125; print(linux.intersection(python)) # 交集print(linux &amp; python) # 交集print(linux.difference(python)) # 差集 linux中有而python中没有print(linux - python) # 差集 linux中有而python中没有print(linux.union(python)) # 并集print(linux | python) # 并集print(linux.symmetric_difference(python)) # 对称 互相不在的都打印print(linux ^ python) # 对称 互相不在的都打印 linux.add() #增加 linux.clear() #把linux集合中内容删光 linux.update(python) #把python合并到linux集合中 linux.discard("alex") #把linux中的alex删除，元素不存在不会报错 linux.remove('alex') #把linux中的alex删除，元素不存在会报错 linux.pop() #随机删除一个 linux.issubset(python) #判断linux是不是python的子集 linux.issuperset(python) #判断linux是不是python的父集 linux.isdisjoint(python) #如果两个集合没有任何关联，则返回Ture tuple 元祖元组类型在很多操作上都跟列表一样，许多用在列表上的例子在元组上照样能跑，我们有一节内容专门讲解元组类型。它们的主要不同在于元组是不可变的，或者说是只读的，所以那些用于更新列表的操作，比如用切片操作来更新一部分元素的操作，就不能用于元组类型 12345678CPython&gt;&gt;&gt; a = ('a','123',['a',123])&gt;&gt;&gt; a('a', '123', ['a', 123])&gt;&gt;&gt; type(a)&lt;class 'tuple'&gt;&gt;&gt;&gt; tu = tuple('abcde')&gt;&gt;&gt; tu('a', 'b', 'c', 'd', 'e') 列表与字典的一个methodname=[21,23,454[34,123]] h=name.copy() 当改变h[0],h[1],h[2]这些值时，name中的不变 但改变h[3]时 h[3][0]=56 name中也会变 同理 n1={12:”asda”,24:”asdasd”,33:[78,34]} n2=n1.copy() 更改n1[12]的值，n2不变 更改 n1[33][0]的值，n2中也会变 转换类型int(x [,base ]) 将x转换为一个整数 long(x [,base ]) 将x转换为一个长整数 float(x ) 将x转换到一个浮点数 complex(real [,imag ]) 创建一个复数 str(x ) 将对象 x 转换为字符串 repr(x ) 将对象 x 转换为表达式字符串 eval(str ) 用来计算在字符串中的有效Python表达式,并返回一个对象 tuple(s ) 将序列 s 转换为一个元组 list(s ) 将序列 s 转换为一个列表 chr(x ) 将一个整数转换为一个字符 unichr(x ) 将一个整数转换为Unicode字符 ord(x ) 将一个字符转换为它的整数值 hex(x ) 将一个整数转换为一个十六进制字符串 oct(x ) 将一个整数转换为一个八进制字符串 编码utf -8 英文1个字节 中文3个字节 gbk 中文2个字节]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo的next主题详细配置]]></title>
    <url>%2F2019%2F02%2F23%2Fhexo%E7%9A%84next%E4%B8%BB%E9%A2%98%E8%AF%A6%E7%BB%86%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[在 Hexo 中有两份主要的配置文件，其名称都是 _config.yml。 其中，一份位于站点根目录下，主要包含 Hexo 本身的配置；另一份位于主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项。 为了描述方便，在以下说明中，将前者称为站点配置文件， 后者称为主题配置文件。 以下所有终端执行的命令都在你的Hexo根目录下 基本信息配置打开 站点配置文件 ，找到Site模块 123456title: 标题subtitle: 副标题description: 描述author: 作者language: 语言（简体中文是zh-Hans）timezone: 网站时区（Hexo 默认使用您电脑的时区，不用写） 关于 站点配置文件 中的其他配置可参考站点配置 菜单设置菜单包括：首页、归档、分类、标签、关于等等 我们刚开始默认的菜单只有首页和归档两个，不能够满足我们的要求，所以需要添加菜单，打开 主题配置文件 找到Menu Settings 看看你需要哪个菜单就把哪个取消注释打开就行了； 关于后面的格式，以archives: /archives/ || archive为例： || 之前的/archives/表示标题“归档”，关于标题的格式可以去themes/next/languages/zh-Hans.yml中参考或修改 ||之后的archive表示图标，可以去Font Awesome中查看或修改，Next主题所有的图标都来自Font Awesome Next主题样式设置我们百里挑一选择了Next主题，不过Next主题还有4种风格供我们选择，打开 主题配置文件 找到Scheme Settings 12345# Schemes# scheme: Muse# scheme: Mist# scheme: Piscesscheme: Gemini 4种风格大同小异，本人用的是Gemini风格，你们可以选择自己喜欢的风格 侧栏设置开启侧边栏社交链接1234567891011# Social linkssocial: GitHub: https://github.com/hydcoder Weibo: https://weibo.com/3180967953/profile?rightmod=1&amp;wvr=6&amp;mod=personinfo # 等等social_icons: enable: true # Icon Mappings. GitHub: github Weibo: weibo 开启打赏功能123reward_comment: 坚持原创技术分享，您的支持将鼓励我继续创作！wechatpay: 你的微信收款码链接alipay: 你的支付宝收款码链接 开启友情链接1234links_title: Linkslinks: MacTalk: http://macshuo.com/ Title: http://example.com/ 开启订阅微信公众号1234wechat_subscriber:enabled: trueqcode: /uploads/wechat-qcode.jpgdescription: 欢迎您扫一扫上面的微信公众号，订阅我的博客！ 头像设置打开 主题配置文件 找到Sidebar Avatar字段 12# Sidebar Avataravatar: /images/header.jpg 这是头像的路径，只需把你的头像命名为header.jpg（随便命名）放入themes/next/source/images中，将avatar的路径名改成你的头像名就OK啦！ 设置侧边栏设置圆形可旋转头像 找到生成的Hexo目录\themes\next\source\css_common\components\sidebar下的sidebar-author.styl，将里面的css样式内容全部替换为： 123456789101112131415161718192021222324252627282930313233.site-author-image &#123; margin: 0 auto; padding: $site-author-image-padding; max-width: $site-author-image-width; height: $site-author-image-height; border: $site-author-image-border-width solid $site-author-image-border-color; border-radius: 50%; -webkit-border-radius: 50%; -moz-border-radius: 50%; transition: 1.4s all;&#125;.site-author-image:hover &#123; -webkit-transform: rotate(360deg); -moz-transform: rotate(360deg); -ms-transform: rotate(360deg); -transform: rotate(360deg);&#125;.site-author-name &#123; margin: $site-author-name-margin; text-align: $site-author-name-align; color: $site-author-name-color; font-weight: $site-author-name-weight;&#125;.site-description &#123; margin-top: $site-description-margin-top; text-align: $site-description-align; font-size: $site-description-font-size; color: $site-description-color;&#125; 设置首页不显示全文(只显示预览)打开主题配置文件_config.yml，ctrl + F搜索找到”auto_excerpt”，可以看见 12345# Automatically Excerpt. Not recommand.# Please use &lt;!-- more --&gt; in the post to control excerpt accurately.auto_excerpt:enable: falselength: 150 把enable改为对应的false改为true，length就是预览显示的文字长度，你可以根据你的需要进行更改，然后重新部署，再进主页，你就发现你首页的文章多了一个阅读全文的按钮。 添加动态背景先上张图 打开生成的Hexo目录\themes\next/layout/_layout.swig文件，在 &lt; head&gt;中的添加代码 123&#123;% if theme.canvas_nest %&#125;&lt;script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"&gt;&lt;/script&gt;&#123;% endif %&#125; 打开主题配置文件，搜索canvas_nest，将其改成true 1canvas_nest: true 什么？线条太多了？没事，来看看怎么让线条变少点 在上一步修改的主题配置文件中，把刚才的那些代码改成下面这样： 1234&#123;% if theme.canvas_nest %&#125;&lt;script type="text/javascript"color="0,0,255" opacity='0.7' zIndex="-2" count="99" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"&gt;&lt;/script&gt;&#123;% e 配置项说明 color ：线条颜色, 默认: ‘0,0,0’；三个数字分别为(R,G,B) opacity: 线条透明度（0~1）, 默认: 0.5 count: 线条的总数量, 默认: 150 zIndex: 背景的z-index属性，css属性用于控制所在层的位置, 默认: -1 分类和标签设置这里主要说的是在编写文章的时候，怎么给文章设置标签和分类。 首先通过hexo n &quot;name&quot;命令来新建一个页面，在source/_posts目录下找到刚才新建的name.md文件，用Typora或者notepad++t打开(推荐Typora) 1234title: namedate: 2014-08-05 11:15:00 tags: --- 页面默认就是长这样的，可以编辑标题、日期、标签和内容，但是没有分类的选项。我们可以手动加入categories:项,但是下次创建新的页面的时候还是没有，所以我们直接打开scaffolds/post.md文件，在tages:上面加入categories:,保存后，重新执行hexo n ‘name’命令，会发现新建的页面里有categories:项了。 scaffolds目录下，是新建页面的模板，执行新建命令时，是根据这里的模板页来完成的，所以可以在这里根据你自己的需求添加一些默认值。 设置分类列表在我们编辑文章的时候，直接在categories:项填写属于哪个分类，但如果分类是中文的时候，路径也会包含中文。 比如分类我们设置的是： 1categories: 开车 那在生成页面后，分类列表就会出现开车这个选项，他的访问路径是： 1*/categories/开车 我们都知道，有时候中文路径可能会出现一些奇奇怪怪的问题，所以我们需要路径名和分类名分别设置。 打开站点配置文件_config.yml，找到如下位置做更改： 1234567# Category &amp; Tagdefault_category: uncategorizedcategory_map: 开车: drive 生活: life 其他: othertag_map: 在这里category_map:是设置分类的地方，每行一个分类，冒号前面是分类名称，后面是访问路径。可以提前在这里设置好一些分类，当编辑的文章填写了对应的分类名时，就会自动的按照对应的路径来访问。 设置标签在编辑文章的时候，tags:后面是设置标签的地方，如果有多个标签的话，可以用下面两种办法来设置： 第一种： 1tages: [标签1,标签2,...标签n] 第二种： 12345 tages: - 标签1- 标签2...- 标签n 添加文章更新时间修改（博客主目录）/themes/next/layout/_macro/post.swig 文件，在&lt;span class=&quot;post-time&quot;&gt;...&lt;/span&gt;标签后添加 12345678&#123;%if post.updated and post.updated &gt; post.date%&#125; &lt;span class="post-updated"&gt; &amp;nbsp; | &amp;nbsp; &#123;&#123; __('post.updated') &#125;&#125; &lt;time itemprop="dateUpdated" datetime="&#123;&#123; moment(post.updated).format() &#125;&#125;" content="&#123;&#123; date(post.updated, config.date_format) &#125;&#125;"&gt; &#123;&#123; date(post.updated, config.date_format) &#125;&#125; &lt;/time&gt; &lt;/span&gt;&#123;% endif %&#125; 根据博客配置文件中的 language 参数修改对应的语言配置文件（博客主目录）/themes/next/languages/zh_Hans.yml 12post: updated: 更新于 修改主题配置文件（博客主目录）/themes/next/_config.yml，增加一行 1display_updated: true 或者写文章的时候可以直接在文章开头设置更新时间，没有这参数的话将会显示md文件的修改日期 1updated: 2018-01-01 12:00:00 添加搜索功能安装 hexo-generator-searchdb 插件 1$ npm install hexo-generator-searchdb --save 打开 站点配置文件 找到Extensions在下面添加 123456# 搜索search: path: search.xml field: post format: html limit: 10000 3、打开 主题配置文件 找到Local search，将enable设置为true 添加阅读全文按钮因为在你的博客主页会有多篇文章，如果你想让你的文章只显示一部分，多余的可以点击阅读全文来查看，那么你需要在你的文章中添加 1&lt;!--more--&gt; 其后面的部分就不会显示了，只能点击阅读全文才能看 修改文章内链接文本样式打开文件 themes/next/source/css/_common/components/post/post.styl，在末尾添加 12345678910.post-body p a &#123; color: #0593d3; border-bottom: none; border-bottom: 1px solid #0593d3; &amp;:hover &#123; color: #fc6423; border-bottom: none; border-bottom: 1px solid #fc6423; &#125;&#125; 其中选择 .post-body 是为了不影响标题，选择 p 是为了不影响首页“阅读全文”的显示样式,颜色可以自己定义。 设置网站缩略图标从网上看了很多设置方法都是说把favicon.ico放到站点目录的source目录下就可以了，可是我试了好多遍，并不行 我的设置方法是这样的：把你的图片（png或jpg格式，不是favicon.ico）放在themes/next/source/images里，然后打开 主题配置文件 找到favicon，将small、medium、apple_touch_icon三个字段的值都设置成/images/图片名.jpg就可以了，其他字段都注释掉。 设置文章字体的颜色、大小 如果想设置某一句的颜色或大小，只需用html语法写出来就行了 1234接下来就是见证奇迹的时刻&lt;font color="#FF0000"&gt; 我可以设置这一句的颜色哈哈 &lt;/font&gt; &lt;font size=6&gt; 我还可以设置这一句的大小嘻嘻 &lt;/font&gt; &lt;font size=5 color="#FF0000"&gt; 我甚至可以设置这一句的颜色和大小呵呵&lt;/font&gt; 设置文字居中1&lt;center&gt;这一行需要居中&lt;/center&gt; 添加评论系统目前国内比较有名的多说、网易云跟帖评论系统都已停止服务了，国外的Disqus评论系统还得需要翻墙，所以不推荐使用，剩下的还有搜狐畅言、友言、来必力等。本来想使用畅言的，结果注册完之后还得要求备案，我只想说F开头的那个单词，果断放弃。后来选择了友言 1、进入友言官网注册、登录步骤我就不介绍了2、登录完成之后，点击获取代码，你会发现出来了一段代码，里面有你的uid=12345673、打开 主题配置文件 找到youyan_uid将值设置为上面的uid就可以了 添加站点访问计数站点访问计数有名的就是不蒜子，使用起来非常方便1、安装脚本打开 themes/next/layout/_partial/footer.swig，将下面这段代码添加到里面 12345678910&lt;div&gt;&lt;script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"&gt;&lt;/script&gt;&lt;span id="busuanzi_container_site_pv" style='display:none'&gt; 本站总访问量 &lt;span id="busuanzi_value_site_pv"&gt;&lt;/span&gt; 次 &lt;span class="post-meta-divider"&gt;|&lt;/span&gt;&lt;/span&gt;&lt;span id="busuanzi_container_site_uv" style='display:none'&gt; 有&lt;span id="busuanzi_value_site_uv"&gt;&lt;/span&gt;人看过我的博客啦&lt;/span&gt;&lt;/div&gt; 添加的位置如下图，可自行根据个人喜好更换位置 2、以上只是显示站点的访问次数，如果想显示每篇文章的访问次数，打开 themes/next/layout/_macro/post.swig，在第一行增加is_pv字段 1&#123;% macro render(post, is_index, is_pv, post_extra_class) %&#125; 然后将这段代码插入到里面 1234&#123;% if is_pv %&#125; &lt;span class="post-meta-divider"&gt;|&lt;/span&gt; &lt;span id="busuanzi_value_page_pv"&gt;&lt;/span&gt;次阅读&#123;% endif %&#125; 插入的位置 然后再打开 themes/next/layout/post.swig，这个文件是文章的模板，给render方法传入参数（对应刚才添加的is_pv字段） 最后再打开 themes/next/layout/index.swig，这个文件是首页的模板，给render方法传入参数（对应刚才添加的is_pv字段） OK！设置完毕 去掉文章目录标题的自动编号我们自己写文章的时候一般都会自己带上标题编号，但是默认的主题会给我们带上编号，很是别扭，如何去掉呢？打开主题配置文件，找到 123456789# Table Of Contents in the Sidebartoc: enable: true # Automatically add list number to toc. number: true # If true, all words will placed on next lines if header width longer then sidebar width. wrap: false 将number改为false即可 自定义样式 引用需加入custom.styl的代码 文件位置：~/blog/themes/next/source/css/_custom/custom.styl 123456789// 自定义的引用样式blockquote.question &#123; color: #555; border-left: 4px solid rgb(16, 152, 173); background-color: rgb(227, 242, 253); border-top-right-radius: 3px; border-bottom-right-radius: 3px; margin-bottom: 20px;&#125; 文字颜色改color的值 背景色改background-color的值 边框颜色和粗细改border-left的值 效果： 内容 使用方法： 1&lt;blockquote class="question"&gt;内容&lt;/blockquote&gt; 修改hexo的主题nexT中的Pisces主题宽度在source/css/_schemes/Picses/_layout.styl文件末尾添加如下代码 12345678910111213141516171819202122232425262728293031323334// 以下为新增代码！！header&#123; width: 90% !important; &#125;header.post-header &#123; width: auto !important;&#125;.container .main-inner &#123; width: 90%; &#125;.content-wrap &#123; width: calc(100% - 260px); &#125;.header &#123; +tablet() &#123; width: auto !important; &#125; +mobile() &#123; width: auto !important; &#125;&#125;.container .main-inner &#123; +tablet() &#123; width: auto !important; &#125; +mobile() &#123; width: auto !important; &#125;&#125;.content-wrap &#123; +tablet() &#123; width: 100% !important; &#125; +mobile() &#123; width: 100% !important; &#125;&#125; 更多还有其他更多的主题配置，请查看主题配置 还有其他更多的插件，请查看Hexo插件]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>next主题配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何更换hexo博客主题]]></title>
    <url>%2F2019%2F02%2F23%2F%E5%A6%82%E4%BD%95%E6%9B%B4%E6%8D%A2hexo%E5%8D%9A%E5%AE%A2%E4%B8%BB%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在成功用github+hexo搭建好个人博客之后，原生的主题一般不大讨喜。在此，简单介绍一下如何找一个自己喜欢的主题并运用到自己的博客中： 挑个好看的主题hexo官方：Themes 知乎话题：有哪些好看的 Hexo 主题？ 下载用git bash，进入到博客的本地目录中 然后使用clone的方法将想要的主题下载下来。（我选用的是NexT主题） 1$ git clone https://github.com/theme-next/hexo-theme-next themes/next 修改配置文件，安装git克隆完成后，打开当前目录下的“_config.yml”配置文件。 找到theme的配置选项，一般在文件的最后。之后，将theme选项配置为我们新下载好的next主题即可。（“：”冒号之后空格不可少） 调试，发布回到git bash，输入调试命令： 1hexo server --debug 在浏览器中输入localhost:4000查看 在本地查看无误之后，输入生成和发布命令,就可已将新主题发布到自己的博客网站上了 12hexo ghexo d 如出现缓存引起的异常，可以在生成命令前执行清除缓存命令 1hexo clean 完成做完这些之后，就可以打开你的博客网站，查看新更换的主题效果了。]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo更换主题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用hexo+github搭建属于自己的博客]]></title>
    <url>%2F2019%2F02%2F23%2F%E4%BD%BF%E7%94%A8hexo-github%E6%90%AD%E5%BB%BA%E5%B1%9E%E4%BA%8E%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[一、注册GitHub账号（已经有GitHub账号的请忽略这一步）先在Github注册一个账号:https://github.com/ 新建项目，项目必须要遵守格式：账户名.github.io，不然接下来会有很多麻烦。并且需要勾选Initialize this repository with a README 在建好的项目右侧有个settings按钮，点击它，向下拉到GitHub Pages，你会看到那边有个网址，访问它，你将会发现该项目已经被部署到网络上，能够通过外网来访问它。 二、环境搭建下载Node.js安装文件现在电脑基本都是64位的，我就放64位的下载地址：https://nodejs.org/dist/v8.9.4/node-v8.9.4-x64.msi 或者自行到官网下载最新版本： https://nodejs.org 安装Git：Git下载包（64位） Git下载包（32位） 完成之后到桌面空白处单击鼠标右键，选择Git Bash Here进入bash窗口输入命令 node -v 和 npm -v 验证安装是否成功,成功界面如下 三、Hexo安装Hexo简介Hexo是什么呢？也许引用Hexo官方文档里面的说明是再好不过了： 1Hexo is a fast, simple and powerful blog framework. You write posts in Markdown (or other languages) and Hexo generates static files with a beautiful theme in seconds. 1Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 安装Git下载地址：https://git-scm.com/download，按照默认傻瓜式安装就好了 补充一句，如果你已经安装了Git，你可以通过Git本身获得最新的开发版本： 1$ git clone https://github.com/git/git 完成之后到桌面空白处单击鼠标右键，如果有出现Git Bash Here选项则证明已经安装成功 下载Hexo在桌面空白处单击鼠标右键，选择Git Bash Here进入bash窗口，在自己认为合适的地方创个文件夹，我是在D盘建了一个blog文件夹。然后通过命令行进入到该文件夹里面 再输入命令 npm install -g hexo 下载Hexo 1$ npm install -g hexo 等待完成之后，输入命令 hexo -v 验证安装是否成功 初始化输入hexo init，初始化该文件夹 输入npm install，安装所需要的组件 输入hexo g，首次体验Hexo 输入hexo s，开启服务器，访问该网址，正式体验Hexo 问题：假如页面一直无法跳转，那么可能4000端口被占用了。此时我们ctrl+c停止服务器，接着输入hexo server -p 端口号来改变端口号 那么出现如下图就成功了 四、将Hexo与Github page联系起来安装插件打开git bash，进入hexo根文件夹，输入npm install hexo-deployer-git --save 命令安装插件 配置SSH设置全局配置user.name 和user.email（如果是第一次的话） 12git config –-global user.name “shuaibi” //(“”的账号是刚才Github里面自己注册的账号) git config –-global user.email “okjbk.gmail.com” //(""的邮箱是你自己注册的邮箱) 输入cd ~/.ssh，检查是否有.ssh的文件夹 输入ssh-keygen -t rsa -C &quot;ojbk.gmail.com&quot;(&quot;&quot;中间写你直接设置的邮箱)，连续三个回车，生成密钥，最后得到了两个文件：id_rsa和id_rsa.pub（默认存储路径是：C:\Users\Administrator.ssh）。 输入eval &quot;$(ssh-agent -s)&quot;，添加密钥到ssh-agent 再输入ssh-add ~/.ssh/id_rsa，添加生成的SSH key到ssh-agent 登录Github，点击头像下的settings，添加ssh 新建一个new ssh key，将id_rsa.pub文件里的内容复制上去 回到git bash 输入ssh -T git@github.com，测试添加ssh是否成功。如果看到Hi后面是你的用户名，就说明成功了 问题: 假如ssh-key配置失败，那么只要以下步骤就能完全解决 首先，清除所有的key-pairssh-add -Drm -r ~/.ssh删除你在github中的public-key 重新生成ssh密钥对ssh-keygen -t rsa -C “xxx@xxx.com“ 接下来正常操作在github上添加公钥public-key:1、首先在你的终端运行 xclip -sel c ~/.ssh/id_rsa.pub将公钥内容复制到剪切板2、在github上添加公钥时，直接复制即可3、保存 测试： 在终端 ssh -T git@github.com 配置配置Deployment，在根文件夹中，找到_config.yml文件，修改repo值（在末尾） 1234deploy: type: git repository: git@github.com:RobotNo42/RobotNo42.github.io.git branch: master repo值是你在github项目里的ssh（右下角） 部署用git bash部署hexo到github hexo server 或者 hexo s hexo generate 或者 hexo g hexo deploy 或者 hexo d 看到这样的进程，代表成功部署hexo到github 等待10分钟左右，打开用户名.github.io,会出现如下界面（代表成功搭建博客）：]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo+github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LINUX命令三]]></title>
    <url>%2F2019%2F02%2F23%2FLINUX%E5%91%BD%E4%BB%A4%E4%B8%89%2F</url>
    <content type="text"><![CDATA[网络相关配置ifconfig 查看ip信息 远程复制 scp /etc/h.txt 192.168.1.1:/tmp 配置ssh（之后访问无需密码）： ssh-keygen ssh-copy-id -i 192.168.1.16 赋值变量 x=2 调用x echo $x 取消变量 unset x 设置别名 alias x=‘ls /’ 将命令得到的结果赋值到变量 x=$(ls) 搜索文件 ls [a-z][0-9].txt []代表在中间取一个值, a-z代表aAbBcC…..z不包含Z ls [!0-9],txt 查找不以数字开头的文件 执行历史命令 ！638 查看上条命令执行是否成功 echo $? 成功则为0 注释 || 前面命令成功，则后面不执行 ；只有前面命令失败后面才执行 &amp;&amp; 只有前面的命令执行成功才会执行后面的命令 \ 转义符号 ? 匹配一个任意字符 例： ls ???.txt 固化命令在登录时就加载出命令 在/etc/bashrc 文件中添加想要的命令 grep命令grep -A 2 ‘fuck’ /etc/passwd 显示查询结果及后两行 grep -B 2 ‘fuck’ /etc/passwd 显示查询结果及前两行 grep -C 2 ‘fuck’ /etc/passwd 显示查询结果及前后两行 grep -c ‘fuck’ /etc/passwd 显示查询行数 grep -i ‘fuck’ /etc/passwd 无视大小写查询 grep -v ‘fuck’ /etc/passwd 取目标之外的剩余结果 grep -w ‘fuck’ /etc/passwd 单词匹配 grep -rl ‘fuck’ /etc/passwd 匹配文件内容中带fuck的文件路径 正则grep ‘^root’ 匹配以root开头的 grep ‘root$’ 匹配以root结尾的 grep ‘a.b’ .代表任意一个字符 grep ‘ab‘ 代表b有0个或者多个 grep ‘ab?’ 代表b有0个或者1个 egrep ‘ab+’ 必须用egrep +代表b有1个或者多个 egrep ‘ab{2}’ 2个b egrep ‘ab{2，4}’ 2到4个b egrep ‘ab{2，}’ 2个以上b egrep ‘[abc\ / -]’ 含abc/-中一个字符的 [a-z] 代表所有的小写字母 [A-Z] 代表所有的大写字母 [a-Z] 代表所有的大小写字母 注意点如果要匹配的是-本身，则必须放到最后[asd-] echo ^[^0-9] 匹配不是数字开头的 sed命令sed ‘3d’ 删除第三行 sed ‘1,4d’ 删除1-4行 sed ‘1;4d’ 删除第1行和第4行 sed ‘s/sb/fuck’ 把所有行的第一个sb换成fuck sed ‘s/sb/fuck/g’ 把所有行的所有sb换成fuck sed ‘3p’ 打印第三行 sed ‘3c 123456’ 把第三行改成123456 sed ‘3a 123’ 在第三行后插入123 sed ‘3i 123’ 在第三行前插入123 sed’/^root/d’ 加入正则法 sed -r ‘/^[0-9][a-Z]+sb$/ s/sb/SB/g’ r为扩展模式 sed -ri 多加一个i则是直接将文件内容改掉，而不是仅仅输入到终端 sed -r ‘s/^([a-Z]+)([^a-Z])([a-Z]+)([^a-Z])/\3\2\1\4/‘ 将第一个单词和第三个单词换位置 sed -r ‘s/ //g’ 将所有的空格去掉 sed -r ‘s/[0-9]//g’ 将所有的数字去掉 awk文本处理awk -F: ‘{print $1,$7}’ 打印以：为分隔符取第1段和第7段 (:后面加空格) awk -F: ‘{print $1,$NF}’ 打印以：为分隔符取第1段和最后一段 awk -F: ‘NR&lt;=3{print $1,NR}’ 打印前三行的第一段 awk -F: ‘NR&lt;=3{print NR,”—–”,$1}’ 打印出前三段 1——root 的样式 awk -F: ‘/log$/{print $1}’ 匹配有log的行，打印第1段 awk -F: ‘$1~/^r.*t$/{print $3}’ 匹配第一段中以r开头t结尾的行，并打印出这些行的第三段 awk -F: ‘$1==”root”{print $3,NR}’ 匹配第一段是root的行，并打印出这些行的第三段和行号 awk -v x=$count -F: ‘$3&gt;=x{print NR,$1}’ 匹配第三段大于参数x的行，打印行号和第一段 其他命令cat a.txt |sort |uniq 排序 去重 du -sh 统计文件大小 find /file -name “*.txt” 查找file文件夹中以txt结尾的文件 find /file -size +30M 查找file文件夹中大于30M的文件 find /file -size +10M -30M 查找file文件夹中大于10M小于30M的文件 变量linux 没有数据类型之分 set 显示所有变量 env 显示环境变量 变量关系操作test [] 括号里前后要空格 测试数值[ $x -gt $y ] 判断x的值大于y [ $x -ge $y ] 判断x大于等于y [ $x -lt $y ] 判断x小于y [ $x -le $y ] 判断x小于等于y [ $x -eq $y ] 判断x等于y [ $x -ne $y ] 判断x不等于y [ $x -gt $y -a $a -eq $b ] 判断x大于y并且a等于b [ $x -gt $y -o $a -eq $b ] 判断x大于y或者a等于b 测试文件状态-d 目录 -f 普通文件- -w 可写 -r 可读 -x 可执行 3.字符串测试 = 两字符串相等 != 两字符串不相等 -z 空串 -n 非空串 赋值运算符 ((x=x+1)) ——–((x+=1)) echo $((x-=2)) expr $x + $y echo “scale=2;20/100” | bc -l 保留两位小数 bc要先安装]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LINUX命令二]]></title>
    <url>%2F2019%2F02%2F22%2FLINUX%E5%91%BD%E4%BB%A4%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[打包压缩打包命令 tar -cvf /test.tar /a.txt /b.txt /c.txt 查看包内的内容 tar -tf /test.tar 解压包到当前目录 tar -xvf /test.tar 解压包到指定目录 tar -xvf /test.tar -C /try 压缩文件 gzip /test.tar (压缩快但大) 或者bzip2 /test.tar （压缩慢但小） 解压文件 tar -xf /test.tar.zp tar-xf /test.tar.bz2 打包并同时压缩文件tar -cvzf /test.tar.zp /a.txt /b.txt /c.txt 或 tar -cvjf /test.tar.bz2 /a.txt /b.txt /c.txt 如果要连同目录一起压缩则最后用/ 如果只想压缩目录下面的文件则/* vi查看并编辑文档 vim 按a 编辑 按 :wq 保存并退出 q！不保存 x 小写的x表示向后删除一个字符,也就是删除光标所在字符 nx n表示数字，表示向后删除每个字符，例如：10x表示删除包括光标在内的后面10个字符 dd 删除当前一行 ,就是截切 ndd删除n行（例如3dd删除3行） yy复制一行 nyy复制n行 p 粘贴到目标位置的下一行 P 粘贴到目标位置的上一行 u 撤销上一步操作 ctrl+r 返回前一步 gg 光标移动到文件的第一行 G 光标移动到文件的最后一行 nG 光标移动到文件的第n行 dgg 删除光标所在行到第一行数据 dG 删除光标所在行到最后一行数据 磁盘分区/dev fdisk -l /dev/sda 查看磁盘信息 fdisk /dev/sdb 进入磁盘分区 p 输出目前磁盘分区信息 n 分区 分为p主分区 e扩展分区 d 删除分区 给分区装装指定系统 mkfs.xfs /dev/sdb1 挂载一个目录 mount /dev/sdb1 /test 卸除挂载目录 umount /dev/sdb1 一个分区挂载两个目录时，则两个目录同时指向该分区，即同步 df 查看磁盘分区信息 df-Th 创建软连接相当于创建快捷方式ln -s /test/a.txt /sb/a.txt 前面是被创建的软连接 内存查看内存信息 swapon -s 增加内存区 mkswap /dev/sdb2 swapon -a /dev/sdb2 删除内存区swapoff /dev/sdb2 查看内存 free 进程firefox &amp; 后台运行程序 ps aux 查看全部进程 ps aux|grep fire 查找带fire的进程 pgrep firefox 查找firefox进程号 kill -9 3315 强制杀死进程(3315代表进程编号) pkill -9 firefox 指定名称的杀死进程 软件安装二进制软件安装 rpm -ivh /vsf-3.0.2-9.e17.x86_64.rpm覆盖安装 rpm -ivh /vsf-3.0.2-9.e17.x86_64.rpm –force 查看系统中所有安装的rpm包 rpm -qa 查看指定的包 rpm -qa|grep vsf 查看rpm包安装在哪 rpm -ql vsf 查看rmp包详细信息 rpm -qi vsf 查看文件是由那个包产生 rpm -qf /test/b1.txt 删除rmp包 rmp -e vsf 使用yum安装和卸载软件，有个前提是yum安装的软件包都是rpm格式的 yum update 升级系统 yum install ～ 安装指定软件包 yum update ～ 升级指定软件包 yum remove ～ 卸载指定软件 yum grouplist 查看系统中已经安装的和可用的软件组，可用的可以安装 yum grooupinstall ～安装上一个命令显示的可用的软件组中的一个 源代码安装python安装 python官网下载file源代码 安装环境 查看group列表 yum grouplist 安装组包 yum groupinstall ‘开发工具’ -y 解压文件 tar -xvf pytho-3.7.0.tgz cd到解压好的文件目录，更改源码包安装路径 ./configure –prefix=/usr/local/python3.7 编码 make 安装 make install（安装时会出现下面两种错误 1. 需要安装zlib包 yum install zlib* 2.ModuleNotFoundError: No module named ‘_ctypes’ 解决方法：3.7版本需要一个新的包libffi-devel，安装此包之后再次进行编译安装即可 yum install libffi-* 把python3.7加到path环境中 更改profile文件 vim /etc/profile 在文件的最后面加上 PATH=$PATH:/usr/local/python3.7/bin export PATH netstat -tunapl 查看网络状态]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LINUX命令一]]></title>
    <url>%2F2019%2F02%2F22%2FLINUX%E5%91%BD%E4%BB%A4%E4%B8%80%2F</url>
    <content type="text"><![CDATA[快捷键：ctrl+c 取消命令 ctrl+l 清屏 命令：更换用户 su - 或sudo su 关机 init 0 重启 init 6 立即关机 shutdown -h now 查询当前用户 who am i 查看当前日期 date 修改当前日期 date -s “2012-01-02 14:00:00”（必须切换到root用户） 查看今天日历 cal 查看某天 cal 日月年（cal 3 4 2012） 改密码 passwd 查看文件下的子文件 ls 查看文件夹下的子文件详细信息 ls -l (简写ll) 查看文件的详细信息 ls -dl(简写ll -d) 查看文件夹下的所有文件包括隐藏文件 ls-a 切换目录 cd 退到上级目录 cd ,, 返回到上一次的目录 cd - 查看当前目录 pwd 递归建文件夹 mkdir -p 改名/移动 mv /a/b1 /a/b2(把a文件下的b1改成b2) mv /a/b1 /z/(把b1移动到z文件下) 文件复制顺便改名 cp /a/b1 /a/b2 文件夹的复制 cp -rf /a/b /c 删除文件夹 rm 删除文件夹下的所有子文件 rm -rf (不建议使用，最好用mv /a /tmp/ 移动到临时文件，还可以还原） ,如果文件带特殊符号，则加上“”即可删除 创建文件 touch a.txt 查看内容 cat 百分比查看 more 分页查看 less 查看前三行 head - n3 查看后三行 tail -n3 监控文件 tail -f 覆盖内容 echo 内容 &gt; 新增内容 echo 内容 &gt;&gt; 查看历史命令 history 使用第57行的历史命令 !57 直接修改密码 echo 123456 | passwd –stdin Messiless 用户信息文件 /etc/passwd 用户密码文件 /etc/shadow 用户组 /etc/group 用户组密码 /etc/gshadow 创建hsy用户 useradd hsy 完全删除hsy用户 userdel -r hsy 第一段代表文件权限信息，第一个数字是-代表普通文件，d则是目录 ，后面的一堆分3个3个来看，rwx代表属主的权限（可读可执行可写） r-x代表属组的权限（可读可执行） r-x代表其他用户的权限（可读可执行） 在jack组中附加一个tom用户 usermod -G jack tom 手动创建一个用户的流程 /etc/passwd /etc/shadow /etc/group /etc/gshaow mkdir /home/hsy cp -r /etc/skel/.[!.]* /home/hsy chown -R hsy.hsy /home/hsy touch /var/spool/mail/hsy chown -R hsy.mail /var/spool/mail/hsy 更换文件权限： 方法一：chmod u=rw,g=r,o=rx /a.txt 方法二：chmod 744 /a.txt (r=4,w=2,x=1) 如果要在一个目录下创建删除重命名文件，则该用户需要同时有wx权限 如果要修改一个目录下文件的内容，则需要文件的w权限，和前面目录的x权限]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
</search>
